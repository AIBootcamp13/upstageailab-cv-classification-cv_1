# -*- coding: utf-8 -*-
"""baseline_code_kfold.py

K-Fold Cross Validation version of the document type classification baseline code.

## Improvements Applied:
- Stratified 5-Fold Cross Validation
- Better model architecture (EfficientNet)
- Larger image size (224x224)
- Enhanced data augmentation
- Learning rate scheduler
- Label smoothing loss
- Mixed precision training
- Test time augmentation (TTA)
- Model ensemble from all folds

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- K-Fold Cross Validation Training
- Ensemble Inference & Save File
"""

import os
import time
import random
import cv2

import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp.autocast_mode import autocast
from torch.cuda.amp.grad_scaler import GradScaler
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import StratifiedKFold
import gc

# Augraphy imports
try:
    from augraphy import (
        AugraphyPipeline, InkBleed, BleedThrough, ColorPaper, OneOf, NoiseTexturize,
        SubtleNoise, LightingGradient, ShadowCast
    )
    AUGRAPHY_AVAILABLE = True
except ImportError:
    AUGRAPHY_AVAILABLE = False
    print("Warning: Augraphy not available. Skipping augraphy augmentations.")

# ë¡œê·¸ ìœ í‹¸ë¦¬í‹° import
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # í˜„ì¬ íŒŒì¼ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
import utils.log_util as log


# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
def set_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    
    # CUDA 10.2+ í™˜ê²½ì—ì„œ ê²°ì •ì  ì—°ì‚°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    # ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì •
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    # CUDA í™˜ê²½ì—ì„œ ê²°ì •ì  ì—°ì‚° ì„¤ì • (ì„ íƒì )
    try:
        torch.use_deterministic_algorithms(True)
        log.info("ì™„ì „í•œ ì¬í˜„ì„± ì„¤ì •ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        log.info(f"torch.use_deterministic_algorithms(True) ì„¤ì • ì‹¤íŒ¨: {e}")
        log.info("ê¸°ë³¸ ì¬í˜„ì„± ì„¤ì •ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# ì‹œë“œ ë¦¬ìŠ¤íŠ¸ ì •ì˜ (2ê°œ ì‹œë“œ ì‚¬ìš©)
SEEDS = [42, 123]
# ì´ˆê¸° ì‹œë“œ ì„¤ì •
set_seed(SEEDS[0])
log.info(f"ğŸŒ± Initial random seed set to {SEEDS[0]}")

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Label Smoothing Loss í´ë˜ìŠ¤ ì •ì˜
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes, smoothing=0.1):
        super(LabelSmoothingLoss, self).__init__()
        self.smoothing = smoothing
        self.classes = classes
        
    def forward(self, pred, target):
        pred = pred.log_softmax(dim=-1)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.classes - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)
        return torch.mean(torch.sum(-true_dist * pred, dim=-1))

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, csv_data, path, transform=None, cache_images=True, cache_augmented=True, augmentation_multiplier=1, save_augmented_to_disk=True, current_seed=None, img_size=None):
        if isinstance(csv_data, str):
            self.df = pd.read_csv(csv_data).values
        else:
            self.df = csv_data.values
        self.path = path
        self.transform = transform
        self.cache_images = cache_images
        self.cache_augmented = cache_augmented
        self.augmentation_multiplier = augmentation_multiplier
        self.save_augmented_to_disk = save_augmented_to_disk
        self.current_seed = current_seed
        self.img_size = img_size
        self.image_cache = {} if cache_images else None
        self.augmented_cache = {} if cache_augmented else None
        
        # Augraphy íŒŒì´í”„ë¼ì¸ ì´ˆê¸°í™”
        self.augraphy_pipeline = get_augraphy_pipeline()
        if self.augraphy_pipeline:
            log.info("ğŸ“¸ Augraphy pipeline initialized")
        
        # ì‹œë“œë³„ ì¦ê°• ì´ë¯¸ì§€ ì €ì¥ í´ë” ì„¤ì •
        if self.save_augmented_to_disk and self.current_seed is not None:
            # ìºì‹œ ë””ë ‰í† ë¦¬ë¥¼ data í´ë” ì•ˆìœ¼ë¡œ ë³€ê²½ (input/data/train_cache)
            data_dir = os.path.dirname(os.path.dirname(self.path))  # input/data/train/ -> input/data/
            self.train_cache_dir = os.path.join(data_dir, 'train_cache')
            # img_sizeë¥¼ í¬í•¨í•œ ìºì‹œ ë””ë ‰í† ë¦¬ëª… ìƒì„±
            cache_dir_name = f'img{self.img_size}_seed{self.current_seed}' if self.img_size is not None else f'seed_{self.current_seed}'
            self.seed_cache_dir = os.path.join(self.train_cache_dir, cache_dir_name)
            os.makedirs(self.seed_cache_dir, exist_ok=True)
            log.info(f"ğŸ“ Seed {self.current_seed} cache directory: {self.seed_cache_dir}")
        else:
            self.seed_cache_dir = None
        
        # ì¦ê°• ë°°ìˆ˜ê°€ 1ë³´ë‹¤ í° ê²½ìš° ë°ì´í„°ë¥¼ ë³µì œ (ì›ë³¸ ì œì™¸, ì¦ê°•ëœ ë°ì´í„°ë§Œ ì‚¬ìš©)
        if self.augmentation_multiplier > 1:
            original_df = self.df.copy()
            augmented_data = []
            
            # ì¦ê°•ëœ ë°ì´í„°ë§Œ ì¶”ê°€ (ì›ë³¸ ì œì™¸)
            for i, (name, target) in enumerate(original_df):
                for aug_idx in range(1, self.augmentation_multiplier + 1):  # 1ë¶€í„° augmentation_multiplierê¹Œì§€
                    augmented_data.append((name, target, aug_idx))  # aug_idxëŠ” ì¦ê°• ì¸ë±ìŠ¤
            
            self.df = np.array(augmented_data)
            log.info(f"ğŸ“ˆ Data augmented (ì›ë³¸ ì œì™¸): {len(original_df)} â†’ {len(self.df)} samples (ì¦ê°• x{self.augmentation_multiplier})")
        elif self.augmentation_multiplier == 1:
            # augmentation_multiplierê°€ 1ì´ë©´ ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš©
            original_df = self.df.copy()
            augmented_data = []
            
            # ì›ë³¸ ë°ì´í„° ì¶”ê°€
            for i, (name, target) in enumerate(original_df):
                augmented_data.append((name, target, 0))  # 0ì€ ì›ë³¸ì„ ì˜ë¯¸
            
            self.df = np.array(augmented_data)
            log.info(f"ğŸ“ˆ ì›ë³¸ ë°ì´í„°ë§Œ ì‚¬ìš©: {len(original_df)} samples")
        
        # ìºì‹± í†µê³„
        self.stats = {
            'original_cache_hits': 0,
            'original_cache_misses': 0,
            'augmented_cache_hits': 0,
            'augmented_cache_misses': 0,
            'disk_cache_hits': 0,
            'disk_cache_misses': 0,
            'disk_loads': 0,
            'augmentations': 0,
            'augmented_saves': 0
        }

    def _get_augmented_cache_path(self, img_name, aug_idx):
        """ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.save_augmented_to_disk or self.seed_cache_dir is None:
            return None
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  ì¦ê°• ì¸ë±ìŠ¤ì™€ í•¨ê»˜ .pt í™•ì¥ì ì¶”ê°€ (í…ì„œ ì €ì¥ìš©)
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(self.seed_cache_dir, f"{base_name}_aug_{aug_idx}.pt")
    
    def _get_augmented_visual_path(self, img_name, aug_idx):
        """ì¦ê°•ëœ ì´ë¯¸ì§€ ì‹œê°ì  í™•ì¸ìš© íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.save_augmented_to_disk or self.seed_cache_dir is None:
            return None
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  ì¦ê°• ì¸ë±ìŠ¤ì™€ í•¨ê»˜ .jpg í™•ì¥ì ì¶”ê°€ (ì‹œê°ì  í™•ì¸ìš©)
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(self.seed_cache_dir, f"{base_name}_aug_{aug_idx}.jpg")
    
    def _get_tta_cache_path(self, img_name, tta_idx):
        """TTA ì´ë¯¸ì§€ ìºì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.save_augmented_to_disk or self.seed_cache_dir is None:
            return None
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  TTA ì¸ë±ìŠ¤ì™€ í•¨ê»˜ .pt í™•ì¥ì ì¶”ê°€ (í…ì„œ ì €ì¥ìš©)
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(self.seed_cache_dir, f"{base_name}_tta_{tta_idx}.pt")
    
    def _get_tta_visual_path(self, img_name, tta_idx):
        """TTA ì´ë¯¸ì§€ ì‹œê°ì  í™•ì¸ìš© íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if not self.save_augmented_to_disk or self.seed_cache_dir is None:
            return None
        # íŒŒì¼ëª…ì—ì„œ í™•ì¥ì ì œê±°í•˜ê³  TTA ì¸ë±ìŠ¤ì™€ í•¨ê»˜ .jpg í™•ì¥ì ì¶”ê°€ (ì‹œê°ì  í™•ì¸ìš©)
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(self.seed_cache_dir, f"{base_name}_tta_{tta_idx}.jpg")
    
    def _load_image_from_cache(self, cache_path):
        """ìºì‹œ íŒŒì¼ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if cache_path is None or not os.path.exists(cache_path):
            return None
        
        try:
            # í…ì„œ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (ë” ë¹ ë¦„)
            img_tensor = torch.load(cache_path, map_location='cpu')
            
            self.stats['disk_cache_hits'] += 1
            return img_tensor
            
        except Exception as e:
            log.warning(f"Failed to load cached tensor from {cache_path}: {e}")
            self.stats['disk_cache_misses'] += 1
            return None
    
    def _save_augmented_to_disk(self, img_name, aug_idx, img_tensor):
        """ì¦ê°•ëœ ì´ë¯¸ì§€ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥í•©ë‹ˆë‹¤."""
        if not self.save_augmented_to_disk or self.seed_cache_dir is None:
            return
        
        try:
            # í…ì„œë¥¼ ì§ì ‘ ì €ì¥ (ë” ë¹ ë¦„)
            cache_path = self._get_augmented_cache_path(img_name, aug_idx)
            if cache_path is not None:
                torch.save(img_tensor.cpu(), cache_path)
                self.stats['augmented_saves'] += 1
            
            # ì‹œê°ì  í™•ì¸ìš© jpg íŒŒì¼ë„ ì €ì¥
            visual_path = self._get_augmented_visual_path(img_name, aug_idx)
            if visual_path is not None:
                # í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                img_array = img_tensor.cpu().numpy()
                
                # [C, H, W] -> [H, W, C] ë³€í™˜
                img_array_hwc = img_array.transpose(1, 2, 0)
                
                # ì •ê·œí™” ì—­ë³€í™˜ (ImageNet í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì‚¬ìš©)
                mean = np.array([0.485, 0.456, 0.406])
                std = np.array([0.229, 0.224, 0.225])
                
                # ì •ê·œí™” í•´ì œ: normalized = (original - mean) / std -> original = normalized * std + mean
                img_array_denorm = img_array_hwc * std + mean
                
                # [0, 1] ë²”ìœ„ë¡œ í´ë¦¬í•‘í•˜ê³  255ë¥¼ ê³±í•´ì„œ uint8ë¡œ ë³€í™˜
                img_array_uint8 = (np.clip(img_array_denorm, 0, 1) * 255).astype(np.uint8)
                
                pil_image = Image.fromarray(img_array_uint8)
                pil_image.save(visual_path, 'JPEG', quality=95)
                
        except Exception as e:
            log.warning(f"Failed to save augmented cache for {img_name}_aug{aug_idx}: {e}")

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        if self.augmentation_multiplier > 1:
            name, target, aug_idx = self.df[idx]
            # aug_idxë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ (numpy arrayì—ì„œ ë¬¸ìì—´ë¡œ ì½í ìˆ˜ ìˆìŒ)
            aug_idx = int(aug_idx)
        else:
            name, target = self.df[idx]
            aug_idx = 0
        
        # ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹œ í™•ì¸ (ë©”ëª¨ë¦¬ ìºì‹œ)
        cache_key = f"{name}_aug{aug_idx}" if aug_idx > 0 else name
        if self.cache_augmented and self.augmented_cache is not None and cache_key in self.augmented_cache:
            img = self.augmented_cache[cache_key]
            self.stats['augmented_cache_hits'] += 1
            target = int(target)
            return img, target
        
        self.stats['augmented_cache_misses'] += 1
        
        # ë””ìŠ¤í¬ ìºì‹œ í™•ì¸ (ì¦ê°• ì´ë¯¸ì§€)
        if aug_idx > 0:
            cache_path = self._get_augmented_cache_path(name, aug_idx)
            cached_img = self._load_image_from_cache(cache_path)
            if cached_img is not None:
                # ë©”ëª¨ë¦¬ ìºì‹œì—ë„ ì €ì¥
                if self.cache_augmented and self.augmented_cache is not None:
                    self.augmented_cache[cache_key] = cached_img
                target = int(target)
                return cached_img, target
        
        # ìºì‹œì— ì—†ìœ¼ë©´ ì´ë¯¸ì§€ ë¡œë“œ ë° ì¦ê°• ì²˜ë¦¬
        # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
        if self.cache_images and self.image_cache is not None and name in self.image_cache:
            img = self.image_cache[name]
            self.stats['original_cache_hits'] += 1
        else:
            self.stats['original_cache_misses'] += 1
            img = np.array(Image.open(os.path.join(self.path, name)))
            self.stats['disk_loads'] += 1
            
            # ë©”ëª¨ë¦¬ ìºì‹œì— ì €ì¥
            if self.cache_images and self.image_cache is not None:
                self.image_cache[name] = img
        
        # ì¦ê°• ì ìš©
        if self.transform:
            if aug_idx > 0:
                # ì¦ê°•ëœ ë°ì´í„°: Augraphy + ëœë¤ ì¦ê°• + transform ì ìš©
                self.stats['augmentations'] += 1
                
                # Augraphy ì ìš© (50% í™•ë¥ )
                if self.augraphy_pipeline and random.random() < 0.5:
                    try:
                        # imgê°€ numpy arrayì¸ì§€ í™•ì¸
                        if not isinstance(img, np.ndarray):
                            img = np.array(img)
                        # í‘ë°±ì´ë©´ 3ì±„ë„ë¡œ ë³€í™˜
                        if img.ndim == 2:
                            img = np.stack([img]*3, axis=-1)
                        if img.shape[2] == 1:
                            img = np.repeat(img, 3, axis=2)
                        if img.dtype != np.uint8:
                            img = img.astype(np.uint8)
                        # Augraphy ì ìš©
                        img = self.augraphy_pipeline(img)
                    except Exception as e:
                        log.warning(f"Augraphy failed for {name}: {e}")
                
                # Albumentations transform ì ìš©
                img = self.transform(image=img)['image']
                
                # ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹±
                if self.cache_augmented and self.augmented_cache is not None:
                    self.augmented_cache[cache_key] = img
                
                # ì¦ê°•ëœ ì´ë¯¸ì§€ë¥¼ ë””ìŠ¤í¬ì— ì €ì¥
                self._save_augmented_to_disk(name, aug_idx, img)
                
            else:
                # ì›ë³¸ ë°ì´í„°: transformë§Œ ì ìš© (resize, normalize ë“±, ì¦ê°• ì—†ìŒ)
                # ì›ë³¸ìš© transform ìƒì„± (ì¦ê°• ì œì™¸)
                original_transform = A.Compose([
                    A.LongestMaxSize(max_size=320, interpolation=cv2.INTER_AREA),  # img_size í•˜ë“œì½”ë”©
                    A.PadIfNeeded(min_height=320, min_width=320,
                                border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
                    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                    ToTensorV2(),
                ])
                img = original_transform(image=img)['image']
        
        # targetì„ ì •ìˆ˜ë¡œ ë³€í™˜ (numpy arrayì—ì„œ ë¬¸ìì—´ë¡œ ì½í ìˆ˜ ìˆìŒ)
        target = int(target)
        return img, target
    
    def print_stats(self):
        """ìºì‹± í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        # í˜„ì¬ ì—í¬í¬ì˜ ì´ ìš”ì²­ ìˆ˜ (ì¦ê°• ìºì‹œ íˆíŠ¸ + ë¯¸ìŠ¤ì˜ í•©)
        current_epoch_requests = self.stats['augmented_cache_hits'] + self.stats['augmented_cache_misses']
        
        if current_epoch_requests > 0:
            log.info(f"ğŸ“Š Dataset Disk Cache Statistics (Memory Cache Disabled):")
            log.info(f"   Current epoch requests: {current_epoch_requests}")
            log.info(f"   Disk cache hits: {self.stats['disk_cache_hits']} ({self.stats['disk_cache_hits']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Disk cache misses: {self.stats['disk_cache_misses']} ({self.stats['disk_cache_misses']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Disk loads: {self.stats['disk_loads']}")
            log.info(f"   Augmented saves: {self.stats['augmented_saves']}")
            log.info(f"   Augmentations applied: {self.stats['augmentations']}")
            
            # ë””ìŠ¤í¬ ìºì‹œ íš¨ìœ¨ì„± ê³„ì‚°
            if self.stats['disk_cache_hits'] > 0:
                disk_cache_efficiency = self.stats['disk_cache_hits'] / current_epoch_requests * 100
                log.info(f"   Disk cache efficiency: {disk_cache_efficiency:.1f}%")
    
    def reset_stats(self):
        """í†µê³„ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.stats = {
            'original_cache_hits': 0,
            'original_cache_misses': 0,
            'augmented_cache_hits': 0,
            'augmented_cache_misses': 0,
            'disk_cache_hits': 0,
            'disk_cache_misses': 0,
            'disk_loads': 0,
            'augmentations': 0,
            'augmented_saves': 0
        }

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader, desc="Training")
    for image, targets in pbar:
        image = image.to(device, dtype=torch.float32)  # ëª…ì‹œì ìœ¼ë¡œ float32ë¡œ ë³€í™˜
        targets = targets.to(device)

        optimizer.zero_grad()

        with autocast():
            preds = model(image)
            loss = loss_fn(preds, targets)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Training - Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret

# ê²€ì¦ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def validate_one_epoch(loader, model, loss_fn, device):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader, desc="Validation")
    with torch.no_grad():
        for image, targets in pbar:
            image = image.to(device, dtype=torch.float32)  # ëª…ì‹œì ìœ¼ë¡œ float32ë¡œ ë³€í™˜
            targets = targets.to(device)

            with autocast():
                preds = model(image)
                loss = loss_fn(preds, targets)

            val_loss += loss.item()
            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
            targets_list.extend(targets.detach().cpu().numpy())

            pbar.set_description(f"Validation - Loss: {loss.item():.4f}")

    val_loss /= len(loader)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
    }

    return ret

# Validation TTAë¥¼ ìœ„í•œ ê³ ì •ëœ transform ì„¸íŠ¸
def get_val_tta_transforms(img_size):
    """TTAë¥¼ ìœ„í•œ ê³ ì •ëœ transformë“¤ (ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ ë³€í˜•ë“¤)"""
    return [
        # ì›ë³¸
        A.Compose([
            A.Resize(height=img_size, width=img_size),
            # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            # A.PadIfNeeded(min_height=img_size, min_width=img_size,
            #               border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ì¢Œìš° ë°˜ì „
        A.Compose([
            A.HorizontalFlip(p=1.0),
            A.Resize(height=img_size, width=img_size),
            # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            # A.PadIfNeeded(min_height=img_size, min_width=img_size,
            #               border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ìƒí•˜ ë°˜ì „ (ë¬¸ì„œ ì´ë¯¸ì§€ì— ìœ ìš©í•  ìˆ˜ ìˆìŒ)
        A.Compose([
            A.VerticalFlip(p=1.0),
            A.Resize(height=img_size, width=img_size),
            # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            # A.PadIfNeeded(min_height=img_size, min_width=img_size,
            #               border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # íšŒì „ (ì•½ê°„ì˜ íšŒì „)
        A.Compose([
            A.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=15, p=1.0),
            A.Resize(height=img_size, width=img_size),
            # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            # A.PadIfNeeded(min_height=img_size, min_width=img_size,
            #               border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ë°ê¸° ì¡°ì •
        A.Compose([
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0, p=1.0),
            A.Resize(height=img_size, width=img_size),
            # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            # A.PadIfNeeded(min_height=img_size, min_width=img_size,
            #               border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
    ]

# Test Time Augmentationì„ ìœ„í•œ ì˜ˆì¸¡ í•¨ìˆ˜ (tst_dataset ì‚¬ìš©)
def predict_with_tta(model, dataset, device, img_size, current_seed=None):
    """ì§„ì§œ TTAë¥¼ ì ìš©í•œ ì˜ˆì¸¡ í•¨ìˆ˜ - datasetì„ ì‚¬ìš©"""
    model.eval()
    predictions = []
    
    # TTA transforms ê°€ì ¸ì˜¤ê¸° (validationê³¼ ë™ì¼)
    tta_transforms = get_val_tta_transforms(img_size)
    
    # ì‹œë“œë³„ TTA ìºì‹œ ë””ë ‰í† ë¦¬ ì„¤ì •
    if current_seed is not None:
        data_dir = os.path.dirname(os.path.dirname(dataset.path))  # input/data/train/ -> input/data/
        train_cache_dir = os.path.join(data_dir, 'train_cache')
        # img_sizeë¥¼ í¬í•¨í•œ ìºì‹œ ë””ë ‰í† ë¦¬ëª… ìƒì„±
        cache_dir_name = f'img{img_size}_seed{current_seed}' if img_size is not None else f'seed_{current_seed}'
        seed_cache_dir = os.path.join(train_cache_dir, cache_dir_name)
        os.makedirs(seed_cache_dir, exist_ok=True)
    else:
        seed_cache_dir = None
    
    def get_tta_cache_path(img_name, tta_idx):
        """TTA ì´ë¯¸ì§€ ìºì‹œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if seed_cache_dir is None:
            return None
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(seed_cache_dir, f"{base_name}_tta_{tta_idx}.pt")
    
    def get_tta_visual_path(img_name, tta_idx):
        """TTA ì´ë¯¸ì§€ ì‹œê°ì  í™•ì¸ìš© íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        if seed_cache_dir is None:
            return None
        base_name = os.path.splitext(img_name)[0]
        return os.path.join(seed_cache_dir, f"{base_name}_tta_{tta_idx}.jpg")
    
    def load_tta_from_cache(cache_path):
        """ìºì‹œëœ TTA ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤."""
        if cache_path is None or not os.path.exists(cache_path):
            return None
        
        try:
            img = Image.open(cache_path)
            img_array = np.array(img)
            
            # ì •ê·œí™” ì ìš© (ImageNet í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì‚¬ìš©)
            img_array = img_array.astype(np.float32) / 255.0
            mean = np.array([0.485, 0.456, 0.406])
            std = np.array([0.229, 0.224, 0.225])
            img_array = (img_array - mean) / std
            
            # [H, W, C] -> [C, H, W] ë³€í™˜ í›„ í…ì„œë¡œ ë³€í™˜
            img_tensor = torch.from_numpy(img_array.transpose(2, 0, 1))
            return img_tensor
            
        except Exception as e:
            log.warning(f"Failed to load cached TTA image from {cache_path}: {e}")
            return None
    
    def save_tta_to_cache(img_name, tta_idx, img_tensor):
        """TTA ì´ë¯¸ì§€ë¥¼ ìºì‹œì— ì €ì¥í•©ë‹ˆë‹¤."""
        if seed_cache_dir is None:
            return
        
        try:
            cache_path = get_tta_cache_path(img_name, tta_idx)
            if cache_path is not None:
                # í…ì„œë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜
                img_array = img_tensor.cpu().numpy()
                
                # [C, H, W] -> [H, W, C] ë³€í™˜
                img_array_hwc = img_array.transpose(1, 2, 0)
                
                # ì •ê·œí™” ì—­ë³€í™˜ (ImageNet í‰ê· ê³¼ í‘œì¤€í¸ì°¨ ì‚¬ìš©)
                mean = np.array([0.485, 0.456, 0.406])
                std = np.array([0.229, 0.224, 0.225])
                
                # ì •ê·œí™” í•´ì œ: normalized = (original - mean) / std -> original = normalized * std + mean
                img_array_denorm = img_array_hwc * std + mean
                
                # [0, 1] ë²”ìœ„ë¡œ í´ë¦¬í•‘í•˜ê³  255ë¥¼ ê³±í•´ì„œ uint8ë¡œ ë³€í™˜
                img_array_uint8 = (np.clip(img_array_denorm, 0, 1) * 255).astype(np.uint8)
                
                pil_image = Image.fromarray(img_array_uint8)
                pil_image.save(cache_path, 'JPEG', quality=95)
                
        except Exception as e:
            log.warning(f"Failed to save TTA cache for {img_name}_tta{tta_idx}: {e}")
    
    with torch.no_grad():
        for idx in tqdm(range(len(dataset)), desc="Real TTA Prediction"):
            # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (transform ì—†ì´)
            if len(dataset.df[idx]) == 3:
                img_name, _, _ = dataset.df[idx]  # augmentation_multiplier > 1ì¸ ê²½ìš°
            else:
                img_name, _ = dataset.df[idx]  # augmentation_multiplier == 1ì¸ ê²½ìš°
            img_path = os.path.join(dataset.path, img_name)
            original_img = np.array(Image.open(img_path))
            
            # ê° TTA transform ì ìš©í•˜ì—¬ ì˜ˆì¸¡
            all_preds = []
            
            for tta_idx, transform in enumerate(tta_transforms):
                # ìºì‹œëœ TTA ì´ë¯¸ì§€ í™•ì¸
                cache_path = get_tta_cache_path(img_name, tta_idx)
                cached_img = load_tta_from_cache(cache_path)
                
                if cached_img is not None:
                    # ìºì‹œëœ ì´ë¯¸ì§€ ì‚¬ìš©
                    transformed_img = cached_img.unsqueeze(0).to(device)
                else:
                    # ë§¤ë²ˆ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë‹¤ë¥¸ ë³€í˜• ì ìš©
                    transformed_img_tensor = transform(image=original_img)['image']
                    transformed_img = transformed_img_tensor.unsqueeze(0).to(device)
                    
                    # ìºì‹œì— ì €ì¥
                    save_tta_to_cache(img_name, tta_idx, transformed_img_tensor)
                
                with autocast():
                    # ì…ë ¥ í…ì„œë¥¼ float32ë¡œ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
                    transformed_img = transformed_img.float()
                    preds = model(transformed_img)
                
                all_preds.append(preds.softmax(dim=1))
            
            # ì˜ˆì¸¡ í‰ê·  (í™•ë¥  ë¶„í¬ ë°˜í™˜)
            final_pred = torch.stack(all_preds).mean(0)
            predictions.append(final_pred.squeeze(0).detach().cpu().numpy())
    
    return np.array(predictions)

# ì•™ìƒë¸” ì˜ˆì¸¡ í•¨ìˆ˜
def predict_ensemble(models, dataset, device, img_size):
    all_predictions = []
    
    for i, model in enumerate(models):
        log.info(f"ğŸ”® Predicting with Fold {i+1} model...")
        fold_predictions = predict_with_tta(model, dataset, device, img_size)
        all_predictions.append(fold_predictions)
    
    # ëª¨ë“  í´ë“œì˜ ì˜ˆì¸¡ì„ í‰ê·  (shape: [num_samples, num_classes])
    ensemble_predictions = np.mean(all_predictions, axis=0)
    # ê° ìƒ˜í”Œì— ëŒ€í•´ argmax ì ìš©
    final_predictions = np.argmax(ensemble_predictions, axis=1)
    
    return final_predictions

"""## Hyper-parameters
* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
"""

# device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
log.info(f"ğŸ’» Using device: {device}")

# data config
# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
script_dir = os.path.dirname(os.path.abspath(__file__))
data_path = os.path.join(os.path.dirname(os.path.dirname(script_dir)), 'input', 'data')
log.info(f"ğŸ“‚ Data path: {data_path}")

# model config
model_name = 'efficientnetv2_rw_m'  # ë” ì¢‹ì€ ëª¨ë¸ ì‚¬ìš©

# training config
img_size = 320  # ì´ë¯¸ì§€ í¬ê¸° ëŒ€í­ í™•ëŒ€
LR = 1e-3  # ë” ë‚®ì€ í•™ìŠµë¥ 
EPOCHS = 100  # early stoppingì„ ìœ„í•´ ë” ë§ì€ epoch ì„¤ì •
BATCH_SIZE = 16  # í° ëª¨ë¸ì— ë§ì¶° ë°°ì¹˜ í¬ê¸° ì¡°ì •
num_workers = 0
weight_decay = 1e-4
label_smoothing = 0.1
patience = 10  # early stopping patience

# Data augmentation config
AUGMENTATION_MULTIPLIER = 10 # ë°ì´í„° ì¦ê°• ë°°ìˆ˜ (ê¸°ë³¸ê°’: 2ë°°)
# ì˜ˆ: AUGMENTATION_MULTIPLIER = 3ì´ë©´ ì›ë³¸ ë°ì´í„° 1ê°œë‹¹ ì¦ê°•ëœ ë°ì´í„° 2ê°œê°€ ì¶”ê°€ë˜ì–´ ì´ 3ë°°ê°€ ë©ë‹ˆë‹¤.
# ì›ë³¸ ë°ì´í„°ëŠ” ê·¸ëŒ€ë¡œ ìœ ì§€ë˜ê³ , ì¶”ê°€ë¡œ ì¦ê°•ëœ ë°ì´í„°ë§Œ ìƒì„±ë©ë‹ˆë‹¤.

# K-Fold config
K_FOLDS = 5

"""## Data Preparation
* ë°ì´í„° ë¡œë“œ ë° transform ì •ì˜
"""

# ê°•í™”ëœ augmentationì„ ìœ„í•œ transform ì½”ë“œ
trn_transform = A.Compose([
    # ë‹¤ì–‘í•œ ë°ì´í„° ì¦ê°• ê¸°ë²•ë“¤
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.2),
    # A.RandomRotate90(p=0.5),
    # A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
    # A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),
    # A.Blur(blur_limit=3, p=0.1),
    # A.CLAHE(clip_limit=2.0, p=0.2),

    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5, border_mode=cv2.BORDER_CONSTANT, value=(255,255,255)),
    # A.OneOf([
    #     A.Blur(blur_limit=2),
    #     A.MotionBlur(blur_limit=5),
    #     A.Defocus(radius=(1, 3)),
    # ], p=0.5),
    A.GaussNoise(var_limit=(0.0000002, 0.000001), mean=0, p=0.3),  # ì€ì€í•œ ë¯¸ì„¸ ë…¸ì´ì¦ˆ
    # A.OneOf([
    #     A.GaussNoise(var_limit=(0.0000002, 0.000001), mean=0, p=1.0),  # ì€ì€í•œ ë¯¸ì„¸ ë…¸ì´ì¦ˆ
    #     # A.ImageCompression(quality_lower=40, quality_upper=60, p=1.0),  # ì••ì¶•ìœ¼ë¡œ ì „ì²´ì  ì–¼ë£©
    #     # A.CoarseDropout(max_holes=8, max_height=img_size//10, max_width=img_size//10),
    # ], p=0.3),
    # A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
    # A.OneOf([
    #     A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.5),
    #     A.GridDropout(ratio=0.5, p=0.5),
    # ], p=0.4),
    
    A.Resize(height=img_size, width=img_size),
    # A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
    # A.PadIfNeeded(min_height=img_size, min_width=img_size,
    #                 border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),    
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

def get_augraphy_pipeline():
    """Augraphy íŒŒì´í”„ë¼ì¸ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    if not AUGRAPHY_AVAILABLE:
        return None
    
    return AugraphyPipeline(
        ink_phase=[
            InkBleed(p=0.3), # ì‰í¬ ë²ˆì§
            BleedThrough(p=0.3), # ë’·ë©´ ì‰í¬ ë¹„ì¹¨
        ],
        paper_phase=[
            ColorPaper(p=0.3), # ì¢…ì´ ìƒ‰ìƒ ë³€ê²½
            OneOf([
                NoiseTexturize( # í…ŒìŠ¤íŠ¸ ë°ì´í„°ë‘ ë¹„ìŠ·í•œ ë…¸ì´ì¦ˆ
                    sigma_range=(5, 15),
                    turbulence_range=(3, 9),
                    texture_width_range=(50, 500),
                    texture_height_range=(50, 500),
                    p=0.6
                ),
                SubtleNoise(
                    subtle_range=50,
                    p=0.4
                )
            ], p=0.3),
        ],
        post_phase=[
            LightingGradient( # ì¡°ëª… ê·¸ë¼ë°ì´ì…˜
                light_position=None,
                direction=90,
                max_brightness=255,
                min_brightness=0,
                mode="gaussian",
                transparency=0.5,
                p=0.3
            ),
            ShadowCast( # ê·¸ë¦¼ì
                shadow_side=random.choice(["top", "bottom", "left", "right"]), # ê·¸ë¦¼ì ìœ„ì¹˜
                shadow_vertices_range=(2, 3),
                shadow_width_range=(0.5, 0.8),
                shadow_height_range=(0.5, 0.8),
                shadow_color=(0, 0, 0),
                shadow_opacity_range=(0.5, 0.6),
                shadow_iterations_range=(1, 2),
                shadow_blur_kernel_range=(101, 301),
                p=0.3
            ),
        ],
    )

# validation transform (trainê³¼ ë™ì¼í•œ ì¦ê°• ì ìš©)
val_transform = trn_transform

# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv(f"{data_path}/train.csv")
log.info(f"ğŸ“‚ Total training samples: {len(train_df)}")

# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
class_counts = train_df['target'].value_counts().sort_index()
log.info(f"ğŸ“Š Class distribution: {class_counts.to_dict()}")

"""## K-Fold Cross Validation Training
* 5í´ë“œ ì¸µí™” êµì°¨ê²€ì¦ìœ¼ë¡œ ëª¨ë¸ì„ í•™ìŠµí•©ë‹ˆë‹¤.
"""

# Early Stopping í´ë˜ìŠ¤ ì •ì˜
class EarlyStopping:
    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score, model):
        if self.best_score is None:
            self.best_score = val_score
            self.best_weights = model.state_dict().copy()
        elif val_score > self.best_score + self.min_delta:
            self.best_score = val_score
            self.counter = 0
            self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

# K-Fold ì •ì˜
# ì´ˆê¸° ì‹œë“œ ì„¤ì •ì„ ìœ„í•´ ì—¬ê¸°ì„œëŠ” skf ì •ì˜í•˜ì§€ ì•Šê³  ë‚˜ì¤‘ì— ì‹œë“œë³„ë¡œ ì •ì˜

# ì‹œë“œë³„ ê²°ê³¼ ì €ì¥
all_seed_scores = []
model_paths = []  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì €ì¥

log.info(f"\nğŸ”„ Starting {K_FOLDS}-Fold Cross Validation with {len(SEEDS)} seeds...")

# ëª¨ë¸ ì €ì¥ ê²½ë¡œ ì„¤ì •
models_dir = "./models"
os.makedirs(models_dir, exist_ok=True)
log.info(f"ğŸ“‚ Models will be saved to: {models_dir}")

# ì‹œë“œë³„ ê²°ê³¼ ì €ì¥
all_seed_scores = []
model_paths = []  # ëª¨ë¸ íŒŒì¼ ê²½ë¡œë¥¼ ì €ì¥

# ì‹œë“œë³„ í•™ìŠµ ë£¨í”„
for seed_idx, seed in enumerate(SEEDS):
    log.info(f"\n{'='*80}")
    log.info(f"ğŸŒ± SEED {seed_idx+1}/{len(SEEDS)}: {seed}")
    log.info(f"{'='*80}")
    
    # ì‹œë“œ ì¬ì„¤ì •
    set_seed(seed)
    
    # ì´ ì‹œë“œì— ëŒ€í•œ K-Fold ì •ì˜
    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=seed)
    
    # í´ë“œë³„ ê²°ê³¼ ì €ì¥
    fold_scores = []
    seed_model_paths = []  # ì´ ì‹œë“œì˜ ëª¨ë¸ íŒŒì¼ ê²½ë¡œë“¤
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):
        log.info(f"\n{'='*60}")
        log.info(f"ğŸ”¥ SEED {seed} | FOLD {fold+1}/{K_FOLDS}")
        log.info(f"{'='*60}")
        
        # í´ë“œë³„ ë°ì´í„° ë¶„í• 
        train_fold = train_df.iloc[train_idx].reset_index(drop=True)
        val_fold = train_df.iloc[val_idx].reset_index(drop=True)
        
        log.info(f"ğŸ“š Train samples: {len(train_fold)}")
        log.info(f"ğŸ“ Validation samples: {len(val_fold)}")
        
        # ë°ì´í„°ì…‹ ìƒì„± (ë©”ëª¨ë¦¬ ìºì‹œ ë¹„í™œì„±í™”, ë””ìŠ¤í¬ ìºì‹œë§Œ ì‚¬ìš©)
        trn_dataset = ImageDataset(train_fold, f"{data_path}/train/", transform=trn_transform, cache_images=False, cache_augmented=False, augmentation_multiplier=AUGMENTATION_MULTIPLIER, save_augmented_to_disk=True, current_seed=seed, img_size=img_size)
        val_dataset = ImageDataset(val_fold, f"{data_path}/train/", transform=val_transform, cache_images=False, cache_augmented=False, augmentation_multiplier=AUGMENTATION_MULTIPLIER, save_augmented_to_disk=True, current_seed=seed, img_size=img_size)
        
        # DataLoader ìƒì„±
        trn_loader = DataLoader(
            trn_dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=BATCH_SIZE,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=False
        )
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ë§¤ í´ë“œë§ˆë‹¤ ìƒˆë¡œ ì‹œì‘)
        model = timm.create_model(
            model_name,
            pretrained=True,
            num_classes=17
        ).to(device)
        
        # ëª¨ë¸ì„ float32ë¡œ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
        model = model.float()
        
        log.info(f"ğŸ—ï¸ Model: {model_name}")
        log.info(f"ğŸ”¢ Number of parameters: {sum(p.numel() for p in model.parameters()):,}")
        
        # Loss function, optimizer, scheduler ì •ì˜
        loss_fn = LabelSmoothingLoss(classes=17, smoothing=label_smoothing)
        optimizer = Adam(model.parameters(), lr=LR, weight_decay=weight_decay)
        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)
        scaler = GradScaler()
        
        # Early stopping ì´ˆê¸°í™”
        early_stopping = EarlyStopping(patience=patience, min_delta=0.001, restore_best_weights=True)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
        best_val_f1 = 0.0
        best_model_state = None
        
        log.info(f"ğŸš€ Starting Seed {seed} | Fold {fold+1} training...")
        
        # í´ë“œë³„ í•™ìŠµ
        for epoch in range(EPOCHS):
            log.info(f"\n--- Seed {seed} | Fold {fold+1} | Epoch {epoch+1}/{EPOCHS} ---")
            
            # ì—í¬í¬ ì‹œì‘ ì‹œ í†µê³„ ì´ˆê¸°í™”
            trn_dataset.reset_stats()
            val_dataset.reset_stats()
            
            # Training
            train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler)
            
            # Validation
            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)
            
            # Learning rate scheduler step
            scheduler.step()
            
            # ê²°ê³¼ ì¶œë ¥
            current_lr = optimizer.param_groups[0]['lr']
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_ret['val_f1'] > best_val_f1:
                best_val_f1 = val_ret['val_f1']
                best_model_state = model.state_dict().copy()
                log.info(f"ğŸ’¾ Seed {seed} | Fold {fold+1} Best model updated! F1: {best_val_f1:.4f}")
            
            # Early stopping ì²´í¬
            if early_stopping(val_ret['val_f1'], model):
                log.info(f"ğŸ›‘ Early stopping triggered at epoch {epoch+1} for Seed {seed} | Fold {fold+1}")
                log.info(f"ğŸ¯ Best F1 score: {early_stopping.best_score:.4f}")
                break
            
            # ë¡œê·¸ ì¶œë ¥
            log_msg = f"train_loss: {train_ret['train_loss']:.4f} | "
            log_msg += f"train_acc: {train_ret['train_acc']:.4f} | "
            log_msg += f"train_f1: {train_ret['train_f1']:.4f} | "
            log_msg += f"val_loss: {val_ret['val_loss']:.4f} | "
            log_msg += f"val_acc: {val_ret['val_acc']:.4f} | "
            log_msg += f"val_f1: {val_ret['val_f1']:.4f} | "
            log_msg += f"lr: {current_lr:.6f}"
            
            log.info(log_msg)
            
            # ë§¤ ì—í¬í¬ë§ˆë‹¤ ìºì‹± í†µê³„ ì¶œë ¥ (ë””ìŠ¤í¬ ìºì‹œë§Œ)
            log.info(f"\nğŸ“Š Epoch {epoch+1} Disk Cache Statistics:")
            trn_dataset.print_stats()
            val_dataset.print_stats()
        
        # í´ë“œ ì™„ë£Œ í›„ ëª¨ë¸ ì €ì¥
        # Early stoppingì´ í™œì„±í™”ëœ ê²½ìš° best_weightsë¥¼ ì‚¬ìš©, ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if early_stopping.best_weights is not None:
            final_f1 = early_stopping.best_score
            final_model_state = early_stopping.best_weights
            log.info(f"\nğŸ¯ Seed {seed} | Fold {fold+1} completed with early stopping! Best F1: {final_f1:.4f}")
        else:
            final_f1 = best_val_f1
            final_model_state = best_model_state if best_model_state is not None else model.state_dict()
            log.info(f"\nğŸ¯ Seed {seed} | Fold {fold+1} completed! Best F1: {final_f1:.4f}")
        
        fold_scores.append(final_f1)
        
        # ëª¨ë¸ì„ ë””ìŠ¤í¬ì— ì €ì¥
        model_filename = f"model_seed{seed}_fold{fold+1}.pth"
        model_path = os.path.join(models_dir, model_filename)
        torch.save(final_model_state, model_path)
        seed_model_paths.append(model_path)
        log.info(f"ğŸ’¾ Model saved to: {model_path}")
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬ (ëª¨ë¸ ìƒíƒœ ì‚­ì œ)
        del model, optimizer, scheduler, scaler, trn_loader, val_loader
        del trn_dataset, val_dataset, train_fold, val_fold
        del best_model_state, final_model_state
        if early_stopping.best_weights is not None:
            del early_stopping.best_weights
        torch.cuda.empty_cache()
        gc.collect()
        
        log.info(f"ğŸ§¹ Memory cleaned for Seed {seed} | Fold {fold+1}")
    
    # ì‹œë“œë³„ ê²°ê³¼ ì €ì¥
    all_seed_scores.append(fold_scores)
    model_paths.append(seed_model_paths)
    
    # ì‹œë“œë³„ ê²°ê³¼ ìš”ì•½
    log.info(f"\n{'='*60}")
    log.info(f"ğŸ“Š SEED {seed} K-FOLD RESULTS")
    log.info(f"{'='*60}")
    
    seed_mean_score = np.mean(fold_scores)
    seed_std_score = np.std(fold_scores)
    
    log.info(f"ğŸ“ˆ Seed {seed} fold scores: {[f'{score:.4f}' for score in fold_scores]}")
    log.info(f"ğŸ¯ Seed {seed} Mean F1 Score: {seed_mean_score:.4f}")
    log.info(f"ğŸ“ Seed {seed} Standard Deviation: {seed_std_score:.4f}")
    log.info(f"ğŸ“Š Seed {seed} Score Range: {seed_mean_score:.4f} Â± {seed_std_score:.4f}")
    log.info(f"â¬‡ï¸ Seed {seed} Min Score: {min(fold_scores):.4f}")
    log.info(f"â¬†ï¸ Seed {seed} Max Score: {max(fold_scores):.4f}")
    log.info(f"ğŸ’¾ Seed {seed} model paths: {seed_model_paths}")

# ì „ì²´ ì‹œë“œë³„ ê²°ê³¼ ìš”ì•½
log.info(f"\n{'='*80}")
log.info(f"ğŸ“Š ALL SEEDS K-FOLD CROSS VALIDATION RESULTS")
log.info(f"{'='*80}")

# ëª¨ë“  ì‹œë“œì˜ ëª¨ë“  í´ë“œ ì ìˆ˜ë¥¼ í•˜ë‚˜ì˜ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ê¸°
all_scores = []
for seed_idx, seed_scores in enumerate(all_seed_scores):
    all_scores.extend(seed_scores)

overall_mean_score = np.mean(all_scores)
overall_std_score = np.std(all_scores)

log.info(f"ğŸ“ˆ Total models trained: {len(all_scores)} (Seeds: {len(SEEDS)}, Folds per seed: {K_FOLDS})")
log.info(f"ğŸ¯ Overall Mean F1 Score: {overall_mean_score:.4f}")
log.info(f"ğŸ“ Overall Standard Deviation: {overall_std_score:.4f}")
log.info(f"ğŸ“Š Overall Score Range: {overall_mean_score:.4f} Â± {overall_std_score:.4f}")
log.info(f"â¬‡ï¸ Overall Min Score: {min(all_scores):.4f}")
log.info(f"â¬†ï¸ Overall Max Score: {max(all_scores):.4f}")

# ì‹œë“œë³„ í‰ê·  ì ìˆ˜ ì¶œë ¥
for seed_idx, (seed, seed_scores) in enumerate(zip(SEEDS, all_seed_scores)):
    seed_mean = np.mean(seed_scores)
    log.info(f"ğŸŒ± Seed {seed} average: {seed_mean:.4f}")

# ëª¨ë“  ëª¨ë¸ íŒŒì¼ ê²½ë¡œ ì¶œë ¥
all_model_paths = []
for seed_paths in model_paths:
    all_model_paths.extend(seed_paths)
log.info(f"ğŸ’¾ Total saved models: {len(all_model_paths)}")

"""## Ensemble Inference & Save File
* ëª¨ë“  ì‹œë“œì˜ ëª¨ë“  í´ë“œ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.
"""

log.info(f"\nğŸš€ Starting Ensemble Prediction with {len(all_scores)} models...")

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„± (ë©”ëª¨ë¦¬ ìºì‹œ ë¹„í™œì„±í™”)
tst_dataset = ImageDataset(
    f"{data_path}/sample_submission.csv",
    f"{data_path}/test/",
    transform=None,  # TTAì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë³€í˜•í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” None
    cache_images=False,  # ë©”ëª¨ë¦¬ ìºì‹œ ë¹„í™œì„±í™”
    cache_augmented=False,  # ë©”ëª¨ë¦¬ ìºì‹œ ë¹„í™œì„±í™”
    augmentation_multiplier=1,  # í…ŒìŠ¤íŠ¸ëŠ” ì¦ê°• ì ìš©í•˜ì§€ ì•ŠìŒ
    save_augmented_to_disk=False,  # í…ŒìŠ¤íŠ¸ëŠ” ì¦ê°•í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì €ì¥í•˜ì§€ ì•ŠìŒ
    current_seed=None,  # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ì‹œë“œ ë¬´ê´€
    img_size=img_size
)

# ì•™ìƒë¸”ì„ ìœ„í•´ ì €ì¥ëœ ëª¨ë“  ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡
log.info(f"ğŸ”® Running ensemble prediction with {len(all_model_paths)} models and TTA...")

# ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
all_predictions = []

# ê° ëª¨ë¸ì„ ìˆœì°¨ì ìœ¼ë¡œ ë¡œë“œí•˜ì—¬ ì˜ˆì¸¡
for i, model_path in enumerate(all_model_paths):
    log.info(f"ğŸ”® Loading and predicting with model {i+1}/{len(all_model_paths)}: {os.path.basename(model_path)}")
    
    # ëª¨ë¸ íŒŒì¼ëª…ì—ì„œ ì‹œë“œ ì¶”ì¶œ (ì˜ˆ: model_seed42_fold1.pth -> 42)
    model_filename = os.path.basename(model_path)
    if 'seed' in model_filename:
        try:
            seed_part = model_filename.split('_')[1]  # 'seed42' ë¶€ë¶„
            current_seed = int(seed_part.replace('seed', ''))  # 42
        except:
            current_seed = None
    else:
        current_seed = None
    
    # ëª¨ë¸ ë¡œë“œ
    model = timm.create_model(
        model_name,
        pretrained=True,
        num_classes=17
    ).to(device)
    
    # ëª¨ë¸ì„ float32ë¡œ ëª…ì‹œì ìœ¼ë¡œ ë³€í™˜
    model = model.float()
    
    model.load_state_dict(torch.load(model_path, map_location=device))
    
    # ì˜ˆì¸¡ ìˆ˜í–‰ (í•´ë‹¹ ëª¨ë¸ì˜ ì‹œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ TTA ìºì‹œ í™œìš©)
    fold_predictions = predict_with_tta(model, tst_dataset, device, img_size, current_seed=current_seed)
    all_predictions.append(fold_predictions)
    
    # ë©”ëª¨ë¦¬ ì •ë¦¬
    del model
    torch.cuda.empty_cache()
    gc.collect()
    
    log.info(f"âœ… Completed prediction with {os.path.basename(model_path)} (seed: {current_seed})")

# ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê· í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ ìƒì„±
log.info(f"ğŸ¯ Averaging predictions from {len(all_predictions)} models...")
ensemble_predictions = np.mean(all_predictions, axis=0)
final_predictions = np.argmax(ensemble_predictions, axis=1)

# ê²°ê³¼ ì €ì¥
# tst_dataset.dfì˜ êµ¬ì¡°ì— ë”°ë¼ ì ì ˆí•œ ì»¬ëŸ¼ ì„ íƒ
if len(tst_dataset.df[0]) == 3:
    # augmentation_multiplier > 1ì¸ ê²½ìš°: (name, target, aug_idx)
    pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target', 'aug_idx'])
    pred_df = pred_df[['ID', 'target']]  # aug_idx ì»¬ëŸ¼ ì œê±°
else:
    # augmentation_multiplier == 1ì¸ ê²½ìš°: (name, target)
    pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])

pred_df['target'] = final_predictions

sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
assert (sample_submission_df['ID'] == pred_df['ID']).all()

output_path = "./output"
os.makedirs(output_path, exist_ok=True)
pred_df.to_csv(f"{output_path}/pred_advanced_kfold_tta2_efnv2rwm_v3_augx2_saveimg_seed_ensemble.csv", index=False)

log.info(f"\nâœ… Ensemble prediction completed and saved to {output_path}/pred_advanced_kfold_tta2_efnv2rwm_v3_augx2_saveimg_seed_ensemble.csv")
log.info(f"ğŸ“ˆ Final Overall CV Score: {overall_mean_score:.4f} Â± {overall_std_score:.4f}")
log.info(f"ğŸ¯ Used {len(all_model_paths)} models for ensemble prediction")
log.info(f"ğŸ’¾ All model files saved in: {models_dir}")
log.info(f"ğŸ¨ Augmented images cached in: {os.path.join(data_path, 'train_cache')}")

# ìºì‹œ í†µê³„ ì¶œë ¥
log.info(f"\nğŸ“Š Final Cache Statistics:")
train_cache_path = os.path.join(data_path, 'train_cache')
if os.path.exists(train_cache_path):
    # ìƒˆë¡œìš´ ë””ë ‰í† ë¦¬ëª… íŒ¨í„´: img{img_size}_seed{seed}
    cache_dir_pattern = f'img{img_size}_seed'
    total_cache_dirs = len([d for d in os.listdir(train_cache_path) if d.startswith(cache_dir_pattern)])
    log.info(f"   Total seed cache directories: {total_cache_dirs}")
    for seed in SEEDS:
        seed_cache_dir = os.path.join(train_cache_path, f'img{img_size}_seed{seed}')
        if os.path.exists(seed_cache_dir):
            cache_files = len([f for f in os.listdir(seed_cache_dir) if f.endswith('.jpg')])
            log.info(f"   Seed {seed} cached images: {cache_files}")
        else:
            log.info(f"   Seed {seed} cache directory not found: {seed_cache_dir}")
else:
    log.info(f"   Train cache directory not found: {train_cache_path}")

# ë©”ëª¨ë¦¬ ì •ë¦¬
torch.cuda.empty_cache()
gc.collect()

pred_df.head() 