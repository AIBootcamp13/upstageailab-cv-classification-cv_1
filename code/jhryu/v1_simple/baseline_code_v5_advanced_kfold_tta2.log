[25-07-03 17:26:28] [INFO] 완전한 재현성 설정이 활성화되었습니다.
[25-07-03 17:26:28] [INFO] 🌱 Random seed set to 42
[25-07-03 17:26:28] [INFO] 💻 Using device: cuda
[25-07-03 17:26:28] [INFO] 📂 Total training samples: 1570
[25-07-03 17:26:28] [INFO] 📊 Class distribution: {0: 100, 1: 46, 2: 100, 3: 100, 4: 100, 5: 100, 6: 100, 7: 100, 8: 100, 9: 100, 10: 100, 11: 100, 12: 100, 13: 74, 14: 50, 15: 100, 16: 100}
[25-07-03 17:26:28] [INFO] 
🔄 Starting 5-Fold Cross Validation Training...
[25-07-03 17:26:28] [INFO] 
============================================================
[25-07-03 17:26:28] [INFO] 🔥 FOLD 1/5
[25-07-03 17:26:28] [INFO] ============================================================
[25-07-03 17:26:28] [INFO] 📚 Train samples: 1256
[25-07-03 17:26:28] [INFO] 📝 Validation samples: 314
[25-07-03 17:26:29] [INFO] 🏗️ Model: efficientnet_b3
[25-07-03 17:26:29] [INFO] 🔢 Number of parameters: 10,722,361
[25-07-03 17:26:29] [INFO] 🚀 Starting Fold 1 training...
[25-07-03 17:26:29] [INFO] 
--- Fold 1 | Epoch 1/20 ---
[25-07-03 17:27:09] [INFO] 💾 Fold 1 Best model updated! F1: 0.7892
[25-07-03 17:27:09] [INFO] train_loss: 2.0142 | train_acc: 0.4920 | train_f1: 0.4581 | val_loss: 1.2604 | val_acc: 0.8248 | val_f1: 0.7892 | lr: 0.000199
[25-07-03 17:27:09] [INFO] 
--- Fold 1 | Epoch 2/20 ---
[25-07-03 17:27:42] [INFO] 💾 Fold 1 Best model updated! F1: 0.8459
[25-07-03 17:27:42] [INFO] train_loss: 1.1954 | train_acc: 0.7818 | train_f1: 0.7623 | val_loss: 1.0682 | val_acc: 0.8726 | val_f1: 0.8459 | lr: 0.000195
[25-07-03 17:27:42] [INFO] 
--- Fold 1 | Epoch 3/20 ---
[25-07-03 17:28:22] [INFO] 💾 Fold 1 Best model updated! F1: 0.8510
[25-07-03 17:28:22] [INFO] train_loss: 1.0348 | train_acc: 0.8575 | train_f1: 0.8407 | val_loss: 0.9751 | val_acc: 0.8822 | val_f1: 0.8510 | lr: 0.000189
[25-07-03 17:28:22] [INFO] 
--- Fold 1 | Epoch 4/20 ---
[25-07-03 17:29:04] [INFO] 💾 Fold 1 Best model updated! F1: 0.8662
[25-07-03 17:29:04] [INFO] train_loss: 0.9448 | train_acc: 0.8909 | train_f1: 0.8748 | val_loss: 0.9517 | val_acc: 0.8854 | val_f1: 0.8662 | lr: 0.000181
[25-07-03 17:29:04] [INFO] 
--- Fold 1 | Epoch 5/20 ---
[25-07-03 17:29:40] [INFO] 💾 Fold 1 Best model updated! F1: 0.8722
[25-07-03 17:29:40] [INFO] train_loss: 0.8924 | train_acc: 0.9061 | train_f1: 0.8981 | val_loss: 0.9285 | val_acc: 0.8981 | val_f1: 0.8722 | lr: 0.000171
[25-07-03 17:29:40] [INFO] 
--- Fold 1 | Epoch 6/20 ---
[25-07-03 17:30:27] [INFO] 💾 Fold 1 Best model updated! F1: 0.8849
[25-07-03 17:30:27] [INFO] train_loss: 0.8526 | train_acc: 0.9196 | train_f1: 0.9100 | val_loss: 0.9182 | val_acc: 0.9013 | val_f1: 0.8849 | lr: 0.000159
[25-07-03 17:30:27] [INFO] 
--- Fold 1 | Epoch 7/20 ---
[25-07-03 17:31:09] [INFO] 💾 Fold 1 Best model updated! F1: 0.8876
[25-07-03 17:31:09] [INFO] train_loss: 0.8504 | train_acc: 0.9275 | train_f1: 0.9214 | val_loss: 0.9055 | val_acc: 0.9013 | val_f1: 0.8876 | lr: 0.000146
[25-07-03 17:31:09] [INFO] 
--- Fold 1 | Epoch 8/20 ---
[25-07-03 17:31:43] [INFO] 💾 Fold 1 Best model updated! F1: 0.8880
[25-07-03 17:31:43] [INFO] train_loss: 0.8168 | train_acc: 0.9379 | train_f1: 0.9352 | val_loss: 0.8909 | val_acc: 0.9045 | val_f1: 0.8880 | lr: 0.000131
[25-07-03 17:31:43] [INFO] 
--- Fold 1 | Epoch 9/20 ---
[25-07-03 17:32:41] [INFO] 💾 Fold 1 Best model updated! F1: 0.8951
[25-07-03 17:32:41] [INFO] train_loss: 0.7728 | train_acc: 0.9586 | train_f1: 0.9543 | val_loss: 0.8909 | val_acc: 0.9076 | val_f1: 0.8951 | lr: 0.000116
[25-07-03 17:32:41] [INFO] 
--- Fold 1 | Epoch 10/20 ---
[25-07-03 17:33:37] [INFO] 💾 Fold 1 Best model updated! F1: 0.8995
[25-07-03 17:33:37] [INFO] train_loss: 0.7642 | train_acc: 0.9594 | train_f1: 0.9554 | val_loss: 0.8764 | val_acc: 0.9076 | val_f1: 0.8995 | lr: 0.000101
[25-07-03 17:33:37] [INFO] 
--- Fold 1 | Epoch 11/20 ---
[25-07-03 17:34:26] [INFO] 💾 Fold 1 Best model updated! F1: 0.9001
[25-07-03 17:34:26] [INFO] train_loss: 0.7492 | train_acc: 0.9626 | train_f1: 0.9581 | val_loss: 0.8758 | val_acc: 0.9108 | val_f1: 0.9001 | lr: 0.000085
[25-07-03 17:34:26] [INFO] 
--- Fold 1 | Epoch 12/20 ---
[25-07-03 17:35:04] [INFO] train_loss: 0.7275 | train_acc: 0.9769 | train_f1: 0.9749 | val_loss: 0.8808 | val_acc: 0.9076 | val_f1: 0.8933 | lr: 0.000070
[25-07-03 17:35:04] [INFO] 
--- Fold 1 | Epoch 13/20 ---
[25-07-03 17:35:37] [INFO] train_loss: 0.7276 | train_acc: 0.9689 | train_f1: 0.9686 | val_loss: 0.8672 | val_acc: 0.9108 | val_f1: 0.8954 | lr: 0.000055
[25-07-03 17:35:37] [INFO] 
--- Fold 1 | Epoch 14/20 ---
[25-07-03 17:36:15] [INFO] 💾 Fold 1 Best model updated! F1: 0.9075
[25-07-03 17:36:15] [INFO] train_loss: 0.7179 | train_acc: 0.9801 | train_f1: 0.9782 | val_loss: 0.8677 | val_acc: 0.9140 | val_f1: 0.9075 | lr: 0.000042
[25-07-03 17:36:15] [INFO] 
--- Fold 1 | Epoch 15/20 ---
[25-07-03 17:36:48] [INFO] train_loss: 0.7057 | train_acc: 0.9833 | train_f1: 0.9809 | val_loss: 0.8788 | val_acc: 0.9076 | val_f1: 0.8986 | lr: 0.000030
[25-07-03 17:36:48] [INFO] 
--- Fold 1 | Epoch 16/20 ---
[25-07-03 17:37:27] [INFO] 💾 Fold 1 Best model updated! F1: 0.9094
[25-07-03 17:37:27] [INFO] train_loss: 0.7114 | train_acc: 0.9817 | train_f1: 0.9808 | val_loss: 0.8627 | val_acc: 0.9172 | val_f1: 0.9094 | lr: 0.000020
[25-07-03 17:37:27] [INFO] 
--- Fold 1 | Epoch 17/20 ---
[25-07-03 17:38:05] [INFO] train_loss: 0.7071 | train_acc: 0.9849 | train_f1: 0.9841 | val_loss: 0.8720 | val_acc: 0.9076 | val_f1: 0.8989 | lr: 0.000012
[25-07-03 17:38:05] [INFO] 
--- Fold 1 | Epoch 18/20 ---
[25-07-03 17:38:38] [INFO] train_loss: 0.7031 | train_acc: 0.9825 | train_f1: 0.9809 | val_loss: 0.8637 | val_acc: 0.9108 | val_f1: 0.9040 | lr: 0.000006
[25-07-03 17:38:38] [INFO] 
--- Fold 1 | Epoch 19/20 ---
[25-07-03 17:39:16] [INFO] train_loss: 0.7066 | train_acc: 0.9841 | train_f1: 0.9821 | val_loss: 0.8558 | val_acc: 0.9076 | val_f1: 0.9014 | lr: 0.000002
[25-07-03 17:39:16] [INFO] 
--- Fold 1 | Epoch 20/20 ---
[25-07-03 17:39:51] [INFO] train_loss: 0.7014 | train_acc: 0.9833 | train_f1: 0.9817 | val_loss: 0.8580 | val_acc: 0.9108 | val_f1: 0.9043 | lr: 0.000001
[25-07-03 17:39:51] [INFO] 
🎯 Fold 1 completed! Best F1: 0.9094
[25-07-03 17:39:51] [INFO] 
============================================================
[25-07-03 17:39:51] [INFO] 🔥 FOLD 2/5
[25-07-03 17:39:51] [INFO] ============================================================
[25-07-03 17:39:51] [INFO] 📚 Train samples: 1256
[25-07-03 17:39:51] [INFO] 📝 Validation samples: 314
[25-07-03 17:39:52] [INFO] 🏗️ Model: efficientnet_b3
[25-07-03 17:39:52] [INFO] 🔢 Number of parameters: 10,722,361
[25-07-03 17:39:52] [INFO] 🚀 Starting Fold 2 training...
[25-07-03 17:39:52] [INFO] 
--- Fold 2 | Epoch 1/20 ---
[25-07-03 17:40:29] [INFO] 💾 Fold 2 Best model updated! F1: 0.7758
[25-07-03 17:40:29] [INFO] train_loss: 2.0380 | train_acc: 0.5000 | train_f1: 0.4701 | val_loss: 1.2088 | val_acc: 0.8185 | val_f1: 0.7758 | lr: 0.000199
[25-07-03 17:40:29] [INFO] 
--- Fold 2 | Epoch 2/20 ---
[25-07-03 17:41:08] [INFO] 💾 Fold 2 Best model updated! F1: 0.8620
[25-07-03 17:41:08] [INFO] train_loss: 1.2164 | train_acc: 0.7779 | train_f1: 0.7574 | val_loss: 1.0295 | val_acc: 0.8758 | val_f1: 0.8620 | lr: 0.000195
[25-07-03 17:41:08] [INFO] 
--- Fold 2 | Epoch 3/20 ---
[25-07-03 17:41:41] [INFO] 💾 Fold 2 Best model updated! F1: 0.8702
[25-07-03 17:41:41] [INFO] train_loss: 1.0329 | train_acc: 0.8479 | train_f1: 0.8320 | val_loss: 0.9905 | val_acc: 0.8758 | val_f1: 0.8702 | lr: 0.000189
[25-07-03 17:41:41] [INFO] 
--- Fold 2 | Epoch 4/20 ---
[25-07-03 17:42:21] [INFO] 💾 Fold 2 Best model updated! F1: 0.8820
[25-07-03 17:42:21] [INFO] train_loss: 0.9284 | train_acc: 0.8917 | train_f1: 0.8803 | val_loss: 0.9716 | val_acc: 0.8917 | val_f1: 0.8820 | lr: 0.000181
[25-07-03 17:42:21] [INFO] 
--- Fold 2 | Epoch 5/20 ---
[25-07-03 17:43:01] [INFO] 💾 Fold 2 Best model updated! F1: 0.9131
[25-07-03 17:43:01] [INFO] train_loss: 0.8995 | train_acc: 0.9029 | train_f1: 0.8926 | val_loss: 0.8961 | val_acc: 0.9172 | val_f1: 0.9131 | lr: 0.000171
[25-07-03 17:43:01] [INFO] 
--- Fold 2 | Epoch 6/20 ---
[25-07-03 17:43:37] [INFO] 💾 Fold 2 Best model updated! F1: 0.9166
[25-07-03 17:43:37] [INFO] train_loss: 0.8417 | train_acc: 0.9339 | train_f1: 0.9253 | val_loss: 0.8869 | val_acc: 0.9172 | val_f1: 0.9166 | lr: 0.000159
[25-07-03 17:43:37] [INFO] 
--- Fold 2 | Epoch 7/20 ---
[25-07-03 17:44:20] [INFO] train_loss: 0.8201 | train_acc: 0.9339 | train_f1: 0.9287 | val_loss: 0.8897 | val_acc: 0.9108 | val_f1: 0.9016 | lr: 0.000146
[25-07-03 17:44:20] [INFO] 
--- Fold 2 | Epoch 8/20 ---
[25-07-03 17:45:04] [INFO] train_loss: 0.7853 | train_acc: 0.9459 | train_f1: 0.9436 | val_loss: 0.8809 | val_acc: 0.9076 | val_f1: 0.9044 | lr: 0.000131
[25-07-03 17:45:04] [INFO] 
--- Fold 2 | Epoch 9/20 ---
[25-07-03 17:45:39] [INFO] train_loss: 0.7807 | train_acc: 0.9570 | train_f1: 0.9531 | val_loss: 0.8566 | val_acc: 0.9108 | val_f1: 0.9049 | lr: 0.000116
[25-07-03 17:45:39] [INFO] 
--- Fold 2 | Epoch 10/20 ---
[25-07-03 17:46:24] [INFO] train_loss: 0.7497 | train_acc: 0.9666 | train_f1: 0.9626 | val_loss: 0.8613 | val_acc: 0.9204 | val_f1: 0.9157 | lr: 0.000101
[25-07-03 17:46:24] [INFO] 
--- Fold 2 | Epoch 11/20 ---
[25-07-03 17:47:08] [INFO] train_loss: 0.7509 | train_acc: 0.9650 | train_f1: 0.9625 | val_loss: 0.8582 | val_acc: 0.9108 | val_f1: 0.9072 | lr: 0.000085
[25-07-03 17:47:08] [INFO] 
--- Fold 2 | Epoch 12/20 ---
[25-07-03 17:47:43] [INFO] train_loss: 0.7322 | train_acc: 0.9618 | train_f1: 0.9588 | val_loss: 0.8459 | val_acc: 0.9204 | val_f1: 0.9157 | lr: 0.000070
[25-07-03 17:47:43] [INFO] 
--- Fold 2 | Epoch 13/20 ---
[25-07-03 17:48:26] [INFO] 💾 Fold 2 Best model updated! F1: 0.9188
[25-07-03 17:48:26] [INFO] train_loss: 0.7227 | train_acc: 0.9809 | train_f1: 0.9803 | val_loss: 0.8443 | val_acc: 0.9204 | val_f1: 0.9188 | lr: 0.000055
[25-07-03 17:48:26] [INFO] 
--- Fold 2 | Epoch 14/20 ---
[25-07-03 17:49:08] [INFO] train_loss: 0.7144 | train_acc: 0.9769 | train_f1: 0.9765 | val_loss: 0.8440 | val_acc: 0.9204 | val_f1: 0.9171 | lr: 0.000042
[25-07-03 17:49:08] [INFO] 
--- Fold 2 | Epoch 15/20 ---
[25-07-03 17:49:50] [INFO] train_loss: 0.7091 | train_acc: 0.9785 | train_f1: 0.9782 | val_loss: 0.8498 | val_acc: 0.9172 | val_f1: 0.9129 | lr: 0.000030
[25-07-03 17:49:50] [INFO] 
--- Fold 2 | Epoch 16/20 ---
[25-07-03 17:50:33] [INFO] train_loss: 0.7053 | train_acc: 0.9857 | train_f1: 0.9845 | val_loss: 0.8503 | val_acc: 0.9172 | val_f1: 0.9164 | lr: 0.000020
[25-07-03 17:50:33] [INFO] 
--- Fold 2 | Epoch 17/20 ---
[25-07-03 17:51:13] [INFO] train_loss: 0.7039 | train_acc: 0.9873 | train_f1: 0.9871 | val_loss: 0.8558 | val_acc: 0.9172 | val_f1: 0.9121 | lr: 0.000012
[25-07-03 17:51:13] [INFO] 
--- Fold 2 | Epoch 18/20 ---
[25-07-03 17:51:46] [INFO] train_loss: 0.7062 | train_acc: 0.9825 | train_f1: 0.9806 | val_loss: 0.8524 | val_acc: 0.9172 | val_f1: 0.9151 | lr: 0.000006
[25-07-03 17:51:46] [INFO] 
--- Fold 2 | Epoch 19/20 ---
[25-07-03 17:52:27] [INFO] train_loss: 0.6984 | train_acc: 0.9881 | train_f1: 0.9862 | val_loss: 0.8523 | val_acc: 0.9204 | val_f1: 0.9154 | lr: 0.000002
[25-07-03 17:52:27] [INFO] 
--- Fold 2 | Epoch 20/20 ---
[25-07-03 17:53:08] [INFO] train_loss: 0.6945 | train_acc: 0.9881 | train_f1: 0.9879 | val_loss: 0.8570 | val_acc: 0.9108 | val_f1: 0.9041 | lr: 0.000001
[25-07-03 17:53:08] [INFO] 
🎯 Fold 2 completed! Best F1: 0.9188
[25-07-03 17:53:08] [INFO] 
============================================================
[25-07-03 17:53:08] [INFO] 🔥 FOLD 3/5
[25-07-03 17:53:08] [INFO] ============================================================
[25-07-03 17:53:08] [INFO] 📚 Train samples: 1256
[25-07-03 17:53:08] [INFO] 📝 Validation samples: 314
[25-07-03 17:53:09] [INFO] 🏗️ Model: efficientnet_b3
[25-07-03 17:53:09] [INFO] 🔢 Number of parameters: 10,722,361
[25-07-03 17:53:09] [INFO] 🚀 Starting Fold 3 training...
[25-07-03 17:53:09] [INFO] 
--- Fold 3 | Epoch 1/20 ---
[25-07-03 17:53:42] [INFO] 💾 Fold 3 Best model updated! F1: 0.7880
[25-07-03 17:53:42] [INFO] train_loss: 2.0206 | train_acc: 0.5056 | train_f1: 0.4756 | val_loss: 1.2060 | val_acc: 0.8248 | val_f1: 0.7880 | lr: 0.000199
[25-07-03 17:53:42] [INFO] 
--- Fold 3 | Epoch 2/20 ---
[25-07-03 17:54:24] [INFO] 💾 Fold 3 Best model updated! F1: 0.8460
[25-07-03 17:54:24] [INFO] train_loss: 1.1969 | train_acc: 0.7866 | train_f1: 0.7625 | val_loss: 1.0429 | val_acc: 0.8567 | val_f1: 0.8460 | lr: 0.000195
[25-07-03 17:54:24] [INFO] 
--- Fold 3 | Epoch 3/20 ---
[25-07-03 17:55:04] [INFO] 💾 Fold 3 Best model updated! F1: 0.8618
[25-07-03 17:55:04] [INFO] train_loss: 1.0392 | train_acc: 0.8503 | train_f1: 0.8318 | val_loss: 0.9576 | val_acc: 0.8854 | val_f1: 0.8618 | lr: 0.000189
[25-07-03 17:55:04] [INFO] 
--- Fold 3 | Epoch 4/20 ---
[25-07-03 17:55:37] [INFO] 💾 Fold 3 Best model updated! F1: 0.8802
[25-07-03 17:55:37] [INFO] train_loss: 0.9690 | train_acc: 0.8702 | train_f1: 0.8599 | val_loss: 0.9129 | val_acc: 0.8949 | val_f1: 0.8802 | lr: 0.000181
[25-07-03 17:55:37] [INFO] 
--- Fold 3 | Epoch 5/20 ---
[25-07-03 17:56:15] [INFO] 💾 Fold 3 Best model updated! F1: 0.8854
[25-07-03 17:56:15] [INFO] train_loss: 0.9087 | train_acc: 0.8989 | train_f1: 0.8860 | val_loss: 0.8729 | val_acc: 0.8949 | val_f1: 0.8854 | lr: 0.000171
[25-07-03 17:56:15] [INFO] 
--- Fold 3 | Epoch 6/20 ---
[25-07-03 17:56:50] [INFO] train_loss: 0.8614 | train_acc: 0.9212 | train_f1: 0.9117 | val_loss: 0.8787 | val_acc: 0.9076 | val_f1: 0.8772 | lr: 0.000159
[25-07-03 17:56:50] [INFO] 
--- Fold 3 | Epoch 7/20 ---
[25-07-03 17:57:29] [INFO] 💾 Fold 3 Best model updated! F1: 0.9029
[25-07-03 17:57:29] [INFO] train_loss: 0.8387 | train_acc: 0.9275 | train_f1: 0.9199 | val_loss: 0.8613 | val_acc: 0.9204 | val_f1: 0.9029 | lr: 0.000146
[25-07-03 17:57:29] [INFO] 
--- Fold 3 | Epoch 8/20 ---
[25-07-03 17:58:07] [INFO] 💾 Fold 3 Best model updated! F1: 0.9182
[25-07-03 17:58:07] [INFO] train_loss: 0.8098 | train_acc: 0.9411 | train_f1: 0.9374 | val_loss: 0.8423 | val_acc: 0.9268 | val_f1: 0.9182 | lr: 0.000131
[25-07-03 17:58:07] [INFO] 
--- Fold 3 | Epoch 9/20 ---
[25-07-03 17:58:39] [INFO] train_loss: 0.7839 | train_acc: 0.9435 | train_f1: 0.9396 | val_loss: 0.8350 | val_acc: 0.9236 | val_f1: 0.9127 | lr: 0.000116
[25-07-03 17:58:39] [INFO] 
--- Fold 3 | Epoch 10/20 ---
[25-07-03 17:59:18] [INFO] train_loss: 0.7526 | train_acc: 0.9658 | train_f1: 0.9602 | val_loss: 0.8515 | val_acc: 0.9268 | val_f1: 0.9114 | lr: 0.000101
[25-07-03 17:59:18] [INFO] 
--- Fold 3 | Epoch 11/20 ---
[25-07-03 17:59:56] [INFO] train_loss: 0.7433 | train_acc: 0.9666 | train_f1: 0.9642 | val_loss: 0.8362 | val_acc: 0.9108 | val_f1: 0.8781 | lr: 0.000085
[25-07-03 17:59:56] [INFO] 
--- Fold 3 | Epoch 12/20 ---
[25-07-03 18:00:29] [INFO] train_loss: 0.7507 | train_acc: 0.9626 | train_f1: 0.9593 | val_loss: 0.8328 | val_acc: 0.9076 | val_f1: 0.8899 | lr: 0.000070
[25-07-03 18:00:29] [INFO] 
--- Fold 3 | Epoch 13/20 ---
[25-07-03 18:01:08] [INFO] train_loss: 0.7282 | train_acc: 0.9745 | train_f1: 0.9728 | val_loss: 0.8375 | val_acc: 0.9299 | val_f1: 0.9150 | lr: 0.000055
[25-07-03 18:01:08] [INFO] 
--- Fold 3 | Epoch 14/20 ---
[25-07-03 18:01:42] [INFO] train_loss: 0.7290 | train_acc: 0.9737 | train_f1: 0.9715 | val_loss: 0.8389 | val_acc: 0.9204 | val_f1: 0.8985 | lr: 0.000042
[25-07-03 18:01:42] [INFO] 
--- Fold 3 | Epoch 15/20 ---
[25-07-03 18:02:22] [INFO] train_loss: 0.7109 | train_acc: 0.9777 | train_f1: 0.9776 | val_loss: 0.8314 | val_acc: 0.9204 | val_f1: 0.9070 | lr: 0.000030
[25-07-03 18:02:22] [INFO] 
--- Fold 3 | Epoch 16/20 ---
[25-07-03 18:03:01] [INFO] train_loss: 0.7042 | train_acc: 0.9825 | train_f1: 0.9817 | val_loss: 0.8275 | val_acc: 0.9204 | val_f1: 0.9069 | lr: 0.000020
[25-07-03 18:03:01] [INFO] 
--- Fold 3 | Epoch 17/20 ---
[25-07-03 18:03:34] [INFO] train_loss: 0.7115 | train_acc: 0.9769 | train_f1: 0.9763 | val_loss: 0.8283 | val_acc: 0.9299 | val_f1: 0.9150 | lr: 0.000012
[25-07-03 18:03:34] [INFO] 
--- Fold 3 | Epoch 18/20 ---
[25-07-03 18:04:12] [INFO] train_loss: 0.7047 | train_acc: 0.9825 | train_f1: 0.9821 | val_loss: 0.8199 | val_acc: 0.9268 | val_f1: 0.9167 | lr: 0.000006
[25-07-03 18:04:12] [INFO] 
--- Fold 3 | Epoch 19/20 ---
[25-07-03 18:04:45] [INFO] train_loss: 0.7024 | train_acc: 0.9849 | train_f1: 0.9836 | val_loss: 0.8275 | val_acc: 0.9268 | val_f1: 0.9137 | lr: 0.000002
[25-07-03 18:04:45] [INFO] 
--- Fold 3 | Epoch 20/20 ---
[25-07-03 18:05:29] [INFO] train_loss: 0.6965 | train_acc: 0.9833 | train_f1: 0.9829 | val_loss: 0.8253 | val_acc: 0.9204 | val_f1: 0.9066 | lr: 0.000001
[25-07-03 18:05:29] [INFO] 
🎯 Fold 3 completed! Best F1: 0.9182
[25-07-03 18:05:29] [INFO] 
============================================================
[25-07-03 18:05:29] [INFO] 🔥 FOLD 4/5
[25-07-03 18:05:29] [INFO] ============================================================
[25-07-03 18:05:29] [INFO] 📚 Train samples: 1256
[25-07-03 18:05:29] [INFO] 📝 Validation samples: 314
[25-07-03 18:05:30] [INFO] 🏗️ Model: efficientnet_b3
[25-07-03 18:05:30] [INFO] 🔢 Number of parameters: 10,722,361
[25-07-03 18:05:30] [INFO] 🚀 Starting Fold 4 training...
[25-07-03 18:05:30] [INFO] 
--- Fold 4 | Epoch 1/20 ---
[25-07-03 18:06:13] [INFO] 💾 Fold 4 Best model updated! F1: 0.7515
[25-07-03 18:06:13] [INFO] train_loss: 2.1016 | train_acc: 0.4721 | train_f1: 0.4492 | val_loss: 1.2874 | val_acc: 0.7834 | val_f1: 0.7515 | lr: 0.000199
[25-07-03 18:06:13] [INFO] 
--- Fold 4 | Epoch 2/20 ---
[25-07-03 18:06:46] [INFO] 💾 Fold 4 Best model updated! F1: 0.8111
[25-07-03 18:06:46] [INFO] train_loss: 1.1933 | train_acc: 0.7978 | train_f1: 0.7789 | val_loss: 1.1331 | val_acc: 0.8344 | val_f1: 0.8111 | lr: 0.000195
[25-07-03 18:06:46] [INFO] 
--- Fold 4 | Epoch 3/20 ---
[25-07-03 18:07:31] [INFO] 💾 Fold 4 Best model updated! F1: 0.8381
[25-07-03 18:07:31] [INFO] train_loss: 1.0350 | train_acc: 0.8455 | train_f1: 0.8266 | val_loss: 1.0126 | val_acc: 0.8694 | val_f1: 0.8381 | lr: 0.000189
[25-07-03 18:07:31] [INFO] 
--- Fold 4 | Epoch 4/20 ---
[25-07-03 18:08:08] [INFO] 💾 Fold 4 Best model updated! F1: 0.8611
[25-07-03 18:08:08] [INFO] train_loss: 0.9531 | train_acc: 0.8893 | train_f1: 0.8732 | val_loss: 0.9734 | val_acc: 0.8885 | val_f1: 0.8611 | lr: 0.000181
[25-07-03 18:08:08] [INFO] 
--- Fold 4 | Epoch 5/20 ---
[25-07-03 18:08:41] [INFO] 💾 Fold 4 Best model updated! F1: 0.8869
[25-07-03 18:08:41] [INFO] train_loss: 0.8874 | train_acc: 0.9100 | train_f1: 0.9000 | val_loss: 0.9503 | val_acc: 0.8981 | val_f1: 0.8869 | lr: 0.000171
[25-07-03 18:08:41] [INFO] 
--- Fold 4 | Epoch 6/20 ---
[25-07-03 18:09:21] [INFO] train_loss: 0.8666 | train_acc: 0.9228 | train_f1: 0.9164 | val_loss: 0.9399 | val_acc: 0.8917 | val_f1: 0.8724 | lr: 0.000159
[25-07-03 18:09:21] [INFO] 
--- Fold 4 | Epoch 7/20 ---
[25-07-03 18:10:01] [INFO] train_loss: 0.8320 | train_acc: 0.9331 | train_f1: 0.9256 | val_loss: 0.9139 | val_acc: 0.8854 | val_f1: 0.8654 | lr: 0.000146
[25-07-03 18:10:01] [INFO] 
--- Fold 4 | Epoch 8/20 ---
[25-07-03 18:10:34] [INFO] train_loss: 0.8024 | train_acc: 0.9475 | train_f1: 0.9410 | val_loss: 0.8952 | val_acc: 0.8981 | val_f1: 0.8862 | lr: 0.000131
[25-07-03 18:10:34] [INFO] 
--- Fold 4 | Epoch 9/20 ---
[25-07-03 18:11:11] [INFO] train_loss: 0.8015 | train_acc: 0.9435 | train_f1: 0.9377 | val_loss: 0.8955 | val_acc: 0.8981 | val_f1: 0.8866 | lr: 0.000116
[25-07-03 18:11:11] [INFO] 
--- Fold 4 | Epoch 10/20 ---
[25-07-03 18:11:47] [INFO] 💾 Fold 4 Best model updated! F1: 0.8937
[25-07-03 18:11:47] [INFO] train_loss: 0.7786 | train_acc: 0.9482 | train_f1: 0.9424 | val_loss: 0.8983 | val_acc: 0.9045 | val_f1: 0.8937 | lr: 0.000101
[25-07-03 18:11:47] [INFO] 
--- Fold 4 | Epoch 11/20 ---
[25-07-03 18:12:34] [INFO] train_loss: 0.7503 | train_acc: 0.9634 | train_f1: 0.9607 | val_loss: 0.8904 | val_acc: 0.8981 | val_f1: 0.8835 | lr: 0.000085
[25-07-03 18:12:34] [INFO] 
--- Fold 4 | Epoch 12/20 ---
[25-07-03 18:13:16] [INFO] train_loss: 0.7489 | train_acc: 0.9697 | train_f1: 0.9662 | val_loss: 0.8932 | val_acc: 0.9013 | val_f1: 0.8884 | lr: 0.000070
[25-07-03 18:13:16] [INFO] 
--- Fold 4 | Epoch 13/20 ---
[25-07-03 18:13:52] [INFO] 💾 Fold 4 Best model updated! F1: 0.8949
[25-07-03 18:13:52] [INFO] train_loss: 0.7343 | train_acc: 0.9721 | train_f1: 0.9707 | val_loss: 0.8863 | val_acc: 0.9045 | val_f1: 0.8949 | lr: 0.000055
[25-07-03 18:13:52] [INFO] 
--- Fold 4 | Epoch 14/20 ---
[25-07-03 18:14:38] [INFO] train_loss: 0.7317 | train_acc: 0.9713 | train_f1: 0.9656 | val_loss: 0.8807 | val_acc: 0.9013 | val_f1: 0.8904 | lr: 0.000042
[25-07-03 18:14:38] [INFO] 
--- Fold 4 | Epoch 15/20 ---
[25-07-03 18:15:20] [INFO] 💾 Fold 4 Best model updated! F1: 0.9013
[25-07-03 18:15:20] [INFO] train_loss: 0.7277 | train_acc: 0.9713 | train_f1: 0.9692 | val_loss: 0.8798 | val_acc: 0.9108 | val_f1: 0.9013 | lr: 0.000030
[25-07-03 18:15:20] [INFO] 
--- Fold 4 | Epoch 16/20 ---
[25-07-03 18:16:02] [INFO] train_loss: 0.7175 | train_acc: 0.9785 | train_f1: 0.9757 | val_loss: 0.8866 | val_acc: 0.9045 | val_f1: 0.8923 | lr: 0.000020
[25-07-03 18:16:02] [INFO] 
--- Fold 4 | Epoch 17/20 ---
[25-07-03 18:16:46] [INFO] train_loss: 0.7120 | train_acc: 0.9809 | train_f1: 0.9789 | val_loss: 0.8783 | val_acc: 0.9013 | val_f1: 0.8883 | lr: 0.000012
[25-07-03 18:16:46] [INFO] 
--- Fold 4 | Epoch 18/20 ---
[25-07-03 18:17:45] [INFO] train_loss: 0.7180 | train_acc: 0.9809 | train_f1: 0.9785 | val_loss: 0.8786 | val_acc: 0.9013 | val_f1: 0.8898 | lr: 0.000006
[25-07-03 18:17:45] [INFO] 
--- Fold 4 | Epoch 19/20 ---
[25-07-03 18:18:42] [INFO] train_loss: 0.7044 | train_acc: 0.9817 | train_f1: 0.9804 | val_loss: 0.8783 | val_acc: 0.9045 | val_f1: 0.8957 | lr: 0.000002
[25-07-03 18:18:42] [INFO] 
--- Fold 4 | Epoch 20/20 ---
[25-07-03 18:20:28] [INFO] 💾 Fold 4 Best model updated! F1: 0.9019
[25-07-03 18:20:28] [INFO] train_loss: 0.7093 | train_acc: 0.9833 | train_f1: 0.9817 | val_loss: 0.8765 | val_acc: 0.9108 | val_f1: 0.9019 | lr: 0.000001
[25-07-03 18:20:28] [INFO] 
🎯 Fold 4 completed! Best F1: 0.9019
[25-07-03 18:20:28] [INFO] 
============================================================
[25-07-03 18:20:28] [INFO] 🔥 FOLD 5/5
[25-07-03 18:20:28] [INFO] ============================================================
[25-07-03 18:20:28] [INFO] 📚 Train samples: 1256
[25-07-03 18:20:28] [INFO] 📝 Validation samples: 314
[25-07-03 18:20:30] [INFO] 🏗️ Model: efficientnet_b3
[25-07-03 18:20:30] [INFO] 🔢 Number of parameters: 10,722,361
[25-07-03 18:20:30] [INFO] 🚀 Starting Fold 5 training...
[25-07-03 18:20:30] [INFO] 
--- Fold 5 | Epoch 1/20 ---
[25-07-03 18:22:23] [INFO] 💾 Fold 5 Best model updated! F1: 0.7825
[25-07-03 18:22:23] [INFO] train_loss: 2.1731 | train_acc: 0.4689 | train_f1: 0.4487 | val_loss: 1.2720 | val_acc: 0.8089 | val_f1: 0.7825 | lr: 0.000199
[25-07-03 18:22:23] [INFO] 
--- Fold 5 | Epoch 2/20 ---
[25-07-03 18:23:14] [INFO] 💾 Fold 5 Best model updated! F1: 0.8253
[25-07-03 18:23:14] [INFO] train_loss: 1.2226 | train_acc: 0.7771 | train_f1: 0.7546 | val_loss: 1.0939 | val_acc: 0.8471 | val_f1: 0.8253 | lr: 0.000195
[25-07-03 18:23:14] [INFO] 
--- Fold 5 | Epoch 3/20 ---
[25-07-03 18:24:06] [INFO] 💾 Fold 5 Best model updated! F1: 0.8420
[25-07-03 18:24:06] [INFO] train_loss: 1.0682 | train_acc: 0.8455 | train_f1: 0.8222 | val_loss: 1.0054 | val_acc: 0.8631 | val_f1: 0.8420 | lr: 0.000189
[25-07-03 18:24:06] [INFO] 
--- Fold 5 | Epoch 4/20 ---
[25-07-03 18:24:49] [INFO] 💾 Fold 5 Best model updated! F1: 0.8592
[25-07-03 18:24:49] [INFO] train_loss: 0.9414 | train_acc: 0.8885 | train_f1: 0.8762 | val_loss: 0.9496 | val_acc: 0.8790 | val_f1: 0.8592 | lr: 0.000181
[25-07-03 18:24:49] [INFO] 
--- Fold 5 | Epoch 5/20 ---
[25-07-03 18:25:41] [INFO] 💾 Fold 5 Best model updated! F1: 0.8882
[25-07-03 18:25:41] [INFO] train_loss: 0.9004 | train_acc: 0.9061 | train_f1: 0.8942 | val_loss: 0.9314 | val_acc: 0.8981 | val_f1: 0.8882 | lr: 0.000171
[25-07-03 18:25:41] [INFO] 
--- Fold 5 | Epoch 6/20 ---
[25-07-03 18:26:46] [INFO] 💾 Fold 5 Best model updated! F1: 0.8897
[25-07-03 18:26:46] [INFO] train_loss: 0.8567 | train_acc: 0.9172 | train_f1: 0.9110 | val_loss: nan | val_acc: 0.8949 | val_f1: 0.8897 | lr: 0.000159
[25-07-03 18:26:46] [INFO] 
--- Fold 5 | Epoch 7/20 ---
[25-07-03 18:28:39] [INFO] train_loss: 0.8250 | train_acc: 0.9339 | train_f1: 0.9294 | val_loss: nan | val_acc: 0.8949 | val_f1: 0.8873 | lr: 0.000146
[25-07-03 18:28:39] [INFO] 
--- Fold 5 | Epoch 8/20 ---
[25-07-03 18:30:38] [INFO] train_loss: 0.7939 | train_acc: 0.9451 | train_f1: 0.9399 | val_loss: nan | val_acc: 0.8885 | val_f1: 0.8805 | lr: 0.000131
[25-07-03 18:30:38] [INFO] 
--- Fold 5 | Epoch 9/20 ---
[25-07-03 18:32:44] [INFO] 💾 Fold 5 Best model updated! F1: 0.8917
[25-07-03 18:32:44] [INFO] train_loss: 0.7774 | train_acc: 0.9522 | train_f1: 0.9506 | val_loss: 0.8864 | val_acc: 0.9045 | val_f1: 0.8917 | lr: 0.000116
[25-07-03 18:32:44] [INFO] 
--- Fold 5 | Epoch 10/20 ---
[25-07-03 18:36:19] [INFO] 💾 Fold 5 Best model updated! F1: 0.8980
[25-07-03 18:36:19] [INFO] train_loss: 0.7530 | train_acc: 0.9674 | train_f1: 0.9633 | val_loss: nan | val_acc: 0.9076 | val_f1: 0.8980 | lr: 0.000101
[25-07-03 18:36:19] [INFO] 
--- Fold 5 | Epoch 11/20 ---
[25-07-03 18:39:08] [INFO] train_loss: 0.7451 | train_acc: 0.9682 | train_f1: 0.9669 | val_loss: nan | val_acc: 0.9013 | val_f1: 0.8922 | lr: 0.000085
[25-07-03 18:39:08] [INFO] 
--- Fold 5 | Epoch 12/20 ---
[25-07-03 18:40:25] [INFO] train_loss: 0.7443 | train_acc: 0.9721 | train_f1: 0.9713 | val_loss: nan | val_acc: 0.9013 | val_f1: 0.8931 | lr: 0.000070
[25-07-03 18:40:25] [INFO] 
--- Fold 5 | Epoch 13/20 ---
[25-07-03 18:41:40] [INFO] 💾 Fold 5 Best model updated! F1: 0.9069
[25-07-03 18:41:40] [INFO] train_loss: 0.7408 | train_acc: 0.9689 | train_f1: 0.9643 | val_loss: nan | val_acc: 0.9140 | val_f1: 0.9069 | lr: 0.000055
[25-07-03 18:41:40] [INFO] 
--- Fold 5 | Epoch 14/20 ---
[25-07-03 18:42:37] [INFO] train_loss: 0.7324 | train_acc: 0.9697 | train_f1: 0.9657 | val_loss: nan | val_acc: 0.9076 | val_f1: 0.8986 | lr: 0.000042
[25-07-03 18:42:37] [INFO] 
--- Fold 5 | Epoch 15/20 ---
[25-07-03 18:43:29] [INFO] train_loss: 0.7183 | train_acc: 0.9753 | train_f1: 0.9745 | val_loss: nan | val_acc: 0.9140 | val_f1: 0.9059 | lr: 0.000030
[25-07-03 18:43:29] [INFO] 
--- Fold 5 | Epoch 16/20 ---
[25-07-03 18:44:26] [INFO] train_loss: 0.7182 | train_acc: 0.9761 | train_f1: 0.9741 | val_loss: nan | val_acc: 0.9045 | val_f1: 0.8947 | lr: 0.000020
[25-07-03 18:44:26] [INFO] 
--- Fold 5 | Epoch 17/20 ---
[25-07-03 18:45:05] [INFO] train_loss: 0.7005 | train_acc: 0.9833 | train_f1: 0.9820 | val_loss: nan | val_acc: 0.9108 | val_f1: 0.9015 | lr: 0.000012
[25-07-03 18:45:05] [INFO] 
--- Fold 5 | Epoch 18/20 ---
[25-07-03 18:45:41] [INFO] train_loss: 0.7062 | train_acc: 0.9809 | train_f1: 0.9794 | val_loss: nan | val_acc: 0.9140 | val_f1: 0.9049 | lr: 0.000006
[25-07-03 18:45:41] [INFO] 
--- Fold 5 | Epoch 19/20 ---
[25-07-03 18:46:27] [INFO] train_loss: 0.6990 | train_acc: 0.9881 | train_f1: 0.9879 | val_loss: nan | val_acc: 0.9076 | val_f1: 0.8972 | lr: 0.000002
[25-07-03 18:46:27] [INFO] 
--- Fold 5 | Epoch 20/20 ---
[25-07-03 18:47:10] [INFO] train_loss: 0.7013 | train_acc: 0.9809 | train_f1: 0.9803 | val_loss: nan | val_acc: 0.9076 | val_f1: 0.8992 | lr: 0.000001
[25-07-03 18:47:10] [INFO] 
🎯 Fold 5 completed! Best F1: 0.9069
[25-07-03 18:47:10] [INFO] 
============================================================
[25-07-03 18:47:10] [INFO] 📊 K-FOLD CROSS VALIDATION RESULTS
[25-07-03 18:47:10] [INFO] ============================================================
[25-07-03 18:47:10] [INFO] 📈 Individual fold scores: ['0.9094', '0.9188', '0.9182', '0.9019', '0.9069']
[25-07-03 18:47:10] [INFO] 🎯 Mean F1 Score: 0.9110
[25-07-03 18:47:10] [INFO] 📏 Standard Deviation: 0.0066
[25-07-03 18:47:10] [INFO] 📊 Score Range: 0.9110 ± 0.0066
[25-07-03 18:47:10] [INFO] ⬇️ Min Score: 0.9019
[25-07-03 18:47:10] [INFO] ⬆️ Max Score: 0.9188
[25-07-03 18:47:10] [INFO] 
🚀 Starting Ensemble Prediction...
[25-07-03 18:47:11] [INFO] ✅ Loaded Fold 1 model
[25-07-03 18:47:11] [INFO] ✅ Loaded Fold 2 model
[25-07-03 18:47:12] [INFO] ✅ Loaded Fold 3 model
[25-07-03 18:47:12] [INFO] ✅ Loaded Fold 4 model
[25-07-03 18:47:13] [INFO] ✅ Loaded Fold 5 model
[25-07-03 18:47:13] [INFO] 
🔮 Running ensemble prediction with 5 models and TTA...
[25-07-03 18:47:13] [INFO] 🔮 Predicting with Fold 1 model...
[25-07-03 18:51:37] [INFO] 🔮 Predicting with Fold 2 model...
[25-07-03 18:55:51] [INFO] 🔮 Predicting with Fold 3 model...
[25-07-03 19:00:02] [INFO] 🔮 Predicting with Fold 4 model...
[25-07-03 19:04:11] [INFO] 🔮 Predicting with Fold 5 model...
[25-07-03 19:08:40] [INFO] 
✅ Ensemble prediction completed and saved to ./output/pred_advanced_kfold_tta2.csv
[25-07-03 19:08:40] [INFO] 📈 Final K-Fold CV Score: 0.9110 ± 0.0066
