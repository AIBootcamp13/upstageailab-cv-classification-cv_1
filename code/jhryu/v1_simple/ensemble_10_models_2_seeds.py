# -*- coding: utf-8 -*-
"""ensemble_10_models_2_seeds.py

5í´ë“œ êµì°¨ê²€ì¦ì„ 2ë²ˆì˜ ë‹¤ë¥¸ ëœë¤ì‹œë“œë¡œ ì‹¤í–‰í•˜ì—¬ ì´ 10ê°œì˜ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ëŠ” ìŠ¤í¬ë¦½íŠ¸.

## Features:
- 2ê°œì˜ ë‹¤ë¥¸ ëœë¤ì‹œë“œë¡œ 5í´ë“œ êµì°¨ê²€ì¦ ì‹¤í–‰
- ì´ 10ê°œì˜ ëª¨ë¸ ìƒì„± (5í´ë“œ Ã— 2ì‹œë“œ)
- ì¦ê°• ì´ë¯¸ì§€ ìºì‹œ ì´ˆê¸°í™”ë¡œ ìƒˆë¡œìš´ ì¦ê°• ì ìš©
- ì•™ìƒë¸” ì¶”ë¡ ìœ¼ë¡œ ìµœì¢… ê²°ê³¼ ìƒì„±

## Contents
- Import Library & Define Functions
- Hyper-parameters
- Multi-Seed K-Fold Cross Validation Training
- Ensemble Inference & Save File
"""

import os
import time
import random
import cv2
import shutil

import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp.autocast_mode import autocast
from torch.cuda.amp.grad_scaler import GradScaler
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import StratifiedKFold
import gc

# ë¡œê·¸ ìœ í‹¸ë¦¬í‹° import
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import utils.log_util as log

# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
def set_seed(seed):
    os.environ['PYTHONHASHSEED'] = str(seed)
    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'
    
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    
    try:
        torch.use_deterministic_algorithms(True)
        log.info("ì™„ì „í•œ ì¬í˜„ì„± ì„¤ì •ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        log.info(f"torch.use_deterministic_algorithms(True) ì„¤ì • ì‹¤íŒ¨: {e}")
        log.info("ê¸°ë³¸ ì¬í˜„ì„± ì„¤ì •ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Label Smoothing Loss í´ë˜ìŠ¤ ì •ì˜
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes, smoothing=0.1):
        super(LabelSmoothingLoss, self).__init__()
        self.smoothing = smoothing
        self.classes = classes
        
    def forward(self, pred, target):
        pred = pred.log_softmax(dim=-1)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.classes - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)
        return torch.mean(torch.sum(-true_dist * pred, dim=-1))

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, csv_data, path, transform=None, cache_images=True, cache_augmented=True):
        if isinstance(csv_data, str):
            self.df = pd.read_csv(csv_data).values
        else:
            self.df = csv_data.values
        self.path = path
        self.transform = transform
        self.cache_images = cache_images
        self.cache_augmented = cache_augmented
        self.image_cache = {} if cache_images else None
        self.augmented_cache = {} if cache_augmented else None
        
        # ìºì‹± í†µê³„
        self.stats = {
            'original_cache_hits': 0,
            'original_cache_misses': 0,
            'augmented_cache_hits': 0,
            'augmented_cache_misses': 0,
            'disk_loads': 0,
            'augmentations': 0
        }

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        
        # ì¦ê°•ëœ ì´ë¯¸ì§€ê°€ ìºì‹œë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
        if self.cache_augmented and self.augmented_cache is not None and name in self.augmented_cache:
            img = self.augmented_cache[name]
            self.stats['augmented_cache_hits'] += 1
        else:
            self.stats['augmented_cache_misses'] += 1
            
            # ì›ë³¸ ì´ë¯¸ì§€ ë¡œë“œ
            if self.cache_images and self.image_cache is not None and name in self.image_cache:
                img = self.image_cache[name]
                self.stats['original_cache_hits'] += 1
            else:
                self.stats['original_cache_misses'] += 1
                img = np.array(Image.open(os.path.join(self.path, name)))
                self.stats['disk_loads'] += 1
                if self.cache_images and self.image_cache is not None:
                    self.image_cache[name] = img
            
            # ì¦ê°• ì ìš©
            if self.transform:
                self.stats['augmentations'] += 1
                img = self.transform(image=img)['image']
                # ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹±
                if self.cache_augmented and self.augmented_cache is not None:
                    self.augmented_cache[name] = img
        
        return img, target
    
    def clear_augmented_cache(self):
        """ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹œë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        if self.augmented_cache is not None:
            self.augmented_cache.clear()
            log.info("ğŸ§¹ ì¦ê°•ëœ ì´ë¯¸ì§€ ìºì‹œê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
    
    def print_stats(self):
        """ìºì‹± í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        current_epoch_requests = self.stats['augmented_cache_hits'] + self.stats['augmented_cache_misses']
        
        if current_epoch_requests > 0:
            log.info(f"ğŸ“Š Dataset Cache Statistics:")
            log.info(f"   Current epoch requests: {current_epoch_requests}")
            log.info(f"   Original cache hits: {self.stats['original_cache_hits']} ({self.stats['original_cache_hits']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Original cache misses: {self.stats['original_cache_misses']} ({self.stats['original_cache_misses']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Augmented cache hits: {self.stats['augmented_cache_hits']} ({self.stats['augmented_cache_hits']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Augmented cache misses: {self.stats['augmented_cache_misses']} ({self.stats['augmented_cache_misses']/current_epoch_requests*100:.1f}%)")
            log.info(f"   Disk loads: {self.stats['disk_loads']}")
            log.info(f"   Augmentations applied: {self.stats['augmentations']}")
            log.info(f"   Original cache size: {len(self.image_cache) if self.image_cache else 0}")
            log.info(f"   Augmented cache size: {len(self.augmented_cache) if self.augmented_cache else 0}")
            
            if self.stats['augmented_cache_hits'] > 0:
                cache_efficiency = self.stats['augmented_cache_hits'] / current_epoch_requests * 100
                log.info(f"   Cache efficiency: {cache_efficiency:.1f}%")
    
    def reset_stats(self):
        """í†µê³„ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.stats = {
            'original_cache_hits': 0,
            'original_cache_misses': 0,
            'augmented_cache_hits': 0,
            'augmented_cache_misses': 0,
            'disk_loads': 0,
            'augmentations': 0
        }

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []
    
    for batch_idx, (images, targets) in enumerate(tqdm(loader, desc="Training")):
        images = images.to(device)
        targets = targets.to(device)
        
        optimizer.zero_grad()
        
        with autocast():
            preds = model(images)
            loss = loss_fn(preds, targets)
        
        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()
        
        train_loss += loss.item()
        preds_list.append(preds.softmax(dim=1).detach().cpu().numpy())
        targets_list.append(targets.detach().cpu().numpy())
    
    train_loss /= len(loader)
    preds_list = np.concatenate(preds_list, axis=0)
    targets_list = np.concatenate(targets_list, axis=0)
    
    train_acc = accuracy_score(targets_list, np.argmax(preds_list, axis=1))
    train_f1 = f1_score(targets_list, np.argmax(preds_list, axis=1), average='macro')
    
    return {
        'train_loss': train_loss,
        'train_acc': train_acc,
        'train_f1': train_f1
    }

# one epoch ê²€ì¦ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def validate_one_epoch(loader, model, loss_fn, device):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []
    
    with torch.no_grad():
        for batch_idx, (images, targets) in enumerate(tqdm(loader, desc="Validation")):
            images = images.to(device)
            targets = targets.to(device)
            
            with autocast():
                preds = model(images)
                loss = loss_fn(preds, targets)
            
            val_loss += loss.item()
            preds_list.append(preds.softmax(dim=1).detach().cpu().numpy())
            targets_list.append(targets.detach().cpu().numpy())
    
    val_loss /= len(loader)
    preds_list = np.concatenate(preds_list, axis=0)
    targets_list = np.concatenate(targets_list, axis=0)
    
    val_acc = accuracy_score(targets_list, np.argmax(preds_list, axis=1))
    val_f1 = f1_score(targets_list, np.argmax(preds_list, axis=1), average='macro')
    
    return {
        'val_loss': val_loss,
        'val_acc': val_acc,
        'val_f1': val_f1
    }

# TTA ë³€í™˜ í•¨ìˆ˜ë“¤
def get_val_tta_transforms(img_size):
    return [
        A.Compose([
            A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            A.PadIfNeeded(min_height=img_size, min_width=img_size,
                          border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Resize(256, 256),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        A.Compose([
            A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            A.PadIfNeeded(min_height=img_size, min_width=img_size,
                          border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Resize(256, 256),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        A.Compose([
            A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            A.PadIfNeeded(min_height=img_size, min_width=img_size,
                          border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Resize(256, 256),
            A.RandomRotate90(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        A.Compose([
            A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
            A.PadIfNeeded(min_height=img_size, min_width=img_size,
                          border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
            A.Resize(256, 256),
            A.RandomRotate90(p=1.0),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
    ]

# TTAë¥¼ ì‚¬ìš©í•œ ê²€ì¦ í•¨ìˆ˜
def validate_one_epoch_tta(val_data, model, loss_fn, device, img_size, data_path):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []
    
    tta_transforms = get_val_tta_transforms(img_size)
    
    with torch.no_grad():
        for idx in tqdm(range(len(val_data)), desc="TTA Validation"):
            name, target = val_data.iloc[idx]
            img = np.array(Image.open(os.path.join(data_path, name)))
            
            all_preds = []
            for transform in tta_transforms:
                transformed_img = transform(image=img)['image'].unsqueeze(0).to(device)
                with autocast():
                    preds = model(transformed_img)
                all_preds.append(preds.softmax(dim=1))
            
            # TTA ì˜ˆì¸¡ í‰ê· 
            final_pred = torch.stack(all_preds).mean(0)
            preds_list.append(final_pred.squeeze(0).detach().cpu().numpy())
            targets_list.append(target)
    
    preds_list = np.array(preds_list)
    targets_list = np.array(targets_list)
    
    # Loss ê³„ì‚° (ì²« ë²ˆì§¸ TTA ë³€í™˜ë§Œ ì‚¬ìš©)
    val_loss = loss_fn(torch.tensor(preds_list).to(device), torch.tensor(targets_list).to(device)).item()
    
    val_acc = accuracy_score(targets_list, np.argmax(preds_list, axis=1))
    val_f1 = f1_score(targets_list, np.argmax(preds_list, axis=1), average='macro')
    
    return {
        'val_loss': val_loss,
        'val_acc': val_acc,
        'val_f1': val_f1
    }

# TTAë¥¼ ì‚¬ìš©í•œ ì˜ˆì¸¡ í•¨ìˆ˜
def predict_with_tta(model, dataset, device, img_size):
    model.eval()
    predictions = []
    
    tta_transforms = get_val_tta_transforms(img_size)
    
    with torch.no_grad():
        for idx in tqdm(range(len(dataset)), desc="TTA Prediction"):
            name, _ = dataset.df[idx]
            img = np.array(Image.open(os.path.join(dataset.path, name)))
            
            all_preds = []
            for transform in tta_transforms:
                transformed_img = transform(image=img)['image'].unsqueeze(0).to(device)
                with autocast():
                    preds = model(transformed_img)
                all_preds.append(preds.softmax(dim=1))
            
            # ì˜ˆì¸¡ í‰ê·  (í™•ë¥  ë¶„í¬ ë°˜í™˜)
            final_pred = torch.stack(all_preds).mean(0)
            predictions.append(final_pred.squeeze(0).detach().cpu().numpy())
    
    return np.array(predictions)

# ì•™ìƒë¸” ì˜ˆì¸¡ í•¨ìˆ˜
def predict_ensemble(models, dataset, device, img_size):
    all_predictions = []
    
    for i, model in enumerate(models):
        log.info(f"ğŸ”® Predicting with Model {i+1}/{len(models)}...")
        fold_predictions = predict_with_tta(model, dataset, device, img_size)
        all_predictions.append(fold_predictions)
    
    # ëª¨ë“  ëª¨ë¸ì˜ ì˜ˆì¸¡ì„ í‰ê·  (shape: [num_samples, num_classes])
    ensemble_predictions = np.mean(all_predictions, axis=0)
    # ê° ìƒ˜í”Œì— ëŒ€í•´ argmax ì ìš©
    final_predictions = np.argmax(ensemble_predictions, axis=1)
    
    return final_predictions

# Early Stopping í´ë˜ìŠ¤ ì •ì˜
class EarlyStopping:
    def __init__(self, patience=10, min_delta=0.001, restore_best_weights=True):
        self.patience = patience
        self.min_delta = min_delta
        self.restore_best_weights = restore_best_weights
        self.best_score = None
        self.counter = 0
        self.best_weights = None
        
    def __call__(self, val_score, model):
        if self.best_score is None:
            self.best_score = val_score
            self.best_weights = model.state_dict().copy()
        elif val_score > self.best_score + self.min_delta:
            self.best_score = val_score
            self.counter = 0
            self.best_weights = model.state_dict().copy()
        else:
            self.counter += 1
            
        if self.counter >= self.patience:
            if self.restore_best_weights:
                model.load_state_dict(self.best_weights)
            return True
        return False

"""## Hyper-parameters
* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
"""

# device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
log.info(f"ğŸ’» Using device: {device}")

# data config
data_path = '../../input/data'

# model config
model_name = 'tf_efficientnetv2_xl'

# training config
img_size = 480
LR = 1e-3
EPOCHS = 100
BATCH_SIZE = 10
num_workers = 0
weight_decay = 1e-4
label_smoothing = 0.1
patience = 10

# K-Fold config
K_FOLDS = 5

# Multi-Seed config
SEEDS = [42, 123]  # 2ê°œì˜ ë‹¤ë¥¸ ëœë¤ì‹œë“œ

# ê°•í™”ëœ augmentationì„ ìœ„í•œ transform ì½”ë“œ
def get_train_transform(img_size):
    return A.Compose([
        A.LongestMaxSize(max_size=img_size, interpolation=cv2.INTER_AREA),
        A.PadIfNeeded(min_height=img_size, min_width=img_size,
                      border_mode=cv2.BORDER_CONSTANT, value=(255, 255, 255), p=1),
        A.Resize(256, 256),
        A.RandomRotate90(p=0.5),
        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=30, p=0.5, border_mode=cv2.BORDER_CONSTANT, value=(255,255,255)),
        A.OneOf([
            A.Blur(blur_limit=2),
            A.MotionBlur(blur_limit=5),
            A.Defocus(radius=(1, 3)),
        ], p=0.5),
        A.OneOf([
            A.GaussNoise(var_limit=(0.0000002, 0.000001), mean=0, p=1.0),
            A.ImageCompression(quality_lower=40, quality_upper=60, p=1.0),
            A.CoarseDropout(max_holes=8, max_height=img_size//10, max_width=img_size//10),
        ], p=0.3),
        A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.5),
        A.OneOf([
            A.CoarseDropout(max_holes=8, max_height=32, max_width=32, fill_value=0, p=0.5),
            A.GridDropout(ratio=0.5, p=0.5),
        ], p=0.4),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

# validation transform (trainê³¼ ë™ì¼í•œ ì¦ê°• ì ìš©)
def get_val_transform(img_size):
    return get_train_transform(img_size)

# ë°ì´í„° ë¡œë“œ
train_df = pd.read_csv(f"{data_path}/train.csv")
log.info(f"ğŸ“‚ Total training samples: {len(train_df)}")

# í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
class_counts = train_df['target'].value_counts().sort_index()
log.info(f"ğŸ“Š Class distribution: {class_counts.to_dict()}")

"""## Multi-Seed K-Fold Cross Validation Training
* 2ê°œì˜ ë‹¤ë¥¸ ëœë¤ì‹œë“œë¡œ 5í´ë“œ êµì°¨ê²€ì¦ì„ ì‹¤í–‰í•˜ì—¬ ì´ 10ê°œì˜ ëª¨ë¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
"""

# ëª¨ë“  ì‹œë“œì™€ í´ë“œì˜ ê²°ê³¼ ì €ì¥
all_fold_scores = []
all_best_models = []

log.info(f"\nğŸ”„ Starting Multi-Seed K-Fold Cross Validation Training...")
log.info(f"ğŸŒ± Seeds: {SEEDS}")
log.info(f"ğŸ“Š Total models to train: {len(SEEDS)} Ã— {K_FOLDS} = {len(SEEDS) * K_FOLDS}")

for seed_idx, seed in enumerate(SEEDS):
    log.info(f"\n{'='*80}")
    log.info(f"ğŸŒ± SEED {seed_idx+1}/{len(SEEDS)}: {seed}")
    log.info(f"{'='*80}")
    
    # ì‹œë“œ ì„¤ì •
    set_seed(seed)
    
    # í˜„ì¬ ì‹œë“œì˜ transform ìƒì„± (ìƒˆë¡œìš´ ì¦ê°•ì„ ìœ„í•´)
    trn_transform = get_train_transform(img_size)
    val_transform = get_val_transform(img_size)
    
    # K-Fold ì •ì˜
    skf = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=seed)
    
    # í˜„ì¬ ì‹œë“œì˜ í´ë“œë³„ ê²°ê³¼ ì €ì¥
    fold_scores = []
    best_models = []
    
    for fold, (train_idx, val_idx) in enumerate(skf.split(train_df, train_df['target'])):
        log.info(f"\n{'='*60}")
        log.info(f"ğŸ”¥ SEED {seed} | FOLD {fold+1}/{K_FOLDS}")
        log.info(f"{'='*60}")
        
        # í´ë“œë³„ ë°ì´í„° ë¶„í• 
        train_fold = train_df.iloc[train_idx].reset_index(drop=True)
        val_fold = train_df.iloc[val_idx].reset_index(drop=True)
        
        log.info(f"ğŸ“š Train samples: {len(train_fold)}")
        log.info(f"ğŸ“ Validation samples: {len(val_fold)}")
        
        # ë°ì´í„°ì…‹ ìƒì„± (ì¦ê°• ìºì‹œ ì´ˆê¸°í™”)
        trn_dataset = ImageDataset(train_fold, f"{data_path}/train/", transform=trn_transform)
        val_dataset = ImageDataset(val_fold, f"{data_path}/train/", transform=val_transform)
        
        # ì¦ê°• ìºì‹œ ì´ˆê¸°í™” (ìƒˆë¡œìš´ ì‹œë“œì—ì„œ ìƒˆë¡œìš´ ì¦ê°•ì„ ìœ„í•´)
        trn_dataset.clear_augmented_cache()
        val_dataset.clear_augmented_cache()
        
        # DataLoader ìƒì„±
        trn_loader = DataLoader(
            trn_dataset,
            batch_size=BATCH_SIZE,
            shuffle=True,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=False
        )
        
        val_loader = DataLoader(
            val_dataset,
            batch_size=BATCH_SIZE,
            shuffle=False,
            num_workers=num_workers,
            pin_memory=True,
            drop_last=False
        )
        
        # ëª¨ë¸ ì´ˆê¸°í™” (ë§¤ í´ë“œë§ˆë‹¤ ìƒˆë¡œ ì‹œì‘)
        model = timm.create_model(
            model_name,
            pretrained=True,
            num_classes=17
        ).to(device)
        
        log.info(f"ğŸ—ï¸ Model: {model_name}")
        log.info(f"ğŸ”¢ Number of parameters: {sum(p.numel() for p in model.parameters()):,}")
        
        # Loss function, optimizer, scheduler ì •ì˜
        loss_fn = LabelSmoothingLoss(classes=17, smoothing=label_smoothing)
        optimizer = Adam(model.parameters(), lr=LR, weight_decay=weight_decay)
        scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)
        scaler = GradScaler()
        
        # Early stopping ì´ˆê¸°í™”
        early_stopping = EarlyStopping(patience=patience, min_delta=0.001, restore_best_weights=True)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
        best_val_f1 = 0.0
        best_model_state = None
        
        log.info(f"ğŸš€ Starting Seed {seed} | Fold {fold+1} training...")
        
        # í´ë“œë³„ í•™ìŠµ
        for epoch in range(EPOCHS):
            log.info(f"\n--- Seed {seed} | Fold {fold+1} | Epoch {epoch+1}/{EPOCHS} ---")
            
            # ì—í¬í¬ ì‹œì‘ ì‹œ í†µê³„ ì´ˆê¸°í™”
            trn_dataset.reset_stats()
            val_dataset.reset_stats()
            
            # Training
            train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler)
            
            # Validation
            val_ret = validate_one_epoch(val_loader, model, loss_fn, device)
            
            # Learning rate scheduler step
            scheduler.step()
            
            # ê²°ê³¼ ì¶œë ¥
            current_lr = optimizer.param_groups[0]['lr']
            
            # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
            if val_ret['val_f1'] > best_val_f1:
                best_val_f1 = val_ret['val_f1']
                best_model_state = model.state_dict().copy()
                log.info(f"ğŸ’¾ Seed {seed} | Fold {fold+1} Best model updated! F1: {best_val_f1:.4f}")
            
            # Early stopping ì²´í¬
            if early_stopping(val_ret['val_f1'], model):
                log.info(f"ğŸ›‘ Early stopping triggered at epoch {epoch+1} for Seed {seed} | Fold {fold+1}")
                log.info(f"ğŸ¯ Best F1 score: {early_stopping.best_score:.4f}")
                break
            
            # ë¡œê·¸ ì¶œë ¥
            log_msg = f"train_loss: {train_ret['train_loss']:.4f} | "
            log_msg += f"train_acc: {train_ret['train_acc']:.4f} | "
            log_msg += f"train_f1: {train_ret['train_f1']:.4f} | "
            log_msg += f"val_loss: {val_ret['val_loss']:.4f} | "
            log_msg += f"val_acc: {val_ret['val_acc']:.4f} | "
            log_msg += f"val_f1: {val_ret['val_f1']:.4f} | "
            log_msg += f"lr: {current_lr:.6f}"
            
            log.info(log_msg)
            
            # ë§¤ ì—í¬í¬ë§ˆë‹¤ ìºì‹± í†µê³„ ì¶œë ¥
            log.info(f"\nğŸ“Š Epoch {epoch+1} Cache Statistics:")
            trn_dataset.print_stats()
            val_dataset.print_stats()
        
        # í´ë“œ ì™„ë£Œ
        if early_stopping.best_weights is not None:
            final_f1 = early_stopping.best_score
            log.info(f"\nğŸ¯ Seed {seed} | Fold {fold+1} completed with early stopping! Best F1: {final_f1:.4f}")
        else:
            final_f1 = best_val_f1
            log.info(f"\nğŸ¯ Seed {seed} | Fold {fold+1} completed! Best F1: {final_f1:.4f}")
        
        fold_scores.append(final_f1)
        
        # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
        if early_stopping.best_weights is not None:
            best_models.append(early_stopping.best_weights.copy())
        elif best_model_state is not None:
            best_models.append(best_model_state.copy())
        else:
            best_models.append(model.state_dict().copy())
        
        # ë©”ëª¨ë¦¬ ì •ë¦¬
        del model, optimizer, scheduler, scaler, trn_loader, val_loader
        del trn_dataset, val_dataset, train_fold, val_fold
        torch.cuda.empty_cache()
        gc.collect()
    
    # í˜„ì¬ ì‹œë“œì˜ ê²°ê³¼ ì €ì¥
    all_fold_scores.extend(fold_scores)
    all_best_models.extend(best_models)
    
    # í˜„ì¬ ì‹œë“œì˜ ê²°ê³¼ ìš”ì•½
    mean_score = np.mean(fold_scores)
    std_score = np.std(fold_scores)
    
    log.info(f"\n{'='*60}")
    log.info(f"ğŸ“Š SEED {seed} K-FOLD RESULTS")
    log.info(f"{'='*60}")
    log.info(f"ğŸ“ˆ Individual fold scores: {[f'{score:.4f}' for score in fold_scores]}")
    log.info(f"ğŸ¯ Mean F1 Score: {mean_score:.4f}")
    log.info(f"ğŸ“ Standard Deviation: {std_score:.4f}")
    log.info(f"ğŸ“Š Score Range: {mean_score:.4f} Â± {std_score:.4f}")
    log.info(f"â¬‡ï¸ Min Score: {min(fold_scores):.4f}")
    log.info(f"â¬†ï¸ Max Score: {max(fold_scores):.4f}")

# ì „ì²´ ê²°ê³¼ ìš”ì•½
log.info(f"\n{'='*80}")
log.info(f"ğŸ“Š OVERALL MULTI-SEED K-FOLD CROSS VALIDATION RESULTS")
log.info(f"{'='*80}")

total_mean_score = np.mean(all_fold_scores)
total_std_score = np.std(all_fold_scores)

log.info(f"ğŸ“ˆ All fold scores: {[f'{score:.4f}' for score in all_fold_scores]}")
log.info(f"ğŸ¯ Overall Mean F1 Score: {total_mean_score:.4f}")
log.info(f"ğŸ“ Overall Standard Deviation: {total_std_score:.4f}")
log.info(f"ğŸ“Š Overall Score Range: {total_mean_score:.4f} Â± {total_std_score:.4f}")
log.info(f"â¬‡ï¸ Overall Min Score: {min(all_fold_scores):.4f}")
log.info(f"â¬†ï¸ Overall Max Score: {max(all_fold_scores):.4f}")
log.info(f"ğŸ”¢ Total models trained: {len(all_best_models)}")

"""## Ensemble Inference & Save File
* ëª¨ë“  ì‹œë“œì™€ í´ë“œì˜ ëª¨ë¸ì„ ì•™ìƒë¸”í•˜ì—¬ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•©ë‹ˆë‹¤.
"""

log.info(f"\nğŸš€ Starting Ensemble Prediction with {len(all_best_models)} models...")

# í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ ìƒì„±
tst_dataset = ImageDataset(
    f"{data_path}/sample_submission.csv",
    f"{data_path}/test/",
    transform=None  # TTAì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë³€í˜•í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” None
)

# ì•™ìƒë¸”ì„ ìœ„í•´ ëª¨ë“  ëª¨ë¸ ë¡œë“œ
ensemble_models = []
for i, model_state in enumerate(all_best_models):
    model = timm.create_model(
        model_name,
        pretrained=True,
        num_classes=17
    ).to(device)
    model.load_state_dict(model_state)
    ensemble_models.append(model)
    log.info(f"âœ… Loaded Model {i+1}/{len(all_best_models)} (Seed {SEEDS[i//K_FOLDS]}, Fold {i%K_FOLDS+1})")

# ì•™ìƒë¸” ì˜ˆì¸¡ ì‹¤í–‰
log.info(f"\nğŸ”® Running ensemble prediction with {len(ensemble_models)} models and TTA...")
preds_list = predict_ensemble(ensemble_models, tst_dataset, device, img_size)

# ê²°ê³¼ ì €ì¥
pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])
pred_df['target'] = preds_list

sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
assert (sample_submission_df['ID'] == pred_df['ID']).all()

output_path = "./output"
os.makedirs(output_path, exist_ok=True)
pred_df.to_csv(f"{output_path}/pred_ensemble_10_models_2_seeds.csv", index=False)

log.info(f"\nâœ… Ensemble prediction completed and saved to {output_path}/pred_ensemble_10_models_2_seeds.csv")
log.info(f"ğŸ“ˆ Overall Multi-Seed K-Fold CV Score: {total_mean_score:.4f} Â± {total_std_score:.4f}")
log.info(f"ğŸ¯ Total models used for ensemble: {len(ensemble_models)}")

# ë©”ëª¨ë¦¬ ì •ë¦¬
for model in ensemble_models:
    del model
torch.cuda.empty_cache()
gc.collect()

log.info(f"\nğŸ“Š Final Results Summary:")
log.info(f"   Seeds used: {SEEDS}")
log.info(f"   Folds per seed: {K_FOLDS}")
log.info(f"   Total models: {len(ensemble_models)}")
log.info(f"   Overall CV Score: {total_mean_score:.4f} Â± {total_std_score:.4f}")
log.info(f"   Output file: {output_path}/pred_ensemble_10_models_2_seeds.csv")

pred_df.head() 