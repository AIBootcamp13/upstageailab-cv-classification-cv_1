"""
í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ëª¨ë“ˆ
ë¬¸ì„œ ì´ë¯¸ì§€ì˜ íšŒì „, ë°ê¸°, ë¸”ëŸ¬, ë…¸ì´ì¦ˆ ë“±ì„ ë¶„ì„í•˜ì—¬ ì¦ê°• íŒŒë¼ë¯¸í„°ë¥¼ ë„ì¶œí•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
from pathlib import Path
from typing import Dict, List, Any


def analyze_document_test_data(test_dir: str, sample_size: int = 100) -> Dict[str, Dict[str, float]]:
    """
    ë¬¸ì„œ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ íŠ¹ì„± ë¶„ì„
    
    Args:
        test_dir: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
        sample_size: ë¶„ì„í•  ìƒ˜í”Œ ìˆ˜
        
    Returns:
        ë¶„ì„ ê²°ê³¼ í†µê³„ ë”•ì…”ë„ˆë¦¬
    """
    test_images = list(Path(test_dir).glob('*.jpg')) + list(Path(test_dir).glob('*.png'))
    
    if len(test_images) == 0:
        raise ValueError(f"í…ŒìŠ¤íŠ¸ ë””ë ‰í† ë¦¬ {test_dir}ì—ì„œ ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    test_images = test_images[:sample_size]
    print(f"ğŸ“ {len(test_images)}ê°œì˜ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")
    
    analysis_results = {
        'rotation_angles': [],
        'brightness_levels': [],
        'blur_levels': [],
        'noise_levels': [],
        'contrast_levels': []
    }
    
    for i, img_path in enumerate(test_images):
        if i % 20 == 0:
            print(f"  ì§„í–‰ë¥ : {i}/{len(test_images)} ({i/len(test_images)*100:.1f}%)")
            
        img = cv2.imread(str(img_path))
        if img is None:
            continue
            
        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
        
        # 1. íšŒì „ ê°ë„ ë¶„ì„
        rotation = estimate_document_rotation(gray)
        analysis_results['rotation_angles'].append(rotation)
        
        # 2. ë°ê¸° ë¶„ì„
        brightness = np.mean(gray)
        analysis_results['brightness_levels'].append(brightness)
        
        # 3. ë¸”ëŸ¬ ì •ë„ ë¶„ì„
        blur_score = cv2.Laplacian(gray, cv2.CV_64F).var()
        analysis_results['blur_levels'].append(blur_score)
        
        # 4. ë…¸ì´ì¦ˆ ë ˆë²¨ ë¶„ì„
        noise_level = estimate_noise_level(gray)
        analysis_results['noise_levels'].append(noise_level)
        
        # 5. ëŒ€ë¹„ ë¶„ì„
        contrast = gray.std()
        analysis_results['contrast_levels'].append(contrast)
    
    print("âœ… í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ì™„ë£Œ!")
    
    # í†µê³„ ì •ë³´ ê³„ì‚°
    stats = {}
    for key, values in analysis_results.items():
        if values:  # ë¹ˆ ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹Œ ê²½ìš°ë§Œ
            stats[key] = {
                'mean': np.mean(values),
                'std': np.std(values),
                'min': np.min(values),
                'max': np.max(values),
                'percentiles': np.percentile(values, [25, 50, 75]).tolist()
            }
        else:
            stats[key] = {
                'mean': 0, 'std': 0, 'min': 0, 'max': 0, 'percentiles': [0, 0, 0]
            }
    
    # ë¶„ì„ ê²°ê³¼ ì¶œë ¥
    print_analysis_summary(stats)
    
    return stats


def estimate_document_rotation(gray_image: np.ndarray) -> float:
    """
    ë¬¸ì„œ ì´ë¯¸ì§€ì˜ íšŒì „ ê°ë„ ì¶”ì •
    
    Args:
        gray_image: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
        
    Returns:
        ì¶”ì •ëœ íšŒì „ ê°ë„ (ë„)
    """
    edges = cv2.Canny(gray_image, 50, 150, apertureSize=3)
    lines = cv2.HoughLines(edges, 1, np.pi/180, threshold=100)
    
    if lines is not None:
        angles = []
        for rho, theta in lines[:20]:
            angle = (theta * 180 / np.pi) - 90
            if abs(angle) <= 45:  # ì£¼ìš” ê°ë„ë§Œ ê³ ë ¤
                angles.append(angle)
        
        if angles:
            # ê°€ì¥ ë¹ˆë²ˆí•œ ê°ë„ ë°˜í™˜
            hist, bins = np.histogram(angles, bins=18, range=(-45, 45))
            dominant_angle_idx = np.argmax(hist)
            return (bins[dominant_angle_idx] + bins[dominant_angle_idx + 1]) / 2
    
    return 0


def estimate_noise_level(gray_image: np.ndarray) -> float:
    """
    ì´ë¯¸ì§€ì˜ ë…¸ì´ì¦ˆ ë ˆë²¨ ì¶”ì •
    
    Args:
        gray_image: ê·¸ë ˆì´ìŠ¤ì¼€ì¼ ì´ë¯¸ì§€
        
    Returns:
        ë…¸ì´ì¦ˆ ë ˆë²¨ ê°’
    """
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬ì™€ ì›ë³¸ì˜ ì°¨ì´ë¡œ ë…¸ì´ì¦ˆ ì¶”ì •
    blurred = cv2.GaussianBlur(gray_image, (5, 5), 0)
    noise = gray_image.astype(float) - blurred.astype(float)
    return float(np.std(noise))


def print_analysis_summary(stats: Dict[str, Dict[str, float]]) -> None:
    """
    ë¶„ì„ ê²°ê³¼ ìš”ì•½ ì¶œë ¥
    
    Args:
        stats: ë¶„ì„ ê²°ê³¼ í†µê³„
    """
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼:")
    print("=" * 50)
    
    for key, values in stats.items():
        print(f"\nğŸ”¹ {key}:")
        print(f"  í‰ê· : {values['mean']:.2f}")
        print(f"  í‘œì¤€í¸ì°¨: {values['std']:.2f}")
        print(f"  ë²”ìœ„: {values['min']:.2f} ~ {values['max']:.2f}")
        print(f"  ë¶„ìœ„ìˆ˜: {values['percentiles']}")


def save_analysis_results(stats: Dict[str, Dict[str, float]], output_path: str = "test_analysis_results.json") -> None:
    """
    ë¶„ì„ ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥
    
    Args:
        stats: ë¶„ì„ ê²°ê³¼ í†µê³„
        output_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    import json
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(stats, f, indent=2, ensure_ascii=False)
    
    print(f"ğŸ’¾ ë¶„ì„ ê²°ê³¼ê°€ {output_path}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


def load_analysis_results(input_path: str = "test_analysis_results.json") -> Dict[str, Dict[str, float]]:
    """
    ì €ì¥ëœ ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œ
    
    Args:
        input_path: ë¡œë“œí•  íŒŒì¼ ê²½ë¡œ
        
    Returns:
        ë¶„ì„ ê²°ê³¼ í†µê³„
    """
    import json
    
    with open(input_path, 'r', encoding='utf-8') as f:
        stats = json.load(f)
    
    print(f"ğŸ“‚ ë¶„ì„ ê²°ê³¼ë¥¼ {input_path}ì—ì„œ ë¡œë“œí–ˆìŠµë‹ˆë‹¤.")
    return stats


if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    test_dir = "input/data/test"
    
    try:
        stats = analyze_document_test_data(test_dir, sample_size=50)
        save_analysis_results(stats)
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        print("í…ŒìŠ¤íŠ¸ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 