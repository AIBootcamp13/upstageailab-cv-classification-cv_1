# í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë°˜ ì ì‘í˜• ì¦ê°• ì‹œìŠ¤í…œ

ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ë°˜ ì ì‘í˜• ì¦ê°• ì‹œìŠ¤í…œì…ë‹ˆë‹¤. í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ íŠ¹ì„±(íšŒì „, ë°ê¸°, ë…¸ì´ì¦ˆ, ë¸”ëŸ¬ ë“±)ì„ ë¶„ì„í•˜ì—¬ í•™ìŠµ ë°ì´í„°ì— ìœ ì‚¬í•œ ì¦ê°•ì„ ì ìš©í•©ë‹ˆë‹¤.

## ğŸ¯ ì£¼ìš” ê¸°ëŠ¥

- **í…ŒìŠ¤íŠ¸ ë°ì´í„° ìë™ ë¶„ì„**: íšŒì „ ê°ë„, ë°ê¸°, ë…¸ì´ì¦ˆ, ë¸”ëŸ¬ ë“±ì˜ íŠ¹ì„± ë¶„ì„
- **Augraphy ê¸°ë°˜ ë¬¸ì„œ ì¦ê°•**: ë¬¸ì„œ ì´ë¯¸ì§€ì— íŠ¹í™”ëœ í˜„ì‹¤ì ì¸ ì¦ê°•
- **ì ì‘í˜• íŒŒì´í”„ë¼ì¸**: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì¦ê°• íŒŒì´í”„ë¼ì¸ ìƒì„±
- **ì ì§„ì  ì¦ê°•**: í•™ìŠµ ê³¼ì •ì—ì„œ ì¦ê°• ê°•ë„ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€
- **fallback ì§€ì›**: Augraphyê°€ ì—†ì–´ë„ ê¸°ë³¸ ì¦ê°•ìœ¼ë¡œ ë™ì‘

## ğŸ“ íŒŒì¼ êµ¬ì¡°

```
code/
â”œâ”€â”€ test_data_analyzer.py      # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ëª¨ë“ˆ
â”œâ”€â”€ adaptive_augmentation.py   # Augraphy ê¸°ë°˜ ì ì‘í˜• ì¦ê°• íŒŒì´í”„ë¼ì¸
â”œâ”€â”€ adaptive_dataset.py        # PyTorch Dataset í´ë˜ìŠ¤
â”œâ”€â”€ main.py                   # ë©”ì¸ ì‹¤í–‰ íŒŒì¼
â”œâ”€â”€ requirements.txt          # í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
â””â”€â”€ README.md                 # ì‚¬ìš©ë²• ì„¤ëª…
```

## ğŸš€ ì„¤ì¹˜ ë° ì„¤ì •

### 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. Augraphy ì„¤ì¹˜ (ì„ íƒì‚¬í•­, ê¶Œì¥)

```bash
pip install augraphy
```

> **ì°¸ê³ **: Augraphyê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ë„ ê¸°ë³¸ ì¦ê°•ìœ¼ë¡œ ë™ì‘í•˜ì§€ë§Œ, ë¬¸ì„œ ì´ë¯¸ì§€ì— íŠ¹í™”ëœ ì¦ê°•ì„ ìœ„í•´ì„œëŠ” Augraphy ì„¤ì¹˜ë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.

## ğŸ“Š ì‚¬ìš©ë²•

### 1. ê¸°ë³¸ ì‚¬ìš©ë²•

```bash
python main.py --train_dir input/data/train --test_dir input/data/test --epochs 50
```

### 2. ìƒì„¸ ì˜µì…˜

```bash
python main.py \
    --train_dir input/data/train \
    --test_dir input/data/test \
    --epochs 100 \
    --batch_size 64 \
    --learning_rate 0.001 \
    --image_size 224 \
    --device cuda
```

### 3. ë¶„ì„ë§Œ ìˆ˜í–‰ (í•™ìŠµ ì—†ì´)

```bash
python main.py --test_dir input/data/test --analysis_only
```

### 4. ì‚¬ìš© ê°€ëŠ¥í•œ ì˜µì…˜ë“¤

| ì˜µì…˜ | ê¸°ë³¸ê°’ | ì„¤ëª… |
|------|--------|------|
| `--train_dir` | `input/data/train` | í•™ìŠµ ë°ì´í„° ë””ë ‰í† ë¦¬ |
| `--test_dir` | `input/data/test` | í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ |
| `--epochs` | `50` | í•™ìŠµ ì—í¬í¬ ìˆ˜ |
| `--batch_size` | `32` | ë°°ì¹˜ í¬ê¸° |
| `--learning_rate` | `0.001` | í•™ìŠµë¥  |
| `--image_size` | `224` | ì´ë¯¸ì§€ í¬ê¸° |
| `--num_classes` | `auto` | í´ë˜ìŠ¤ ìˆ˜ (ìë™ ê°ì§€) |
| `--device` | `auto` | ë””ë°”ì´ìŠ¤ (auto, cuda, cpu) |
| `--analysis_only` | `False` | ë¶„ì„ë§Œ ìˆ˜í–‰ |

## ğŸ—‚ï¸ ë°ì´í„° êµ¬ì¡°

### í•™ìŠµ ë°ì´í„° (í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°)
```
input/data/train/
â”œâ”€â”€ class1/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ class2/
â”‚   â”œâ”€â”€ image1.jpg
â”‚   â”œâ”€â”€ image2.jpg
â”‚   â””â”€â”€ ...
â””â”€â”€ ...
```

### í…ŒìŠ¤íŠ¸ ë°ì´í„° (ë‹¨ì¼ í´ë”)
```
input/data/test/
â”œâ”€â”€ test1.jpg
â”œâ”€â”€ test2.jpg
â”œâ”€â”€ test3.jpg
â””â”€â”€ ...
```

## ğŸ” ì‘ë™ ì›ë¦¬

1. **í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„**: í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë“¤ì˜ íšŒì „, ë°ê¸°, ë…¸ì´ì¦ˆ, ë¸”ëŸ¬ ë“±ì„ ë¶„ì„
2. **ì ì‘í˜• íŒŒì´í”„ë¼ì¸ ìƒì„±**: ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ Augraphy íŒŒì´í”„ë¼ì¸ ìƒì„±
3. **ì ì§„ì  ì¦ê°•**: í•™ìŠµ ê³¼ì •ì—ì„œ ì¦ê°• ê°•ë„ë¥¼ ì ì§„ì ìœ¼ë¡œ ì¦ê°€
4. **ëª¨ë¸ í•™ìŠµ**: ResNet-50 ê¸°ë°˜ ë¶„ë¥˜ ëª¨ë¸ í•™ìŠµ

## ğŸ“ˆ ì¶œë ¥ íŒŒì¼

- `test_analysis_results.json`: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼
- `analysis_report.txt`: ìƒì„¸ ë¶„ì„ ë³´ê³ ì„œ
- `models/best_model.pth`: ìµœê³  ì„±ëŠ¥ ëª¨ë¸
- `test_analysis_cache.json`: ë¶„ì„ ê²°ê³¼ ìºì‹œ

## ğŸ”§ ëª¨ë“ˆë³„ ì‚¬ìš©ë²•

### 1. í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ë§Œ ì‹¤í–‰

```python
from test_data_analyzer import analyze_document_test_data

# í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„
stats = analyze_document_test_data("input/data/test", sample_size=100)
print(stats)
```

### 2. ì ì‘í˜• ë°ì´í„°ì…‹ ì§ì ‘ ì‚¬ìš©

```python
from adaptive_dataset import AdaptiveDocumentDataset, load_image_paths_and_labels
from torchvision import transforms

# ë°ì´í„° ë¡œë“œ
train_paths, train_labels = load_image_paths_and_labels("input/data/train")

# ë³€í™˜ ì •ì˜
transform = transforms.Compose([
    transforms.ToPILImage(),
    transforms.Resize((224, 224)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
])

# ì ì‘í˜• ë°ì´í„°ì…‹ ìƒì„±
dataset = AdaptiveDocumentDataset(
    image_paths=train_paths,
    labels=train_labels,
    test_data_dir="input/data/test",
    pytorch_transform=transform
)
```

### 3. ì»¤ìŠ¤í…€ íŒŒì´í”„ë¼ì¸ ìƒì„±

```python
from adaptive_augmentation import create_adaptive_document_pipeline

# ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ íŒŒì´í”„ë¼ì¸ ìƒì„±
pipeline = create_adaptive_document_pipeline(stats)

# ì´ë¯¸ì§€ì— ì¦ê°• ì ìš©
import cv2
image = cv2.imread("sample.jpg")
augmented = pipeline(image)
```

## âš ï¸ ì£¼ì˜ì‚¬í•­

1. **Augraphy ì„¤ì¹˜**: ìµœì ì˜ ì„±ëŠ¥ì„ ìœ„í•´ Augraphy ì„¤ì¹˜ ê¶Œì¥
2. **ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰**: í° ì´ë¯¸ì§€ë‚˜ ë§ì€ ë°ì´í„°ì˜ ê²½ìš° ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ í™•ì¸
3. **GPU ë©”ëª¨ë¦¬**: ë°°ì¹˜ í¬ê¸° ì¡°ì ˆë¡œ GPU ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¡°ì ˆ
4. **ë°ì´í„° í’ˆì§ˆ**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ì˜ í’ˆì§ˆì´ ì¦ê°• í’ˆì§ˆì— ì§ì ‘ì  ì˜í–¥

## ğŸ› ï¸ ë¬¸ì œ í•´ê²°

### Augraphy ì„¤ì¹˜ ì˜¤ë¥˜
```bash
# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜ (Ubuntu/Debian)
sudo apt-get install python3-opencv

# Augraphy ì„¤ì¹˜
pip install augraphy
```

### CUDA ê´€ë ¨ ì˜¤ë¥˜
```bash
# CPU ëª¨ë“œë¡œ ì‹¤í–‰
python main.py --device cpu
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# ë°°ì¹˜ í¬ê¸° ì¤„ì´ê¸°
python main.py --batch_size 16

# ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜ ì¤„ì´ê¸° (adaptive_dataset.pyì—ì„œ num_workers ì¡°ì •)
```

## ğŸ“Š ì„±ëŠ¥ í–¥ìƒ íŒ

1. **ë¶„ì„ ìƒ˜í”Œ ìˆ˜ ì¦ê°€**: ë” ë§ì€ í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ë¡œ ë¶„ì„í•˜ì—¬ ì •í™•ë„ í–¥ìƒ
2. **ì ì§„ì  í•™ìŠµ**: ì‘ì€ í•™ìŠµë¥ ë¡œ ì˜¤ë˜ í•™ìŠµ
3. **ì•™ìƒë¸”**: ì—¬ëŸ¬ ëª¨ë¸ì˜ ê²°ê³¼ë¥¼ ì•™ìƒë¸”
4. **Test Time Augmentation**: ì¶”ë¡  ì‹œì—ë„ ì¦ê°• ì ìš©

## ğŸ“ ë¼ì´ì„¼ìŠ¤

ì´ ì½”ë“œëŠ” ë¬¸ì„œ ì´ë¯¸ì§€ ë¶„ë¥˜ë¥¼ ìœ„í•œ ì—°êµ¬ ë° êµìœ¡ ëª©ì ìœ¼ë¡œ ì œê³µë©ë‹ˆë‹¤. 