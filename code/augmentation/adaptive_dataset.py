"""
ì ì‘í˜• ë¬¸ì„œ ì´ë¯¸ì§€ Dataset
í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§ì¶¤í˜• ì¦ê°•ì„ ì ìš©í•˜ëŠ” PyTorch Dataset
"""

import torch
from torch.utils.data import Dataset, DataLoader
import cv2
import numpy as np
from pathlib import Path
from typing import List, Optional, Callable, Tuple, Any, Union
import os

# ë¡œì»¬ ëª¨ë“ˆ import
from test_data_analyzer import analyze_document_test_data
from adaptive_augmentation import create_adaptive_document_pipeline, create_progressive_document_pipeline


class AdaptiveDocumentDataset(Dataset):
    """
    í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì‘í˜• ì¦ê°•ì„ ì ìš©í•˜ëŠ” Dataset
    """
    
    def __init__(
        self, 
        image_paths: List[str], 
        labels: List[int], 
        test_data_dir: str,
        pytorch_transform: Optional[Callable] = None,
        cache_analysis: bool = True,
        analysis_cache_path: str = "test_analysis_cache.json"
    ):
        """
        Args:
            image_paths: í•™ìŠµ ì´ë¯¸ì§€ íŒŒì¼ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
            labels: ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸
            test_data_dir: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬ ê²½ë¡œ
            pytorch_transform: PyTorch ë³€í™˜ (ì •ê·œí™”, í…ì„œ ë³€í™˜ ë“±)
            cache_analysis: ë¶„ì„ ê²°ê³¼ ìºì‹± ì—¬ë¶€
            analysis_cache_path: ë¶„ì„ ê²°ê³¼ ìºì‹œ íŒŒì¼ ê²½ë¡œ
        """
        self.image_paths = image_paths
        self.labels = labels
        self.pytorch_transform = pytorch_transform
        self.test_data_dir = test_data_dir
        self.cache_analysis = cache_analysis
        self.analysis_cache_path = analysis_cache_path
        
        # ë°ì´í„° ìœ íš¨ì„± ê²€ì¦
        if len(image_paths) != len(labels):
            raise ValueError("ì´ë¯¸ì§€ ê²½ë¡œì™€ ë ˆì´ë¸”ì˜ ê°œìˆ˜ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ë˜ëŠ” ìºì‹œ ë¡œë“œ
        self.test_stats = self._load_or_analyze_test_data()
        
        # Augraphy íŒŒì´í”„ë¼ì¸ ìƒì„±
        try:
            self.augraphy_pipeline = create_adaptive_document_pipeline(self.test_stats)
            self.augraphy_available = True
            print("âœ… Augraphy íŒŒì´í”„ë¼ì¸ ìƒì„± ì™„ë£Œ!")
        except Exception as e:
            print(f"âš ï¸ Augraphyë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            print("ğŸ’¡ pip install augraphy ë¥¼ ì‹¤í–‰í•˜ì—¬ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            self.augraphy_pipeline = None
            self.augraphy_available = False
    
    def _load_or_analyze_test_data(self) -> dict:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ë¥¼ ë¡œë“œí•˜ê±°ë‚˜ ìƒˆë¡œ ë¶„ì„"""
        
        if self.cache_analysis and os.path.exists(self.analysis_cache_path):
            try:
                from test_data_analyzer import load_analysis_results
                print(f"ğŸ“‚ ìºì‹œëœ ë¶„ì„ ê²°ê³¼ ë¡œë“œ: {self.analysis_cache_path}")
                return load_analysis_results(self.analysis_cache_path)
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ìƒˆë¡œìš´ ë¶„ì„ ìˆ˜í–‰
        print("ğŸ” í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ì¤‘...")
        stats = analyze_document_test_data(self.test_data_dir, sample_size=100)
        
        # ê²°ê³¼ ìºì‹±
        if self.cache_analysis:
            try:
                from test_data_analyzer import save_analysis_results
                save_analysis_results(stats, self.analysis_cache_path)
            except Exception as e:
                print(f"âš ï¸ ë¶„ì„ ê²°ê³¼ ìºì‹± ì‹¤íŒ¨: {e}")
        
        return stats
    
    def update_pipeline_strength(self, epoch: int, total_epochs: int) -> None:
        """
        ì—í¬í¬ì— ë”°ë¥¸ ì¦ê°• ê°•ë„ ì¡°ì ˆ
        
        Args:
            epoch: í˜„ì¬ ì—í¬í¬
            total_epochs: ì´ ì—í¬í¬ ìˆ˜
        """
        if not self.augraphy_available:
            return
            
        try:
            strength_factor = min(1.0, epoch / (total_epochs * 0.7))
            
            if epoch < total_epochs * 0.3:
                stage = "light"
            elif epoch < total_epochs * 0.7:
                stage = "medium" 
            else:
                stage = "heavy"
            
            self.augraphy_pipeline = create_progressive_document_pipeline(
                self.test_stats, stage
            )
            
            print(f"ğŸ”„ ì¦ê°• íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸: {stage} (ì—í¬í¬ {epoch}/{total_epochs})")
            
        except Exception as e:
            print(f"âš ï¸ íŒŒì´í”„ë¼ì¸ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {e}")
    
    def get_test_stats_summary(self) -> str:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ìš”ì•½"""
        summary = []
        summary.append("ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ìš”ì•½:")
        
        for key, stats in self.test_stats.items():
            summary.append(f"  {key}: í‰ê· ={stats['mean']:.2f}, í‘œì¤€í¸ì°¨={stats['std']:.2f}")
        
        return "\n".join(summary)
    
    def __len__(self) -> int:
        return len(self.image_paths)
    
    def __getitem__(self, idx: int) -> Tuple[torch.Tensor, int]:
        """
        ë°ì´í„°ì…‹ ì•„ì´í…œ ë¡œë“œ ë° ì¦ê°• ì ìš©
        
        Args:
            idx: ì¸ë±ìŠ¤
            
        Returns:
            (ì¦ê°•ëœ ì´ë¯¸ì§€ í…ì„œ, ë ˆì´ë¸”) íŠœí”Œ
        """
        try:
            # ì´ë¯¸ì§€ ë¡œë“œ
            image_path = self.image_paths[idx]
            image = cv2.imread(image_path)
            
            if image is None:
                raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {image_path}")
            
            # Augraphy ì¦ê°• ì ìš©
            if self.augraphy_available and self.augraphy_pipeline is not None:
                try:
                    augmented_image = self.augraphy_pipeline(image)
                except Exception as e:
                    print(f"âš ï¸ Augraphy ì¦ê°• ì‹¤íŒ¨, ì›ë³¸ ì´ë¯¸ì§€ ì‚¬ìš©: {e}")
                    augmented_image = image
            else:
                # Augraphyê°€ ì—†ì„ ë•Œ ê¸°ë³¸ ì¦ê°•
                augmented_image = self._basic_augmentation(image)
            
            # PyTorch ë³€í™˜ ì ìš©
            if self.pytorch_transform:
                # BGR -> RGB ë³€í™˜
                augmented_image = cv2.cvtColor(augmented_image, cv2.COLOR_BGR2RGB)
                augmented_image = self.pytorch_transform(augmented_image)
            else:
                # ê¸°ë³¸ í…ì„œ ë³€í™˜
                augmented_image = torch.from_numpy(augmented_image).permute(2, 0, 1).float() / 255.0
            
            return augmented_image, self.labels[idx]
            
        except Exception as e:
            print(f"âŒ ë°ì´í„° ë¡œë“œ ì˜¤ë¥˜ (idx={idx}): {e}")
            # ì˜¤ë¥˜ ì‹œ ë”ë¯¸ ë°ì´í„° ë°˜í™˜
            dummy_image = torch.zeros((3, 224, 224))
            return dummy_image, self.labels[idx]
    
    def _basic_augmentation(self, image: np.ndarray) -> np.ndarray:
        """
        Augraphyê°€ ì—†ì„ ë•Œ ì‚¬ìš©í•  ê¸°ë³¸ ì¦ê°•
        
        Args:
            image: ì…ë ¥ ì´ë¯¸ì§€
            
        Returns:
            ì¦ê°•ëœ ì´ë¯¸ì§€
        """
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê¸°ë³¸ ì¦ê°•
        rotation_mean = self.test_stats['rotation_angles']['mean']
        brightness_mean = self.test_stats['brightness_levels']['mean']
        
        # íšŒì „ ì ìš©
        if abs(rotation_mean) > 5:  # ì˜ë¯¸ìˆëŠ” íšŒì „ì´ ìˆë‹¤ë©´
            angle = np.random.normal(rotation_mean, 15)  # í‰ê·  Â± 15ë„
            angle = np.clip(angle, -45, 45)  # ë²”ìœ„ ì œí•œ
            
            h, w = image.shape[:2]
            center = (w // 2, h // 2)
            rotation_matrix = cv2.getRotationMatrix2D(center, angle, 1.0)
            image = cv2.warpAffine(image, rotation_matrix, (w, h))
        
        # ë°ê¸° ì¡°ì •
        brightness_factor = brightness_mean / 127.5  # ì •ê·œí™”
        brightness_adjust = np.random.uniform(0.8, 1.2) * brightness_factor
        image = cv2.convertScaleAbs(image, alpha=brightness_adjust, beta=0)
        
        # ê°€ìš°ì‹œì•ˆ ë…¸ì´ì¦ˆ ì¶”ê°€
        noise_level = self.test_stats['noise_levels']['mean']
        if noise_level > 5:
            noise = np.random.normal(0, noise_level * 0.5, image.shape)
            image = np.clip(image.astype(float) + noise, 0, 255).astype(np.uint8)
        
        return image


def create_adaptive_dataloader(
    train_image_paths: List[str],
    train_labels: List[int],
    test_data_dir: str,
    batch_size: int = 32,
    num_workers: int = 4,
    pytorch_transform: Optional[Callable] = None,
    shuffle: bool = True
) -> DataLoader:
    """
    ì ì‘í˜• DataLoader ìƒì„± í—¬í¼ í•¨ìˆ˜
    
    Args:
        train_image_paths: í•™ìŠµ ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        train_labels: í•™ìŠµ ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸  
        test_data_dir: í…ŒìŠ¤íŠ¸ ë°ì´í„° ë””ë ‰í† ë¦¬
        batch_size: ë°°ì¹˜ í¬ê¸°
        num_workers: ì›Œì»¤ í”„ë¡œì„¸ìŠ¤ ìˆ˜
        pytorch_transform: PyTorch ë³€í™˜
        shuffle: ì…”í”Œ ì—¬ë¶€
        
    Returns:
        AdaptiveDocumentDatasetì„ ì‚¬ìš©í•˜ëŠ” DataLoader
    """
    
    dataset = AdaptiveDocumentDataset(
        image_paths=train_image_paths,
        labels=train_labels,
        test_data_dir=test_data_dir,
        pytorch_transform=pytorch_transform
    )
    
    dataloader = DataLoader(
        dataset=dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True
    )
    
    return dataloader


def load_image_paths_and_labels(
    data_dir: str,
    class_names: Optional[List[str]] = None
) -> Tuple[List[str], List[int]]:
    """
    ë°ì´í„° ë””ë ‰í† ë¦¬ì—ì„œ ì´ë¯¸ì§€ ê²½ë¡œì™€ ë ˆì´ë¸”ì„ ë¡œë“œ
    
    Args:
        data_dir: ë°ì´í„° ë””ë ‰í† ë¦¬ (í´ë˜ìŠ¤ë³„ í•˜ìœ„ í´ë” êµ¬ì¡° ê°€ì •)
        class_names: í´ë˜ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ ìë™ ì¶”ì¶œ)
        
    Returns:
        (ì´ë¯¸ì§€ ê²½ë¡œ ë¦¬ìŠ¤íŠ¸, ë ˆì´ë¸” ë¦¬ìŠ¤íŠ¸) íŠœí”Œ
    """
    
    data_path = Path(data_dir)
    
    if not data_path.exists():
        raise ValueError(f"ë°ì´í„° ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {data_dir}")
    
    image_paths = []
    labels = []
    
    # í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°ì¸ì§€ í™•ì¸
    subdirs = [d for d in data_path.iterdir() if d.is_dir()]
    
    if subdirs:  # í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡°
        if class_names is None:
            class_names = sorted([d.name for d in subdirs])
        
        print(f"ğŸ“ í´ë˜ìŠ¤ë³„ í´ë” êµ¬ì¡° ê°ì§€: {class_names}")
        
        for class_idx, class_name in enumerate(class_names):
            class_dir = data_path / class_name
            if not class_dir.exists():
                continue
                
            class_images = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
                class_images.extend(list(class_dir.glob(ext)))
            
            image_paths.extend([str(p) for p in class_images])
            labels.extend([class_idx] * len(class_images))
            
            print(f"  {class_name}: {len(class_images)}ê°œ ì´ë¯¸ì§€")
    
    else:  # ë‹¨ì¼ í´ë” êµ¬ì¡°
        print("ğŸ“ ë‹¨ì¼ í´ë” êµ¬ì¡° ê°ì§€")
        
        all_images = []
        for ext in ['*.jpg', '*.jpeg', '*.png', '*.bmp']:
            all_images.extend(list(data_path.glob(ext)))
        
        image_paths = [str(p) for p in all_images]
        labels = [0] * len(all_images)  # ëª¨ë“  ì´ë¯¸ì§€ì— ë ˆì´ë¸” 0 í• ë‹¹
        
        print(f"  ì´ {len(all_images)}ê°œ ì´ë¯¸ì§€")
    
    if not image_paths:
        raise ValueError(f"ì´ë¯¸ì§€ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_dir}")
    
    return image_paths, labels


if __name__ == "__main__":
    # ì‚¬ìš© ì˜ˆì‹œ
    try:
        print("ğŸ§ª AdaptiveDocumentDataset í…ŒìŠ¤íŠ¸")
        
        # ë”ë¯¸ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸
        dummy_paths = ["test1.jpg", "test2.jpg", "test3.jpg"]
        dummy_labels = [0, 1, 0]
        test_dir = "input/data/test"
        
        # ì‹¤ì œë¡œëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì‚¬ìš©:
        # train_paths, train_labels = load_image_paths_and_labels("input/data/train")
        # dataset = AdaptiveDocumentDataset(train_paths, train_labels, test_dir)
        
        print("âœ… ëª¨ë“ˆ ì„í¬íŠ¸ ë° ê¸°ë³¸ êµ¬ì¡° í™•ì¸ ì™„ë£Œ")
        
    except Exception as e:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
        print("ì‹¤ì œ ë°ì´í„° ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.") 