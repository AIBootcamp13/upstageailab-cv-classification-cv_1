# -*- coding: utf-8 -*-
"""baseline_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjsn3XqvQPx3tqy-ZNsGwYhI0MVkVH7b

# **ğŸ“„ Document type classification baseline code**
> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     
> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- Load Data
- Train Model
- Inference & Save File

"""

import os
import time
import random

import hydra
from omegaconf import DictConfig, OmegaConf
import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split, StratifiedKFold

# í™˜ê²½ë³€ìˆ˜ ë° wandb import
from dotenv import load_dotenv
import wandb

# ë¡œê·¸ ìœ í‹¸ë¦¬í‹° import
import log_util as log

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, csv, path, transform=None):
        if isinstance(csv, str):
            self.df = pd.read_csv(csv).values
        else:
            self.df = csv.values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target


# ì¸ë±ìŠ¤ ê¸°ë°˜ ë°ì´í„°ì…‹ í´ë˜ìŠ¤
class IndexedImageDataset(Dataset):
    def __init__(self, df, path, transform=None):
        self.df = df
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df.iloc[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target


# Early Stopping í´ë˜ìŠ¤
class EarlyStopping:
    def __init__(self, patience=10, min_delta=0.001, monitor='val_loss', mode='min'):
        self.patience = patience
        self.min_delta = min_delta
        self.monitor = monitor
        self.mode = mode
        self.counter = 0
        self.best_score = None
        self.should_stop = False
        
    def __call__(self, val_metrics):
        score = val_metrics[self.monitor]
        
        if self.best_score is None:
            self.best_score = score
        elif self.mode == 'min':
            if score < self.best_score - self.min_delta:
                self.best_score = score
                self.counter = 0
            else:
                self.counter += 1
        elif self.mode == 'max':
            if score > self.best_score + self.min_delta:
                self.best_score = score
                self.counter = 0
            else:
                self.counter += 1
                
        if self.counter >= self.patience:
            self.should_stop = True
            
        return self.should_stop

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader)
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)

        model.zero_grad(set_to_none=True)

        preds = model(image)
        loss = loss_fn(preds, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret


# one epoch ê²€ì¦ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def validate_one_epoch(loader, model, loss_fn, device):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []

    with torch.no_grad():
        for image, targets in tqdm(loader, desc="Validating"):
            image = image.to(device)
            targets = targets.to(device)

            preds = model(image)
            loss = loss_fn(preds, targets)

            val_loss += loss.item()
            preds_list.extend(preds.argmax(dim=1).cpu().numpy())
            targets_list.extend(targets.cpu().numpy())

    val_loss /= len(loader)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
    }

    return ret

@hydra.main(version_base=None, config_path="config", config_name="config")
def main(cfg: DictConfig) -> None:
    """## 3. Hyper-parameters
    * í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
    """
    
    # ì„¤ì • ì¶œë ¥
    log.info(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ:")
    log.info(f"\n{OmegaConf.to_yaml(cfg)}")
    
    # wandb ì´ˆê¸°í™”
    if cfg.wandb.enabled:
        wandb_config = {
            "learning_rate": cfg.training.lr,
            "epochs": cfg.training.epochs,
            "batch_size": cfg.training.batch_size,
            "model_name": cfg.model.name,
            "img_size": cfg.data.img_size,
            "seed": cfg.training.seed,
            "num_classes": cfg.model.num_classes,
            "pretrained": cfg.model.pretrained,
        }
        
        # .env íŒŒì¼ì—ì„œ wandb ì„¤ì • ë¶ˆëŸ¬ì˜¤ê¸°
        wandb_entity = os.getenv("WANDB_ENTITY") or cfg.wandb.entity
        wandb_project = os.getenv("WANDB_PROJECT") or cfg.wandb.project
        
        wandb.init(
            project=wandb_project,
            entity=wandb_entity,
            config=wandb_config,
            name=cfg.wandb.run_name,
            tags=cfg.wandb.tags,
            notes=cfg.wandb.notes,
        )
        log.info(f"wandb ì´ˆê¸°í™” ì™„ë£Œ - í”„ë¡œì íŠ¸: {wandb_project}")
    else:
        log.info("wandb ë¹„í™œì„±í™”ë¨")
    
    # ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
    SEED = cfg.training.seed
    os.environ['PYTHONHASHSEED'] = str(SEED)
    random.seed(SEED)
    np.random.seed(SEED)
    torch.manual_seed(SEED)
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.benchmark = True

    log.info("í™˜ê²½ ì„¤ì • ì™„ë£Œ")

    # device
    device = torch.device('cuda' if torch.cuda.is_available() and cfg.device == 'cuda' else 'cpu')
    log.info(f"ì‚¬ìš© ì¥ì¹˜: {device}")

    # data config
    data_path = cfg.data.data_path

    # model config
    model_name = cfg.model.name

    # training config
    img_size = cfg.data.img_size
    LR = cfg.training.lr
    EPOCHS = cfg.training.epochs
    BATCH_SIZE = cfg.training.batch_size
    num_workers = cfg.data.num_workers

    log.info(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • - ëª¨ë¸: {model_name}, ì´ë¯¸ì§€ í¬ê¸°: {img_size}, í•™ìŠµë¥ : {LR}, ì—í¬í¬: {EPOCHS}, ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")

    """## 4. Load Data
    * í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """

    # augmentationì„ ìœ„í•œ transform ì½”ë“œ
    trn_transform = A.Compose([
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        A.Resize(height=img_size, width=img_size),
        # images normalization
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
        ToTensorV2(),
    ])

    # test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ
    tst_transform = A.Compose([
        A.Resize(height=img_size, width=img_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

    # ì „ì²´ í›ˆë ¨ ë°ì´í„° ë¡œë“œ
    full_train_df = pd.read_csv(f"{data_path}/train.csv")
    
    # í…ŒìŠ¤íŠ¸ ë°ì´í„°ëŠ” ë¯¸ë¦¬ ë¡œë“œ
    tst_dataset = ImageDataset(
        f"{data_path}/sample_submission.csv",
        f"{data_path}/test/",
        transform=tst_transform
    )
    tst_loader = DataLoader(
        tst_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    log.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ - ì „ì²´ í›ˆë ¨ ë°ì´í„°: {len(full_train_df)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(tst_dataset)}ê°œ")

    # Validation ì „ëµì— ë”°ë¥¸ ë°ì´í„° ë¶„í• 
    validation_strategy = cfg.validation.strategy
    
    if validation_strategy == "holdout":
        # Holdout validation
        train_ratio = cfg.validation.holdout.train_ratio
        stratify = cfg.validation.holdout.stratify
        
        if stratify:
            train_df, val_df = train_test_split(
                full_train_df, 
                test_size=1-train_ratio, 
                stratify=full_train_df['target'], 
                random_state=SEED
            )
        else:
            train_df, val_df = train_test_split(
                full_train_df, 
                test_size=1-train_ratio, 
                random_state=SEED
            )
        
        # Dataset ì •ì˜
        trn_dataset = IndexedImageDataset(train_df, f"{data_path}/train/", transform=trn_transform)
        val_dataset = IndexedImageDataset(val_df, f"{data_path}/train/", transform=tst_transform)
        
        # DataLoader ì •ì˜
        trn_loader = DataLoader(
            trn_dataset, batch_size=BATCH_SIZE, shuffle=True, 
            num_workers=num_workers, pin_memory=True, drop_last=False
        )
        val_loader = DataLoader(
            val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
            num_workers=num_workers, pin_memory=True
        )
        
        log.info(f"Holdout ê²€ì¦ ì„¤ì • ì™„ë£Œ - í›ˆë ¨: {len(train_df)}ê°œ, ê²€ì¦: {len(val_df)}ê°œ")
        
    elif validation_strategy == "kfold":
        # K-Fold validation
        n_splits = cfg.validation.kfold.n_splits
        stratify = cfg.validation.kfold.stratify
        
        if stratify:
            skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)
            folds = list(skf.split(full_train_df, full_train_df['target']))
        else:
            from sklearn.model_selection import KFold
            kf = KFold(n_splits=n_splits, shuffle=True, random_state=SEED)
            folds = list(kf.split(full_train_df))
        
        log.info(f"K-Fold ê²€ì¦ ì„¤ì • ì™„ë£Œ - {n_splits}ê°œ fold")
        
    elif validation_strategy == "none":
        # No validation
        trn_dataset = IndexedImageDataset(full_train_df, f"{data_path}/train/", transform=trn_transform)
        trn_loader = DataLoader(
            trn_dataset, batch_size=BATCH_SIZE, shuffle=True, 
            num_workers=num_workers, pin_memory=True, drop_last=False
        )
        val_loader = None
        log.info("ê²€ì¦ ì—†ì´ ì „ì²´ ë°ì´í„°ë¡œ í•™ìŠµ")
        
    else:
        raise ValueError(f"Unknown validation strategy: {validation_strategy}")

    """## 5. Train Model
    * ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.
    """

    if validation_strategy == "kfold":
        # K-Fold êµì°¨ ê²€ì¦
        final_predictions = []
        
        for fold_idx, (train_idx, val_idx) in enumerate(folds):
            log.info(f"========== Fold {fold_idx + 1}/{n_splits} ==========")
            
            # í˜„ì¬ foldì˜ ë°ì´í„° ë¶„í• 
            train_df = full_train_df.iloc[train_idx]
            val_df = full_train_df.iloc[val_idx]
            
            # Dataset ì •ì˜
            trn_dataset = IndexedImageDataset(train_df, f"{data_path}/train/", transform=trn_transform)
            val_dataset = IndexedImageDataset(val_df, f"{data_path}/train/", transform=tst_transform)
            
            # DataLoader ì •ì˜
            trn_loader = DataLoader(
                trn_dataset, batch_size=BATCH_SIZE, shuffle=True, 
                num_workers=num_workers, pin_memory=True, drop_last=False
            )
            val_loader = DataLoader(
                val_dataset, batch_size=BATCH_SIZE, shuffle=False, 
                num_workers=num_workers, pin_memory=True
            )
            
            # ëª¨ë¸ ì´ˆê¸°í™”
            model = timm.create_model(
                model_name,
                pretrained=cfg.model.pretrained,
                num_classes=cfg.model.num_classes
            ).to(device)
            loss_fn = nn.CrossEntropyLoss()
            optimizer = Adam(model.parameters(), lr=LR)
            
            log.info(f"Fold {fold_idx + 1} ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - í›ˆë ¨: {len(train_df)}ê°œ, ê²€ì¦: {len(val_df)}ê°œ")
            
            # Early stopping ì´ˆê¸°í™”
            early_stopping = None
            if cfg.validation.early_stopping.enabled:
                early_stopping = EarlyStopping(
                    patience=cfg.validation.early_stopping.patience,
                    min_delta=cfg.validation.early_stopping.min_delta,
                    monitor=cfg.validation.early_stopping.monitor,
                    mode=cfg.validation.early_stopping.mode
                )
            
            # í•™ìŠµ ì‹œì‘
            for epoch in range(EPOCHS):
                # í›ˆë ¨
                train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)
                # ê²€ì¦
                val_ret = validate_one_epoch(val_loader, model, loss_fn, device=device)
                
                # ê²°ê³¼ í•©ì¹˜ê¸°
                ret = {**train_ret, **val_ret, 'epoch': epoch, 'fold': fold_idx + 1}
                
                log_message = f"Fold {fold_idx + 1} Epoch {epoch+1}/{EPOCHS} ì™„ë£Œ - "
                log_message += f"train_loss: {ret['train_loss']:.4f}, "
                log_message += f"train_acc: {ret['train_acc']:.4f}, "
                log_message += f"val_loss: {ret['val_loss']:.4f}, "
                log_message += f"val_acc: {ret['val_acc']:.4f}, "
                log_message += f"val_f1: {ret['val_f1']:.4f}"
                log.info(log_message)
                
                # wandb ë¡œê¹…
                if cfg.wandb.enabled:
                    wandb.log({
                        "fold": fold_idx + 1,
                        "epoch": epoch + 1,
                        "train_loss": ret['train_loss'],
                        "train_acc": ret['train_acc'],
                        "train_f1": ret['train_f1'],
                        "val_loss": ret['val_loss'],
                        "val_acc": ret['val_acc'],
                        "val_f1": ret['val_f1'],
                    })
                
                # Early stopping ì²´í¬
                if early_stopping is not None:
                    if early_stopping(ret):
                        log.info(f"Early stopping at epoch {epoch + 1}")
                        break
            
            # í˜„ì¬ foldì˜ í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡
            log.info(f"Fold {fold_idx + 1} í…ŒìŠ¤íŠ¸ ì˜ˆì¸¡ ì‹œì‘")
            fold_predictions = []
            model.eval()
            with torch.no_grad():
                for image, _ in tqdm(tst_loader, desc=f"Fold {fold_idx + 1} Inference"):
                    image = image.to(device)
                    preds = model(image)
                    fold_predictions.extend(preds.softmax(dim=1).cpu().numpy())
            
            final_predictions.append(fold_predictions)
            log.info(f"Fold {fold_idx + 1} ì™„ë£Œ")
        
        # ì•™ìƒë¸” ì˜ˆì¸¡
        log.info("K-Fold ì•™ìƒë¸” ì˜ˆì¸¡ ê³„ì‚° ì¤‘...")
        ensemble_predictions = np.mean(final_predictions, axis=0)
        final_preds = np.argmax(ensemble_predictions, axis=1)
        
    else:
        # Holdout ë˜ëŠ” No validation
        # ëª¨ë¸ ì´ˆê¸°í™”
        model = timm.create_model(
            model_name,
            pretrained=cfg.model.pretrained,
            num_classes=cfg.model.num_classes
        ).to(device)
        loss_fn = nn.CrossEntropyLoss()
        optimizer = Adam(model.parameters(), lr=LR)
        
        log.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - {model_name}, í´ë˜ìŠ¤ ìˆ˜: {cfg.model.num_classes}ê°œ")
        
        # Early stopping ì´ˆê¸°í™”
        early_stopping = None
        if val_loader is not None and cfg.validation.early_stopping.enabled:
            early_stopping = EarlyStopping(
                patience=cfg.validation.early_stopping.patience,
                min_delta=cfg.validation.early_stopping.min_delta,
                monitor=cfg.validation.early_stopping.monitor,
                mode=cfg.validation.early_stopping.mode
            )
        
        log.info("í•™ìŠµ ì‹œì‘")
        
        for epoch in range(EPOCHS):
            # í›ˆë ¨
            train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)
            ret = {**train_ret, 'epoch': epoch}
            
            # ê²€ì¦ (holdoutì¸ ê²½ìš°)
            if val_loader is not None:
                val_ret = validate_one_epoch(val_loader, model, loss_fn, device=device)
                ret.update(val_ret)
                
                log_message = f"Epoch {epoch+1}/{EPOCHS} ì™„ë£Œ - "
                log_message += f"train_loss: {ret['train_loss']:.4f}, "
                log_message += f"train_acc: {ret['train_acc']:.4f}, "
                log_message += f"val_loss: {ret['val_loss']:.4f}, "
                log_message += f"val_acc: {ret['val_acc']:.4f}, "
                log_message += f"val_f1: {ret['val_f1']:.4f}"
                log.info(log_message)
                
                # wandb ë¡œê¹…
                if cfg.wandb.enabled:
                    wandb.log({
                        "epoch": epoch + 1,
                        "train_loss": ret['train_loss'],
                        "train_acc": ret['train_acc'],
                        "train_f1": ret['train_f1'],
                        "val_loss": ret['val_loss'],
                        "val_acc": ret['val_acc'],
                        "val_f1": ret['val_f1'],
                    })
            else:
                # No validation
                log_message = f"Epoch {epoch+1}/{EPOCHS} ì™„ë£Œ - "
                log_message += f"train_loss: {ret['train_loss']:.4f}, "
                log_message += f"train_acc: {ret['train_acc']:.4f}, "
                log_message += f"train_f1: {ret['train_f1']:.4f}"
                log.info(log_message)
                
                # wandb ë¡œê¹…
                if cfg.wandb.enabled:
                    wandb.log({
                        "epoch": epoch + 1,
                        "train_loss": ret['train_loss'],
                        "train_acc": ret['train_acc'],
                        "train_f1": ret['train_f1'],
                    })
            
            # Early stopping ì²´í¬
            if early_stopping is not None:
                if early_stopping(ret):
                    log.info(f"Early stopping at epoch {epoch + 1}")
                    break

    """# 6. Inference & Save File
    * í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """

    if validation_strategy == "kfold":
        # K-FoldëŠ” ì´ë¯¸ ì•™ìƒë¸” ì˜ˆì¸¡ ì™„ë£Œ
        log.info("K-Fold ì•™ìƒë¸” ì˜ˆì¸¡ ì‚¬ìš©")
        preds_list = final_preds
    else:
        # Holdout ë˜ëŠ” No validation
        log.info("ì¶”ë¡  ì‹œì‘")
        
        preds_list = []
        model.eval()
        for image, _ in tqdm(tst_loader):
            image = image.to(device)

            with torch.no_grad():
                preds = model(image)
            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())

    pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])
    pred_df['target'] = preds_list

    sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
    assert (sample_submission_df['ID'] == pred_df['ID']).all()

    output_path = cfg.output.dir
    os.makedirs(output_path, exist_ok=True)
    pred_df.to_csv(f"{output_path}/{cfg.output.filename}", index=False)

    log.info(f"ì¶”ë¡  ì™„ë£Œ - ê²°ê³¼ íŒŒì¼ ì €ì¥: {output_path}/{cfg.output.filename}")
    
    # wandb ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ
    if cfg.wandb.enabled:
        # ì•„í‹°íŒ©íŠ¸ ìƒì„± ë° ì—…ë¡œë“œ
        artifact = wandb.Artifact(
            name="predictions",
            type="predictions",
            description=f"Model predictions using {model_name}",
            metadata={
                "model_name": model_name,
                "epochs": EPOCHS,
                "batch_size": BATCH_SIZE,
                "learning_rate": LR,
                "img_size": img_size,
                "num_predictions": len(pred_df),
                "output_filename": cfg.output.filename,
            }
        )
        
        # ê²°ê³¼ íŒŒì¼ì„ ì•„í‹°íŒ©íŠ¸ì— ì¶”ê°€
        artifact.add_file(f"{output_path}/{cfg.output.filename}")
        
        # ì•„í‹°íŒ©íŠ¸ ë¡œê¹…
        wandb.log_artifact(artifact)
        log.info(f"wandb ì•„í‹°íŒ©íŠ¸ ì—…ë¡œë“œ ì™„ë£Œ - ì˜ˆì¸¡ ê²°ê³¼ íŒŒì¼: {cfg.output.filename}")
    
    log.info("ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")

    # wandb ì„¸ì…˜ ì¢…ë£Œ
    if cfg.wandb.enabled:
        wandb.finish()
        log.info("wandb ì„¸ì…˜ ì¢…ë£Œ")

    print(pred_df.head())

if __name__ == "__main__":
    main()
