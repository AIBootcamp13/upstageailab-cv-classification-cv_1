# -*- coding: utf-8 -*-
"""baseline_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjsn3XqvQPx3tqy-ZNsGwYhI0MVkVH7b

# **📄 Document type classification baseline code**
> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     
> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- Load Data
- Train Model
- Inference & Save File

## 1. Prepare Environments

* 데이터 로드를 위한 구글 드라이브를 마운트합니다.
* 필요한 라이브러리를 설치합니다.
"""

# 구글 드라이브 마운트, Colab을 이용하지 않는다면 패스해도 됩니다.
# from google.colab import drive
# drive.mount('/gdrive', force_remount=True)
# drive.mount('/content/drive')

# 구글 드라이브에 업로드된 대회 데이터를 압축 해제하고 로컬에 저장합니다.
# !tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null

# 필요한 라이브러리를 설치합니다.
# !pip install timm

"""## 2. Import Library & Define Functions
* 학습 및 추론에 필요한 라이브러리를 로드합니다.
* 학습 및 추론에 필요한 함수와 클래스를 정의합니다.
"""

import os
import time
import random

import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split, StratifiedKFold

# 로그 유틸리티 import
import utils.log_util as log


# 시드를 고정합니다.
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)

# CUDA 10.2+ 환경에서 결정적 연산을 위한 환경 변수 설정
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

# 완전한 재현성을 위한 설정
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# CUDA 환경에서 결정적 연산 설정 (선택적)
try:
    torch.use_deterministic_algorithms(True)
    log.info("완전한 재현성 설정이 활성화되었습니다.")
except Exception as e:
    log.info(f"torch.use_deterministic_algorithms(True) 설정 실패: {e}")
    log.info("기본 재현성 설정만 사용됩니다.")

# 현재 스크립트 위치를 작업 디렉토리로 설정
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# 데이터셋 클래스를 정의합니다.
class ImageDataset(Dataset):
    def __init__(self, csv_data, path, transform=None):
        # csv_data가 DataFrame인 경우와 파일 경로인 경우를 구분
        if isinstance(csv_data, str):
            self.df = pd.read_csv(csv_data).values
        else:
            self.df = csv_data.values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target

# one epoch 학습을 위한 함수입니다.
def train_one_epoch(loader, model, optimizer, loss_fn, device):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader, desc="Training")
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)

        model.zero_grad(set_to_none=True)

        preds = model(image)
        loss = loss_fn(preds, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Training Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret

# one epoch 검증을 위한 함수입니다.
def validate_one_epoch(loader, model, loss_fn, device):
    model.eval()
    valid_loss = 0
    preds_list = []
    targets_list = []

    with torch.no_grad():
        pbar = tqdm(loader, desc="Validation")
        for image, targets in pbar:
            image = image.to(device)
            targets = targets.to(device)

            preds = model(image)
            loss = loss_fn(preds, targets)

            valid_loss += loss.item()
            preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
            targets_list.extend(targets.detach().cpu().numpy())

            pbar.set_description(f"Validation Loss: {loss.item():.4f}")

    valid_loss /= len(loader)
    valid_acc = accuracy_score(targets_list, preds_list)
    valid_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "valid_loss": valid_loss,
        "valid_acc": valid_acc,
        "valid_f1": valid_f1,
    }

    return ret

"""## 3. Hyper-parameters
* 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다.
"""

# device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

# data config
data_path = '../input/data'

# model config
model_name = 'resnet34' # 'resnet50' 'efficientnet-b0', ...

# training config
img_size = 343
LR = 1e-3
EPOCHS = 50  # early stopping을 위해 충분히 큰 값으로 설정
BATCH_SIZE = 32
num_workers = 0

# early stopping config
PATIENCE = 7  # 성능이 개선되지 않는 epoch 수
MIN_DELTA = 1e-4  # 개선으로 간주할 최소 변화량

"""## 4. Load Data
* 학습, 검증, 테스트 데이터셋과 로더를 정의합니다.
"""

# augmentation을 위한 transform 코드
trn_transform = A.Compose([
    # 이미지 크기 조정
    A.Resize(height=img_size, width=img_size),
    # images normalization
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환
    ToTensorV2(),
])

# test image 변환을 위한 transform 코드
tst_transform = A.Compose([
    A.Resize(height=img_size, width=img_size),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# 원본 훈련 데이터 로드
train_df = pd.read_csv(f"{data_path}/train.csv")

# 테스트 데이터셋 정의 (K-Fold 외부에서 한 번만 정의)
tst_dataset = ImageDataset(
    f"{data_path}/sample_submission.csv",
    f"{data_path}/test/",
    transform=tst_transform
)
tst_loader = DataLoader(
    tst_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=0,
    pin_memory=True
)

log.info(f"테스트 데이터셋 크기: {len(tst_dataset)}")

# K-Fold 설정
N_SPLITS = 5 # K-Fold의 분할 수
skf = StratifiedKFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)

all_fold_best_f1 = [] # 각 폴드의 최고 F1 스코어를 저장
model_save_paths = [] # 각 폴드의 모델 저장 경로를 저장

# 모델 저장을 위한 디렉토리 생성
model_save_dir = "saved_models"
os.makedirs(model_save_dir, exist_ok=True)

for fold, (train_index, val_index) in enumerate(skf.split(train_df['ID'], train_df['target'])):
    log.info(f"\n{'=' * 60}")
    log.info(f"Fold {fold+1}/{N_SPLITS} 훈련 시작...")
    log.info(f"{'=' * 60}")

    train_data = train_df.iloc[train_index]
    valid_data = train_df.iloc[val_index]

    log.info(f"Fold {fold+1} 훈련 데이터 크기: {len(train_data)}")
    log.info(f"Fold {fold+1} 검증 데이터 크기: {len(valid_data)}")

    # Dataset 정의
    trn_dataset = ImageDataset(
        train_data,
        f"{data_path}/train/",
        transform=trn_transform
    )
    val_dataset = ImageDataset(
        valid_data,
        f"{data_path}/train/",
        transform=tst_transform
    )

    # DataLoader 정의
    trn_loader = DataLoader(
        trn_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False
    )

    # 모델 로드 (각 폴드마다 새로 로드하여 독립적인 학습 보장)
    model = timm.create_model(
        model_name,
        pretrained=True,
        num_classes=17
    ).to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = Adam(model.parameters(), lr=LR)

    # early stopping을 위한 변수들
    best_f1 = 0.0
    patience_counter = 0
    best_model_state = None

    for epoch in range(EPOCHS):
        log.info(f"\nFold {fold+1} - Epoch {epoch+1}/{EPOCHS}")
        log.info("-" * 40)
        
        # 훈련
        train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)
        
        # 검증
        valid_ret = validate_one_epoch(val_loader, model, loss_fn, device=device)
        
        # 결과 출력
        log.info(f"훈련 - Loss: {train_ret['train_loss']:.4f}, Acc: {train_ret['train_acc']:.4f}, F1: {train_ret['train_f1']:.4f}")
        log.info(f"검증 - Loss: {valid_ret['valid_loss']:.4f}, Acc: {valid_ret['valid_acc']:.4f}, F1: {valid_ret['valid_f1']:.4f}")
        
        # Early stopping 체크
        current_f1 = valid_ret['valid_f1']
        
        if current_f1 > best_f1 + MIN_DELTA:
            best_f1 = current_f1
            patience_counter = 0
            best_model_state = model.state_dict().copy()
            log.info(f"✓ 최고 F1 스코어 갱신: {best_f1:.4f}")
        else:
            patience_counter += 1
            log.info(f"성능 개선 없음 ({patience_counter}/{PATIENCE})")
            
            if patience_counter >= PATIENCE:
                log.info(f"\nEarly stopping! 최고 F1 스코어: {best_f1:.4f}")
                break

    # 최고 성능 모델 저장
    if best_model_state is not None:
        model.load_state_dict(best_model_state)
        model_save_path = os.path.join(model_save_dir, f"fold_{fold+1}_best_model.pth")
        torch.save(best_model_state, model_save_path)
        model_save_paths.append(model_save_path)
        log.info(f"Fold {fold+1} - 최고 성능 모델 저장됨: {model_save_path} (F1: {best_f1:.4f})")
    else:
        # 혹시 best_model_state가 None인 경우 현재 모델 상태 저장
        model_save_path = os.path.join(model_save_dir, f"fold_{fold+1}_best_model.pth")
        torch.save(model.state_dict(), model_save_path)
        model_save_paths.append(model_save_path)
        log.info(f"Fold {fold+1} - 현재 모델 상태 저장됨: {model_save_path} (F1: {best_f1:.4f})")
    
    all_fold_best_f1.append(best_f1)

log.info(f"\n{'=' * 60}")
log.info(f"모든 폴드 훈련 완료. 각 폴드의 최고 F1 스코어: {all_fold_best_f1}")
log.info(f"평균 F1 스코어: {np.mean(all_fold_best_f1):.4f}")
log.info(f"저장된 모델 경로: {model_save_paths}")
log.info(f"{'=' * 60}")

"""# 6. Inference & Save File
* 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다.
* K-Fold 앙상블을 통해 모든 폴드 모델의 예측을 평균내어 최종 예측을 생성합니다.
"""

log.info("\n" + "=" * 60)
log.info("K-Fold 앙상블 테스트 데이터 추론 시작...")
log.info("=" * 60)

# 모든 폴드 모델의 예측 확률을 저장할 리스트
all_fold_probs = []

for fold_idx, model_path in enumerate(model_save_paths):
    log.info(f"Fold {fold_idx+1} 모델로 추론 중...")
    
    # 모델 로드
    model = timm.create_model(
        model_name,
        pretrained=False,  # 저장된 가중치를 사용하므로 pretrained=False
        num_classes=17
    ).to(device)
    
    model.load_state_dict(torch.load(model_path, map_location=device))
    model.eval()
    
    fold_probs = []
    
    with torch.no_grad():
        for image, _ in tqdm(tst_loader, desc=f"Fold {fold_idx+1} 추론"):
            image = image.to(device)
            preds = model(image)
            # 소프트맥스를 적용하여 확률로 변환
            probs = torch.softmax(preds, dim=1)
            fold_probs.extend(probs.detach().cpu().numpy())
    
    all_fold_probs.append(np.array(fold_probs))
    log.info(f"Fold {fold_idx+1} 추론 완료")

# 모든 폴드의 확률을 평균내어 앙상블 예측 생성
log.info("앙상블 예측 생성 중...")
ensemble_probs = np.mean(all_fold_probs, axis=0)
ensemble_preds = np.argmax(ensemble_probs, axis=1)

# 결과 DataFrame 생성
pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])
pred_df['target'] = ensemble_preds

# 검증
sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
assert (sample_submission_df['ID'] == pred_df['ID']).all()

# 결과 저장
output_path = "output"
os.makedirs(output_path, exist_ok=True)
pred_df.to_csv(f"{output_path}/pred_kfold_ensemble.csv", index=False)

log.info(f"\n앙상블 예측 결과가 {output_path}/pred_kfold_ensemble.csv에 저장되었습니다.")
log.info(f"K-Fold 앙상블 검증 평균 F1 스코어: {np.mean(all_fold_best_f1):.4f}")
log.info(f"사용된 폴드 수: {len(model_save_paths)}")

# 추가로 각 폴드별 예측 확률도 저장 (디버깅/분석용)
ensemble_probs_df = pd.DataFrame(ensemble_probs)
ensemble_probs_df.insert(0, 'ID', pred_df['ID'].values)
ensemble_probs_df.to_csv(f"{output_path}/ensemble_probabilities.csv", index=False)
log.info(f"앙상블 확률 결과가 {output_path}/ensemble_probabilities.csv에 저장되었습니다.")

pred_df.head()
