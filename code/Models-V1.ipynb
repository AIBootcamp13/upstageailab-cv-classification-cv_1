{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "073b1c71",
   "metadata": {},
   "source": [
    "### Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "afce244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import timm\n",
    "import torch\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "import shutil\n",
    "import wandb\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from albumentations import Compose, RandomBrightnessContrast, Blur, ShiftScaleRotate, GaussNoise, RandomGamma, CLAHE\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "25c69525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_seed(SEED=42):\n",
    "    # SEED = 42 # default\n",
    "    os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "    random.seed(SEED)\n",
    "    np.random.seed(SEED)\n",
    "    torch.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed(SEED)\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "random_seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb06b4c",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "32449edb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002f99746285dfdd.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008ccd231e1fea5d.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f5911bfda7695.jpg</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009235e4c9c07af5.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b2f44967580c74.jpg</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1565</th>\n",
       "      <td>fed9e9ec4a77bc06.jpg</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1566</th>\n",
       "      <td>feeade617aa68c45.jpg</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>ff51dd281a8423f1.jpg</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1568</th>\n",
       "      <td>ff8a6a251ce51c95.jpg</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1569</th>\n",
       "      <td>ffc22136f958deb1.jpg</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1570 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        ID  target\n",
       "0     002f99746285dfdd.jpg      16\n",
       "1     008ccd231e1fea5d.jpg      10\n",
       "2     008f5911bfda7695.jpg      10\n",
       "3     009235e4c9c07af5.jpg       4\n",
       "4     00b2f44967580c74.jpg      16\n",
       "...                    ...     ...\n",
       "1565  fed9e9ec4a77bc06.jpg       4\n",
       "1566  feeade617aa68c45.jpg       7\n",
       "1567  ff51dd281a8423f1.jpg      11\n",
       "1568  ff8a6a251ce51c95.jpg       5\n",
       "1569  ffc22136f958deb1.jpg       9\n",
       "\n",
       "[1570 rows x 2 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label_path = \"../../data/train.csv\"\n",
    "meta_data_path = \"../../data/meta.csv\"\n",
    "\n",
    "train_df = pd.read_csv(train_label_path)\n",
    "meta_data = pd.read_csv(meta_data_path)\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aac144a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count_plot\n",
    "def count_plot(df, col, figsize=(10, 6), palette=\"Blues_r\", rotation=None, title=None, xlabel=None, ylabel='Count'):\n",
    "    plt.figure(figsize=figsize)\n",
    "    sns.countplot(data=df, x=col, palette=palette)\n",
    "    plt.title(title if title else f'{col} Count')\n",
    "    plt.xticks(rotation=rotation)\n",
    "    plt.xlabel(xlabel if xlabel is not None else col)\n",
    "    plt.ylabel(ylabel)\n",
    "    plt.show()\n",
    "\n",
    "# hist plot\n",
    "def hist_plot(df1, col, df2=None, figsize=(8, 6), bins=30, alpha=0.6, \n",
    "              color1='skyblue', color2='salmon', label1=None, label2=None, \n",
    "              title=None, density=False):\n",
    "    plt.figure(figsize=figsize)\n",
    "    \n",
    "    stat_mode = 'density' if density else 'count'\n",
    "\n",
    "    sns.histplot(df1[col], kde=True, bins=bins, alpha=alpha, color=color1, \n",
    "                 stat=stat_mode, label=label1 if label1 else ('Group 1' if df2 is not None else None))\n",
    "    \n",
    "    if df2 is not None:\n",
    "        sns.histplot(df2[col], kde=True, bins=bins, alpha=alpha, color=color2, \n",
    "                     stat=stat_mode, label=label2 if label2 else 'Group 2')\n",
    "        plt.legend()\n",
    "\n",
    "    plt.title(title if title else f'{col} Distribution ({\"Density\" if density else \"Count\"} Histogram + KDE)')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Density\" if density else \"Count\")\n",
    "    plt.show()\n",
    "\n",
    "# bar plot    \n",
    "def bar_plot(df, x_col, y_col, figsize=(10, 6), hue=None, palette=\"Blues_r\", rotation=None, title=None, xlabel=None, ylabel=None):\n",
    "     plt.figure(figsize=figsize)\n",
    "     \n",
    "     if hue: # hue 지정\n",
    "        sns.barplot(x=x_col, y=y_col, hue=hue, data=df, palette=palette)\n",
    "     else: # hue 지정 X\n",
    "        sns.barplot(x=x_col, y=y_col, data=df, palette=palette)\n",
    "\n",
    "     plt.xticks(rotation=rotation)\n",
    "     plt.title(title)\n",
    "     plt.xlabel(xlabel)\n",
    "     plt.ylabel(ylabel)\n",
    "     plt.show()\n",
    "\n",
    "# heatmap\n",
    "def heat_map(df, target_col=None, figsize=(8, 10), threshold=0, cmap='Reds', method='pearson', annot_kws=None, return_data=False):\n",
    "        df = df.select_dtypes(include=['number'])\n",
    "        \n",
    "        if annot_kws is None:\n",
    "            annot_kws = {\"size\": 10}\n",
    "\n",
    "        if target_col is not None:\n",
    "            corr_series = df.corr(method=method)[target_col].drop(target_col)\n",
    "            corr_filtered = corr_series[abs(corr_series) >= threshold].sort_values(ascending=False)\n",
    "\n",
    "            plt.figure(figsize=figsize)\n",
    "            sns.heatmap(corr_filtered.to_frame(name='Correlation'), annot=True, fmt='.2f', cmap=cmap, annot_kws=annot_kws, cbar=True)\n",
    "            plt.title(f'{method.capitalize()} Correlation with {target_col}', fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "            corr_df = corr_filtered.reset_index()\n",
    "            corr_df.columns = ['Variable', 'Correlation']\n",
    "\n",
    "            if return_data:\n",
    "                return corr_df\n",
    "\n",
    "        else:\n",
    "            corr_matrix = df.corr(method=method) # 전체 변수 간 상관계수\n",
    "\n",
    "            plt.figure(figsize=figsize)\n",
    "            sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap=cmap, annot_kws=annot_kws, cbar=True)\n",
    "            plt.title(f'{method.capitalize()} Correlation Matrix (All Variables)', fontsize=14)\n",
    "            plt.show()\n",
    "\n",
    "            if return_data:\n",
    "                return corr_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7b9378cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class check\n",
    "count_plot(df=train_df, col='target')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69213ccb",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4c40541",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_image(train_df, train_path, save_dir, augmentation, classes):\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    augmented_records = []\n",
    "\n",
    "    for target_class, target_count in classes.items():\n",
    "        current_count = len(train_df[train_df[\"target\"] == target_class])\n",
    "        if current_count >= target_count:\n",
    "            continue\n",
    "\n",
    "        n_to_augment = target_count - current_count\n",
    "        samples = train_df[train_df[\"target\"] == target_class]\n",
    "\n",
    "        print(f\"[INFO] Class {target_class}: 증강 {n_to_augment}개 생성 중...\")\n",
    "        for i in tqdm(range(n_to_augment)):\n",
    "            sample_row = samples.sample(1).iloc[0]\n",
    "            img_name = sample_row['ID']\n",
    "            img_path = os.path.join(train_path, img_name)\n",
    "            true_target = sample_row['target']\n",
    "\n",
    "            img = cv2.imread(img_path)\n",
    "            if img is None:\n",
    "                print(f\"[경고] 이미지 로드 실패: {img_path}\")\n",
    "                continue\n",
    "\n",
    "            img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "            augmented = augmentation(image=img)['image']\n",
    "\n",
    "            aug_name = f\"aug_class{true_target}_{i}_{img_name}\"\n",
    "            aug_path = os.path.join(save_dir, aug_name)\n",
    "            cv2.imwrite(aug_path, cv2.cvtColor(augmented, cv2.COLOR_RGB2BGR))\n",
    "\n",
    "            # 실제 저장 여부를 확인\n",
    "            if not os.path.exists(aug_path):\n",
    "                print(f\"[에러] 증강 이미지 저장 실패: {aug_path}\")\n",
    "                continue\n",
    "\n",
    "            # 디버그용: 증강 대상 및 경로 출력\n",
    "            if i < 3 or i % 50 == 0:\n",
    "                pass\n",
    "                # print(f\"[디버그] Target={true_target}, Saved: {aug_path}\")\n",
    "\n",
    "            augmented_records.append({\"ID\": aug_name, \"target\": true_target})\n",
    "\n",
    "    aug_df = pd.DataFrame(augmented_records)\n",
    "    aug_df.to_csv(\"../../data/augmented.csv\", index=False)\n",
    "    print(\"[완료] 증강 데이터 생성 및 레이블 저장 완료\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bafd1bbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Class 1: 증강 54개 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 54/54 [00:00<00:00, 204.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Class 13: 증강 26개 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 26/26 [00:00<00:00, 296.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Class 14: 증강 50개 생성 중...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:00<00:00, 302.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[완료] 증강 데이터 생성 및 레이블 저장 완료\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "augmentation = A.Compose([\n",
    "    A.RandomBrightnessContrast(limit=0.1, p=0.3),  # 밝기 & 대비: limit 줄이고 확률 30%\n",
    "    A.Blur(blur_limit=2, p=0.2),                  # 블러: 흐림 강도 크게 낮추고 확률 10%\n",
    "    A.ShiftScaleRotate(                            # 이동/스케일/회전: 범위 축소 & 확률 20%\n",
    "        shift_limit=0.02, scale_limit=0.05, rotate_limit=5, p=0.2\n",
    "    ),\n",
    "    A.OneOf([                                      # 테스트셋처럼 강한 회전/반전 케이스 생성\n",
    "        A.Rotate(limit=[-90, 90], p=0.2),          # ±90도까지 강한 회전 허용\n",
    "        A.HorizontalFlip(p=0.2),                   # 좌우 반전\n",
    "        A.VerticalFlip(p=0.1),                     # 상하 반전\n",
    "    ], p=0.3),                                     # 위 셋 중 하나를 30% 확률로 적용\n",
    "\n",
    "    # A.GaussNoise(var_limit=(0.001, 0.01), mean=0, p=0.05),     # 노이즈: 강도 크게 낮추고 확률 10%\n",
    "    A.RandomGamma(gamma_limit=(95, 105), p=0.2),   # 감마: 조정 범위를 매우 좁게\n",
    "    A.CLAHE(clip_limit=1.5, p=0.2),                # CLAHE: 대비 과도 상승 방지\n",
    "])\n",
    "save_dir=\"../../data/augmented_images\"\n",
    "classes={1: 100, 13: 100, 14: 100}\n",
    "train_path = '../../data/train/'\n",
    "test_path = '../../data/test/'\n",
    "\n",
    "augment_image(train_df=train_df, train_path=train_path, save_dir=save_dir, augmentation=augmentation, classes=classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "822b0429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>target</th>\n",
       "      <th>full_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>002f99746285dfdd.jpg</td>\n",
       "      <td>16</td>\n",
       "      <td>../../data/train/002f99746285dfdd.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>008ccd231e1fea5d.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>../../data/train/008ccd231e1fea5d.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>008f5911bfda7695.jpg</td>\n",
       "      <td>10</td>\n",
       "      <td>../../data/train/008f5911bfda7695.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>009235e4c9c07af5.jpg</td>\n",
       "      <td>4</td>\n",
       "      <td>../../data/train/009235e4c9c07af5.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00b2f44967580c74.jpg</td>\n",
       "      <td>16</td>\n",
       "      <td>../../data/train/00b2f44967580c74.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>aug_class14_45_76ff32bef566bd38.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>../../data/augmented_images/aug_class14_45_76f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>aug_class14_46_c323c86de8033ad1.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>../../data/augmented_images/aug_class14_46_c32...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>aug_class14_47_706f88bd829080ed.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>../../data/augmented_images/aug_class14_47_706...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1698</th>\n",
       "      <td>aug_class14_48_80f998b8dd043ab3.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>../../data/augmented_images/aug_class14_48_80f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1699</th>\n",
       "      <td>aug_class14_49_7c6fb8ca1b30ee46.jpg</td>\n",
       "      <td>14</td>\n",
       "      <td>../../data/augmented_images/aug_class14_49_7c6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1700 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       ID  target  \\\n",
       "0                    002f99746285dfdd.jpg      16   \n",
       "1                    008ccd231e1fea5d.jpg      10   \n",
       "2                    008f5911bfda7695.jpg      10   \n",
       "3                    009235e4c9c07af5.jpg       4   \n",
       "4                    00b2f44967580c74.jpg      16   \n",
       "...                                   ...     ...   \n",
       "1695  aug_class14_45_76ff32bef566bd38.jpg      14   \n",
       "1696  aug_class14_46_c323c86de8033ad1.jpg      14   \n",
       "1697  aug_class14_47_706f88bd829080ed.jpg      14   \n",
       "1698  aug_class14_48_80f998b8dd043ab3.jpg      14   \n",
       "1699  aug_class14_49_7c6fb8ca1b30ee46.jpg      14   \n",
       "\n",
       "                                              full_path  \n",
       "0                 ../../data/train/002f99746285dfdd.jpg  \n",
       "1                 ../../data/train/008ccd231e1fea5d.jpg  \n",
       "2                 ../../data/train/008f5911bfda7695.jpg  \n",
       "3                 ../../data/train/009235e4c9c07af5.jpg  \n",
       "4                 ../../data/train/00b2f44967580c74.jpg  \n",
       "...                                                 ...  \n",
       "1695  ../../data/augmented_images/aug_class14_45_76f...  \n",
       "1696  ../../data/augmented_images/aug_class14_46_c32...  \n",
       "1697  ../../data/augmented_images/aug_class14_47_706...  \n",
       "1698  ../../data/augmented_images/aug_class14_48_80f...  \n",
       "1699  ../../data/augmented_images/aug_class14_49_7c6...  \n",
       "\n",
       "[1700 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df = pd.read_csv(\"../../data/augmented.csv\")\n",
    "train_dfs = pd.concat([train_df, aug_df], ignore_index=True)\n",
    "train_dfs[\"full_path\"] = train_dfs[\"ID\"].apply(\n",
    "    lambda x: os.path.join(\n",
    "        \"../../data/augmented_images\" if x.startswith(\"aug_\") else \"../../data/train\", x\n",
    "    )\n",
    ")\n",
    "train_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "10d9f511",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Class check\n",
    "count_plot(df=train_dfs, col='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9f5228d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df.values\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target, full_path = self.df[idx]  # 3개 컬럼 순서 주의\n",
    "        img = np.array(Image.open(full_path))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "48a1befb",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model_name = \"convnextv2_large.fcmae_ft_in22k_in1k\"  \n",
    "img_size = 256 \n",
    "LR = 5e-5\n",
    "EPOCHS = 60\n",
    "BATCH_SIZE = 4\n",
    "num_workers = 2 # GPU 사용\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),   # 1) 이미지 크기 통일\n",
    "    A.Normalize(                                 # 2) 픽셀 정규화\n",
    "        mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),                                # 3) 텐서 변환\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(height=img_size, width=img_size),   # 1) 이미지 크기 통일\n",
    "    A.Normalize(                                 # 2) 픽셀 정규화\n",
    "        mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
    "    ToTensorV2(),                                # 3) 텐서 변환\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52b7dc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 1 ===\n",
      "Fold 1: Train samples=1360, Val samples=340\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mmoonstalker9010\u001b[0m (\u001b[33mmoonstalker9010-none\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../wandb/run-20250702_141456-223tazis</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/223tazis' target=\"_blank\">fold_1</a></strong> to <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/223tazis' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/223tazis</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 1/60] Training: 100%|██████████| 340/340 [00:54<00:00,  6.22it/s, loss=0.0125] \n",
      "[Fold 1][Epoch 1/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep1 - Train: 0.8823 | VaL: 0.3146, Acc: 0.8853, F1: 0.8816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 2/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.61it/s, loss=0.267]  \n",
      "[Fold 1][Epoch 2/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep2 - Train: 0.2241 | VaL: 0.2554, Acc: 0.8971, F1: 0.8848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 3/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.57it/s, loss=0.74]    \n",
      "[Fold 1][Epoch 3/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep3 - Train: 0.1482 | VaL: 0.3541, Acc: 0.8824, F1: 0.8753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 4/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0114]  \n",
      "[Fold 1][Epoch 4/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep4 - Train: 0.1114 | VaL: 0.2595, Acc: 0.9176, F1: 0.9168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 5/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.086]   \n",
      "[Fold 1][Epoch 5/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep5 - Train: 0.0425 | VaL: 0.2564, Acc: 0.9206, F1: 0.9191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 6/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000273]\n",
      "[Fold 1][Epoch 6/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep6 - Train: 0.0509 | VaL: 0.3175, Acc: 0.9176, F1: 0.9130\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 7/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000819]\n",
      "[Fold 1][Epoch 7/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep7 - Train: 0.0605 | VaL: 0.2390, Acc: 0.9324, F1: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 8/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0102]  \n",
      "[Fold 1][Epoch 8/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep8 - Train: 0.0402 | VaL: 0.3875, Acc: 0.9176, F1: 0.9157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 9/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000481]\n",
      "[Fold 1][Epoch 9/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep9 - Train: 0.0362 | VaL: 0.2101, Acc: 0.9235, F1: 0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 10/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000123]\n",
      "[Fold 1][Epoch 10/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep10 - Train: 0.0168 | VaL: 0.3131, Acc: 0.9118, F1: 0.9098\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 11/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000684]\n",
      "[Fold 1][Epoch 11/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep11 - Train: 0.0018 | VaL: 0.3051, Acc: 0.9324, F1: 0.9346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 12/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0122]  \n",
      "[Fold 1][Epoch 12/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep12 - Train: 0.0015 | VaL: 0.4902, Acc: 0.9206, F1: 0.9152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 13/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0177]  \n",
      "[Fold 1][Epoch 13/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep13 - Train: 0.1533 | VaL: 0.3871, Acc: 0.9206, F1: 0.9184\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 14/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=4.37e-5] \n",
      "[Fold 1][Epoch 14/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep14 - Train: 0.0445 | VaL: 0.2410, Acc: 0.9441, F1: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 15/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000986]\n",
      "[Fold 1][Epoch 15/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep15 - Train: 0.0323 | VaL: 0.4074, Acc: 0.9235, F1: 0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 16/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000191]\n",
      "[Fold 1][Epoch 16/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep16 - Train: 0.0061 | VaL: 0.3724, Acc: 0.9265, F1: 0.9264\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 17/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000559]\n",
      "[Fold 1][Epoch 17/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep17 - Train: 0.0009 | VaL: 0.3832, Acc: 0.9382, F1: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 18/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=2.05e-5] \n",
      "[Fold 1][Epoch 18/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep18 - Train: 0.0003 | VaL: 0.3807, Acc: 0.9353, F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 1][Epoch 19/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=6.53e-6] \n",
      "[Fold 1][Epoch 19/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F1] Ep19 - Train: 0.0004 | VaL: 0.4184, Acc: 0.9294, F1: 0.9307\n",
      "[Fold 1] Early stopping triggered. Best F1: 0.9435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▃▄▄▅▅▅▆▆▆▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▃▁▅▅▅▇▅▆▄▇▅▅█▆▆▇▇▆</td></tr><tr><td>val_f1</td><td>▂▂▁▅▅▅▇▅▆▅▇▅▅█▆▆▇▇▇</td></tr><tr><td>val_loss</td><td>▄▂▅▂▂▄▂▅▁▄▃█▅▂▆▅▅▅▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>19</td></tr><tr><td>fold</td><td>1</td></tr><tr><td>train_loss</td><td>0.00039</td></tr><tr><td>val_acc</td><td>0.92941</td></tr><tr><td>val_f1</td><td>0.93071</td></tr><tr><td>val_loss</td><td>0.41837</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_1</strong> at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/223tazis' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/223tazis</a><br> View project at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../../wandb/run-20250702_141456-223tazis/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 2 ===\n",
      "Fold 2: Train samples=1360, Val samples=340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../wandb/run-20250702_143230-arf2cm1h</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/arf2cm1h' target=\"_blank\">fold_2</a></strong> to <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/arf2cm1h' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/arf2cm1h</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 1/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=1.46]   \n",
      "[Fold 2][Epoch 1/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep1 - Train: 0.8501 | VaL: 0.4286, Acc: 0.8559, F1: 0.8399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 2/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.56it/s, loss=0.296]  \n",
      "[Fold 2][Epoch 2/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep2 - Train: 0.2342 | VaL: 0.2523, Acc: 0.9147, F1: 0.9107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 3/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.82]    \n",
      "[Fold 2][Epoch 3/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep3 - Train: 0.1544 | VaL: 0.2219, Acc: 0.9265, F1: 0.9153\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 4/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.00052] \n",
      "[Fold 2][Epoch 4/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep4 - Train: 0.0837 | VaL: 0.1582, Acc: 0.9294, F1: 0.9255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 5/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.294]   \n",
      "[Fold 2][Epoch 5/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep5 - Train: 0.0629 | VaL: 0.2662, Acc: 0.9294, F1: 0.9282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 6/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.12]    \n",
      "[Fold 2][Epoch 6/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep6 - Train: 0.0676 | VaL: 0.2354, Acc: 0.9412, F1: 0.9393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 7/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00269] \n",
      "[Fold 2][Epoch 7/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep7 - Train: 0.0475 | VaL: 0.2435, Acc: 0.9353, F1: 0.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 8/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.262]   \n",
      "[Fold 2][Epoch 8/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep8 - Train: 0.0474 | VaL: 0.2294, Acc: 0.9471, F1: 0.9470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 9/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0103]  \n",
      "[Fold 2][Epoch 9/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep9 - Train: 0.0642 | VaL: 0.2943, Acc: 0.9088, F1: 0.9078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 10/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0736]  \n",
      "[Fold 2][Epoch 10/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep10 - Train: 0.0388 | VaL: 0.3439, Acc: 0.9382, F1: 0.9316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 11/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000562]\n",
      "[Fold 2][Epoch 11/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep11 - Train: 0.0961 | VaL: 0.3034, Acc: 0.9324, F1: 0.9260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 12/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000735]\n",
      "[Fold 2][Epoch 12/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep12 - Train: 0.0414 | VaL: 0.2328, Acc: 0.9441, F1: 0.9452\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 13/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000969]\n",
      "[Fold 2][Epoch 13/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep13 - Train: 0.0141 | VaL: 0.2358, Acc: 0.9529, F1: 0.9523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 14/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.57it/s, loss=0.000256]\n",
      "[Fold 2][Epoch 14/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep14 - Train: 0.0033 | VaL: 0.2493, Acc: 0.9588, F1: 0.9584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 15/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.00012] \n",
      "[Fold 2][Epoch 15/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep15 - Train: 0.0085 | VaL: 0.2385, Acc: 0.9618, F1: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 16/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=4.98e-5] \n",
      "[Fold 2][Epoch 16/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep16 - Train: 0.0006 | VaL: 0.2410, Acc: 0.9588, F1: 0.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 17/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=5.07e-5] \n",
      "[Fold 2][Epoch 17/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep17 - Train: 0.0004 | VaL: 0.2507, Acc: 0.9559, F1: 0.9552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 18/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000143]\n",
      "[Fold 2][Epoch 18/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep18 - Train: 0.0044 | VaL: 0.2875, Acc: 0.9618, F1: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 19/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000107]\n",
      "[Fold 2][Epoch 19/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep19 - Train: 0.0004 | VaL: 0.2931, Acc: 0.9618, F1: 0.9614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 2][Epoch 20/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.00034] \n",
      "[Fold 2][Epoch 20/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F2] Ep20 - Train: 0.0052 | VaL: 0.2937, Acc: 0.9559, F1: 0.9552\n",
      "[Fold 2] Early stopping triggered. Best F1: 0.9617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▂▃▃▄▄▄▅▅▅▆▆▇▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▂▁▁▂▁▂▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▆▆▇▆▇▅▆▆▇▇███████</td></tr><tr><td>val_f1</td><td>▁▅▅▆▆▇▇▇▅▆▆▇▇███████</td></tr><tr><td>val_loss</td><td>█▃▃▁▄▃▃▃▅▆▅▃▃▃▃▃▃▄▄▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>20</td></tr><tr><td>fold</td><td>2</td></tr><tr><td>train_loss</td><td>0.00516</td></tr><tr><td>val_acc</td><td>0.95588</td></tr><tr><td>val_f1</td><td>0.95517</td></tr><tr><td>val_loss</td><td>0.29374</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_2</strong> at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/arf2cm1h' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/arf2cm1h</a><br> View project at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../../wandb/run-20250702_143230-arf2cm1h/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 3 ===\n",
      "Fold 3: Train samples=1360, Val samples=340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../wandb/run-20250702_145058-xfvrjmmm</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/xfvrjmmm' target=\"_blank\">fold_3</a></strong> to <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/xfvrjmmm' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/xfvrjmmm</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 1/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.133]  \n",
      "[Fold 3][Epoch 1/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep1 - Train: 0.8671 | VaL: 0.2345, Acc: 0.9176, F1: 0.9117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 2/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0449] \n",
      "[Fold 3][Epoch 2/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep2 - Train: 0.2658 | VaL: 0.1600, Acc: 0.9382, F1: 0.9326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 3/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0146]  \n",
      "[Fold 3][Epoch 3/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep3 - Train: 0.1456 | VaL: 0.1352, Acc: 0.9441, F1: 0.9367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 4/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0436]  \n",
      "[Fold 3][Epoch 4/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep4 - Train: 0.1180 | VaL: 0.1544, Acc: 0.9412, F1: 0.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 5/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0322]  \n",
      "[Fold 3][Epoch 5/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep5 - Train: 0.0977 | VaL: 0.1553, Acc: 0.9441, F1: 0.9414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 6/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.0188]  \n",
      "[Fold 3][Epoch 6/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep6 - Train: 0.0427 | VaL: 0.2202, Acc: 0.9441, F1: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 7/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0132]  \n",
      "[Fold 3][Epoch 7/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep7 - Train: 0.0473 | VaL: 0.2279, Acc: 0.9471, F1: 0.9430\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 8/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.0114]  \n",
      "[Fold 3][Epoch 8/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep8 - Train: 0.0381 | VaL: 0.1515, Acc: 0.9529, F1: 0.9502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 9/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00116] \n",
      "[Fold 3][Epoch 9/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep9 - Train: 0.0191 | VaL: 0.1803, Acc: 0.9471, F1: 0.9445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 10/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.00855] \n",
      "[Fold 3][Epoch 10/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep10 - Train: 0.0578 | VaL: 0.1859, Acc: 0.9588, F1: 0.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 11/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.00283] \n",
      "[Fold 3][Epoch 11/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep11 - Train: 0.0648 | VaL: 0.2525, Acc: 0.9324, F1: 0.9262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 12/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000811]\n",
      "[Fold 3][Epoch 12/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep12 - Train: 0.0246 | VaL: 0.3006, Acc: 0.9500, F1: 0.9448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 13/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=3.1e-5]  \n",
      "[Fold 3][Epoch 13/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep13 - Train: 0.0061 | VaL: 0.3515, Acc: 0.9206, F1: 0.9201\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 14/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00012] \n",
      "[Fold 3][Epoch 14/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep14 - Train: 0.0470 | VaL: 0.2395, Acc: 0.9471, F1: 0.9464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 3][Epoch 15/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.00698] \n",
      "[Fold 3][Epoch 15/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F3] Ep15 - Train: 0.0262 | VaL: 0.3590, Acc: 0.9500, F1: 0.9441\n",
      "[Fold 3] Early stopping triggered. Best F1: 0.9581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▃▃▃▄▅▅▅▆▇▇▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▅▆▆▆▇▆█▄▇▂▆▇</td></tr><tr><td>val_f1</td><td>▁▄▅▅▅▅▆▇▆█▃▆▂▆▆</td></tr><tr><td>val_loss</td><td>▄▂▁▂▂▄▄▂▂▃▅▆█▄█</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>15</td></tr><tr><td>fold</td><td>3</td></tr><tr><td>train_loss</td><td>0.02624</td></tr><tr><td>val_acc</td><td>0.95</td></tr><tr><td>val_f1</td><td>0.94411</td></tr><tr><td>val_loss</td><td>0.35902</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_3</strong> at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/xfvrjmmm' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/xfvrjmmm</a><br> View project at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../../wandb/run-20250702_145058-xfvrjmmm/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 4 ===\n",
      "Fold 4: Train samples=1360, Val samples=340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../wandb/run-20250702_150448-ak0nwhi9</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/ak0nwhi9' target=\"_blank\">fold_4</a></strong> to <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/ak0nwhi9' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/ak0nwhi9</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 1/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.509]  \n",
      "[Fold 4][Epoch 1/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep1 - Train: 0.8493 | VaL: 0.2760, Acc: 0.8824, F1: 0.8855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 2/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.194]  \n",
      "[Fold 4][Epoch 2/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep2 - Train: 0.2543 | VaL: 0.1807, Acc: 0.9324, F1: 0.9136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 3/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.57it/s, loss=0.139]   \n",
      "[Fold 4][Epoch 3/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep3 - Train: 0.1444 | VaL: 0.1529, Acc: 0.9471, F1: 0.9406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 4/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0124]  \n",
      "[Fold 4][Epoch 4/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep4 - Train: 0.0801 | VaL: 0.2341, Acc: 0.9088, F1: 0.9131\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 5/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0867]  \n",
      "[Fold 4][Epoch 5/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep5 - Train: 0.0869 | VaL: 0.2382, Acc: 0.9353, F1: 0.9172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 6/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.778]   \n",
      "[Fold 4][Epoch 6/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep6 - Train: 0.0626 | VaL: 0.1326, Acc: 0.9500, F1: 0.9486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 7/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0197]  \n",
      "[Fold 4][Epoch 7/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep7 - Train: 0.0404 | VaL: 0.1580, Acc: 0.9529, F1: 0.9518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 8/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.60it/s, loss=0.000712]\n",
      "[Fold 4][Epoch 8/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep8 - Train: 0.0065 | VaL: 0.1232, Acc: 0.9676, F1: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 9/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=6.7e-5]  \n",
      "[Fold 4][Epoch 9/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep9 - Train: 0.1247 | VaL: 0.2682, Acc: 0.9176, F1: 0.9097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 10/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0827]  \n",
      "[Fold 4][Epoch 10/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep10 - Train: 0.0506 | VaL: 0.2743, Acc: 0.9441, F1: 0.9360\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 11/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.000665]\n",
      "[Fold 4][Epoch 11/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep11 - Train: 0.0175 | VaL: 0.2905, Acc: 0.9471, F1: 0.9397\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 12/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0545]  \n",
      "[Fold 4][Epoch 12/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep12 - Train: 0.0351 | VaL: 0.1714, Acc: 0.9382, F1: 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 4][Epoch 13/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00376] \n",
      "[Fold 4][Epoch 13/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F4] Ep13 - Train: 0.0398 | VaL: 0.2541, Acc: 0.9441, F1: 0.9412\n",
      "[Fold 4] Early stopping triggered. Best F1: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▃▃▄▅▅▆▆▇▇█</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▂▁▁▁▁</td></tr><tr><td>val_acc</td><td>▁▅▆▃▅▇▇█▄▆▆▆▆</td></tr><tr><td>val_f1</td><td>▁▃▆▃▄▆▇█▃▅▆▅▆</td></tr><tr><td>val_loss</td><td>▇▃▂▆▆▁▂▁▇▇█▃▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>13</td></tr><tr><td>fold</td><td>4</td></tr><tr><td>train_loss</td><td>0.03982</td></tr><tr><td>val_acc</td><td>0.94412</td></tr><tr><td>val_f1</td><td>0.94121</td></tr><tr><td>val_loss</td><td>0.25408</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_4</strong> at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/ak0nwhi9' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/ak0nwhi9</a><br> View project at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../../wandb/run-20250702_150448-ak0nwhi9/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Fold 5 ===\n",
      "Fold 5: Train samples=1360, Val samples=340\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>../../wandb/run-20250702_151648-soq68bjh</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/soq68bjh' target=\"_blank\">fold_5</a></strong> to <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/soq68bjh' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/soq68bjh</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 1/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.297]  \n",
      "[Fold 5][Epoch 1/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep1 - Train: 1.2155 | VaL: 0.3419, Acc: 0.8559, F1: 0.8520\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 2/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.56it/s, loss=0.0357] \n",
      "[Fold 5][Epoch 2/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep2 - Train: 0.2538 | VaL: 0.2669, Acc: 0.9000, F1: 0.8924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 3/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.00524] \n",
      "[Fold 5][Epoch 3/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep3 - Train: 0.1674 | VaL: 0.2792, Acc: 0.9000, F1: 0.8939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 4/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.00974] \n",
      "[Fold 5][Epoch 4/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep4 - Train: 0.1299 | VaL: 0.2579, Acc: 0.8882, F1: 0.8877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 5/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00216] \n",
      "[Fold 5][Epoch 5/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep5 - Train: 0.0879 | VaL: 0.2133, Acc: 0.9412, F1: 0.9359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 6/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00199] \n",
      "[Fold 5][Epoch 6/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep6 - Train: 0.0471 | VaL: 0.2488, Acc: 0.9441, F1: 0.9411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 7/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.00084] \n",
      "[Fold 5][Epoch 7/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep7 - Train: 0.0744 | VaL: 0.2710, Acc: 0.9294, F1: 0.9299\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 8/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.57it/s, loss=0.0828]  \n",
      "[Fold 5][Epoch 8/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep8 - Train: 0.0609 | VaL: 0.2976, Acc: 0.9294, F1: 0.9293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 9/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000914]\n",
      "[Fold 5][Epoch 9/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep9 - Train: 0.0136 | VaL: 0.2837, Acc: 0.9500, F1: 0.9484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 10/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=7.2e-5]  \n",
      "[Fold 5][Epoch 10/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep10 - Train: 0.0015 | VaL: 0.2341, Acc: 0.9529, F1: 0.9531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 11/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000159]\n",
      "[Fold 5][Epoch 11/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep11 - Train: 0.0009 | VaL: 0.2294, Acc: 0.9529, F1: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 12/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=2.53e-5] \n",
      "[Fold 5][Epoch 12/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep12 - Train: 0.0007 | VaL: 0.3269, Acc: 0.9471, F1: 0.9462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 13/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.0486]  \n",
      "[Fold 5][Epoch 13/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep13 - Train: 0.0416 | VaL: 0.6529, Acc: 0.8676, F1: 0.8481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 14/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.57it/s, loss=0.000354]\n",
      "[Fold 5][Epoch 14/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep14 - Train: 0.1022 | VaL: 0.4038, Acc: 0.9206, F1: 0.9175\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 15/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.58it/s, loss=0.000153]\n",
      "[Fold 5][Epoch 15/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 27.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep15 - Train: 0.0470 | VaL: 0.2045, Acc: 0.9471, F1: 0.9471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Fold 5][Epoch 16/60] Training: 100%|██████████| 340/340 [00:51<00:00,  6.59it/s, loss=0.00122] \n",
      "[Fold 5][Epoch 16/60] Validation: 100%|██████████| 85/85 [00:03<00:00, 26.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[F5] Ep16 - Train: 0.0314 | VaL: 0.2617, Acc: 0.9471, F1: 0.9467\n",
      "[Fold 5] Early stopping triggered. Best F1: 0.9532\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▂▂▃▃▄▄▅▅▆▆▇▇██</td></tr><tr><td>fold</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>train_loss</td><td>█▂▂▂▂▁▁▁▁▁▁▁▁▂▁▁</td></tr><tr><td>val_acc</td><td>▁▄▄▃▇▇▆▆████▂▆██</td></tr><tr><td>val_f1</td><td>▁▄▄▄▇▇▆▆████▁▆██</td></tr><tr><td>val_loss</td><td>▃▂▂▂▁▂▂▂▂▁▁▃█▄▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>16</td></tr><tr><td>fold</td><td>5</td></tr><tr><td>train_loss</td><td>0.03137</td></tr><tr><td>val_acc</td><td>0.94706</td></tr><tr><td>val_f1</td><td>0.9467</td></tr><tr><td>val_loss</td><td>0.26175</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">fold_5</strong> at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/soq68bjh' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification/runs/soq68bjh</a><br> View project at: <a href='https://wandb.ai/moonstalker9010-none/Document%20Classification' target=\"_blank\">https://wandb.ai/moonstalker9010-none/Document%20Classification</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>../../wandb/run-20250702_151648-soq68bjh/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dfs, train_dfs['target'])):\n",
    "    print(f\"\\n=== Fold {fold+1} ===\")\n",
    "    train_fold_df = train_dfs.iloc[train_idx].reset_index(drop=True)\n",
    "    val_fold_df = train_dfs.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = ImageDataset(train_fold_df, transform=train_transform)\n",
    "    val_dataset = ImageDataset(val_fold_df, transform=test_transform)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=num_workers)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "    print(f\"Fold {fold+1}: Train samples={len(train_fold_df)}, Val samples={len(val_fold_df)}\")\n",
    "\n",
    "    # 모델 정의\n",
    "    model = timm.create_model(model_name, pretrained=True, num_classes=17, drop_path_rate=0.3).to(device) # drop_path_rate=0.2\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
    "\n",
    "    best_f1 = -1.0\n",
    "    patience = 5\n",
    "    trigger = 0\n",
    "\n",
    "    os.environ[\"WANDB_DIR\"] = \"../../\"\n",
    "\n",
    "    # WandB 초기화\n",
    "    wandb.init(\n",
    "        project=\"Document Classification\",\n",
    "        entity=\"moonstalker9010-none\",\n",
    "        name=f\"fold_{fold+1}\",\n",
    "        config={\n",
    "            \"epochs\": EPOCHS,\n",
    "            \"img_size\": img_size,\n",
    "            \"batch_size\": BATCH_SIZE,\n",
    "            \"learning_rate\": LR,\n",
    "            \"model_name\": model_name,\n",
    "        }\n",
    "    )\n",
    "\n",
    "    for epoch in range(1, EPOCHS + 1):\n",
    "        # 학습\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_bar = tqdm(train_loader, desc=f\"[Fold {fold+1}][Epoch {epoch}/{EPOCHS}] Training\")\n",
    "        for images, targets in train_bar:\n",
    "            images, targets = images.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = loss_fn(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "            train_bar.set_postfix(loss=loss.item())\n",
    "\n",
    "        avg_train_loss = train_loss / len(train_loader)\n",
    "\n",
    "        # 검증\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            val_bar = tqdm(val_loader, desc=f\"[Fold {fold+1}][Epoch {epoch}/{EPOCHS}] Validation\")\n",
    "            for images, targets in val_bar:\n",
    "                images, targets = images.to(device), targets.to(device)\n",
    "                outputs = model(images)\n",
    "                loss = loss_fn(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                _, preds = torch.max(outputs, 1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "                correct += (preds == targets).sum().item()\n",
    "                total += targets.size(0)\n",
    "\n",
    "        avg_val_loss = val_loss / len(val_loader)\n",
    "        val_acc = correct / total\n",
    "        val_f1 = f1_score(all_targets, all_preds, average='macro')\n",
    "\n",
    "        print(f\"[F{fold+1}] Ep{epoch} - \"\n",
    "              f\"Train: {avg_train_loss:.4f} | VaL: {avg_val_loss:.4f}, \"\n",
    "              f\"Acc: {val_acc:.4f}, F1: {val_f1:.4f}\")\n",
    "\n",
    "        # WandB 로깅\n",
    "        wandb.log({\n",
    "            \"fold\": fold + 1,\n",
    "            \"epoch\": epoch,\n",
    "            \"train_loss\": avg_train_loss,\n",
    "            \"val_loss\": avg_val_loss,\n",
    "            \"val_acc\": val_acc,\n",
    "            \"val_f1\": val_f1,\n",
    "        })\n",
    "\n",
    "        # EarlyStopping\n",
    "        if val_f1 > best_f1:\n",
    "            best_f1 = val_f1\n",
    "            trigger = 0\n",
    "            save_dir = \"../../model\"\n",
    "            os.makedirs(save_dir, exist_ok=True)\n",
    "            torch.save(model.state_dict(), os.path.join(save_dir, f\"model_fold{fold+1}.pth\"))\n",
    "        else:\n",
    "            trigger += 1\n",
    "            if trigger >= patience:\n",
    "                print(f\"[Fold {fold+1}] Early stopping triggered. Best F1: {best_f1:.4f}\")\n",
    "                break\n",
    "\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fec72016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>class_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>account_number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>application_for_payment_of_pregnancy_medical_e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>car_dashboard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>confirmation_of_admission_and_discharge</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>diagnosis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>driver_lisence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>medical_bill_receipts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>medical_outpatient_certificate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>national_id_card</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>passport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>payment_confirmation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>pharmaceutical_receipt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>prescription</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>resume</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>statement_of_opinion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>vehicle_registration_certificate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>vehicle_registration_plate</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    target                                         class_name\n",
       "0        0                                     account_number\n",
       "1        1  application_for_payment_of_pregnancy_medical_e...\n",
       "2        2                                      car_dashboard\n",
       "3        3            confirmation_of_admission_and_discharge\n",
       "4        4                                          diagnosis\n",
       "5        5                                     driver_lisence\n",
       "6        6                              medical_bill_receipts\n",
       "7        7                     medical_outpatient_certificate\n",
       "8        8                                   national_id_card\n",
       "9        9                                           passport\n",
       "10      10                               payment_confirmation\n",
       "11      11                             pharmaceutical_receipt\n",
       "12      12                                       prescription\n",
       "13      13                                             resume\n",
       "14      14                               statement_of_opinion\n",
       "15      15                   vehicle_registration_certificate\n",
       "16      16                         vehicle_registration_plate"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a129a87a",
   "metadata": {},
   "source": [
    "### Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e3fd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Image_Dataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # 테스트셋: target 없으면 예외처리\n",
    "        if self.df.shape[1] == 2:\n",
    "            name, target = self.df[idx]\n",
    "        else:\n",
    "            name = self.df[idx][0]\n",
    "            target = -1  # placeholder\n",
    "\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7c03907d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_path = \"../../data/sample_submission.csv\"\n",
    "test_dataset = Image_Dataset(inference_path, test_path, transform=test_transform)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "models = []\n",
    "for fold in range(1, 6):\n",
    "    model = timm.create_model(model_name, pretrained=False, num_classes=17, drop_path_rate=0.3).to(device)\n",
    "    model.load_state_dict(torch.load(f\"../../model/model_fold{fold}.pth\"))\n",
    "    model.eval()  # 추론 모드\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b81265e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ConvNeXt(\n",
       "   (stem): Sequential(\n",
       "     (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "   )\n",
       "   (stages): Sequential(\n",
       "     (0): ConvNeXtStage(\n",
       "       (downsample): Identity()\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): Identity()\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.017)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.026)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.034)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.043)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.051)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.060)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.069)\n",
       "         )\n",
       "         (3): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.077)\n",
       "         )\n",
       "         (4): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.086)\n",
       "         )\n",
       "         (5): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.094)\n",
       "         )\n",
       "         (6): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.103)\n",
       "         )\n",
       "         (7): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.111)\n",
       "         )\n",
       "         (8): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.120)\n",
       "         )\n",
       "         (9): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.129)\n",
       "         )\n",
       "         (10): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.137)\n",
       "         )\n",
       "         (11): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.146)\n",
       "         )\n",
       "         (12): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.154)\n",
       "         )\n",
       "         (13): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.163)\n",
       "         )\n",
       "         (14): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.171)\n",
       "         )\n",
       "         (15): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.180)\n",
       "         )\n",
       "         (16): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.189)\n",
       "         )\n",
       "         (17): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.197)\n",
       "         )\n",
       "         (18): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.206)\n",
       "         )\n",
       "         (19): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.214)\n",
       "         )\n",
       "         (20): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.223)\n",
       "         )\n",
       "         (21): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.231)\n",
       "         )\n",
       "         (22): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.240)\n",
       "         )\n",
       "         (23): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.249)\n",
       "         )\n",
       "         (24): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.257)\n",
       "         )\n",
       "         (25): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.266)\n",
       "         )\n",
       "         (26): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.274)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.283)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.291)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm_pre): Identity()\n",
       "   (head): NormMlpClassifierHead(\n",
       "     (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "     (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "     (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "     (pre_logits): Identity()\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (fc): Linear(in_features=1536, out_features=17, bias=True)\n",
       "   )\n",
       " ),\n",
       " ConvNeXt(\n",
       "   (stem): Sequential(\n",
       "     (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "   )\n",
       "   (stages): Sequential(\n",
       "     (0): ConvNeXtStage(\n",
       "       (downsample): Identity()\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): Identity()\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.017)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.026)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.034)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.043)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.051)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.060)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.069)\n",
       "         )\n",
       "         (3): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.077)\n",
       "         )\n",
       "         (4): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.086)\n",
       "         )\n",
       "         (5): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.094)\n",
       "         )\n",
       "         (6): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.103)\n",
       "         )\n",
       "         (7): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.111)\n",
       "         )\n",
       "         (8): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.120)\n",
       "         )\n",
       "         (9): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.129)\n",
       "         )\n",
       "         (10): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.137)\n",
       "         )\n",
       "         (11): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.146)\n",
       "         )\n",
       "         (12): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.154)\n",
       "         )\n",
       "         (13): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.163)\n",
       "         )\n",
       "         (14): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.171)\n",
       "         )\n",
       "         (15): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.180)\n",
       "         )\n",
       "         (16): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.189)\n",
       "         )\n",
       "         (17): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.197)\n",
       "         )\n",
       "         (18): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.206)\n",
       "         )\n",
       "         (19): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.214)\n",
       "         )\n",
       "         (20): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.223)\n",
       "         )\n",
       "         (21): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.231)\n",
       "         )\n",
       "         (22): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.240)\n",
       "         )\n",
       "         (23): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.249)\n",
       "         )\n",
       "         (24): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.257)\n",
       "         )\n",
       "         (25): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.266)\n",
       "         )\n",
       "         (26): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.274)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.283)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.291)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm_pre): Identity()\n",
       "   (head): NormMlpClassifierHead(\n",
       "     (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "     (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "     (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "     (pre_logits): Identity()\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (fc): Linear(in_features=1536, out_features=17, bias=True)\n",
       "   )\n",
       " ),\n",
       " ConvNeXt(\n",
       "   (stem): Sequential(\n",
       "     (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "   )\n",
       "   (stages): Sequential(\n",
       "     (0): ConvNeXtStage(\n",
       "       (downsample): Identity()\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): Identity()\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.017)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.026)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.034)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.043)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.051)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.060)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.069)\n",
       "         )\n",
       "         (3): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.077)\n",
       "         )\n",
       "         (4): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.086)\n",
       "         )\n",
       "         (5): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.094)\n",
       "         )\n",
       "         (6): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.103)\n",
       "         )\n",
       "         (7): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.111)\n",
       "         )\n",
       "         (8): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.120)\n",
       "         )\n",
       "         (9): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.129)\n",
       "         )\n",
       "         (10): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.137)\n",
       "         )\n",
       "         (11): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.146)\n",
       "         )\n",
       "         (12): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.154)\n",
       "         )\n",
       "         (13): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.163)\n",
       "         )\n",
       "         (14): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.171)\n",
       "         )\n",
       "         (15): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.180)\n",
       "         )\n",
       "         (16): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.189)\n",
       "         )\n",
       "         (17): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.197)\n",
       "         )\n",
       "         (18): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.206)\n",
       "         )\n",
       "         (19): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.214)\n",
       "         )\n",
       "         (20): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.223)\n",
       "         )\n",
       "         (21): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.231)\n",
       "         )\n",
       "         (22): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.240)\n",
       "         )\n",
       "         (23): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.249)\n",
       "         )\n",
       "         (24): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.257)\n",
       "         )\n",
       "         (25): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.266)\n",
       "         )\n",
       "         (26): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.274)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.283)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.291)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm_pre): Identity()\n",
       "   (head): NormMlpClassifierHead(\n",
       "     (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "     (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "     (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "     (pre_logits): Identity()\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (fc): Linear(in_features=1536, out_features=17, bias=True)\n",
       "   )\n",
       " ),\n",
       " ConvNeXt(\n",
       "   (stem): Sequential(\n",
       "     (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "   )\n",
       "   (stages): Sequential(\n",
       "     (0): ConvNeXtStage(\n",
       "       (downsample): Identity()\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): Identity()\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.017)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.026)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.034)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.043)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.051)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.060)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.069)\n",
       "         )\n",
       "         (3): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.077)\n",
       "         )\n",
       "         (4): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.086)\n",
       "         )\n",
       "         (5): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.094)\n",
       "         )\n",
       "         (6): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.103)\n",
       "         )\n",
       "         (7): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.111)\n",
       "         )\n",
       "         (8): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.120)\n",
       "         )\n",
       "         (9): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.129)\n",
       "         )\n",
       "         (10): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.137)\n",
       "         )\n",
       "         (11): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.146)\n",
       "         )\n",
       "         (12): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.154)\n",
       "         )\n",
       "         (13): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.163)\n",
       "         )\n",
       "         (14): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.171)\n",
       "         )\n",
       "         (15): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.180)\n",
       "         )\n",
       "         (16): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.189)\n",
       "         )\n",
       "         (17): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.197)\n",
       "         )\n",
       "         (18): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.206)\n",
       "         )\n",
       "         (19): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.214)\n",
       "         )\n",
       "         (20): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.223)\n",
       "         )\n",
       "         (21): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.231)\n",
       "         )\n",
       "         (22): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.240)\n",
       "         )\n",
       "         (23): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.249)\n",
       "         )\n",
       "         (24): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.257)\n",
       "         )\n",
       "         (25): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.266)\n",
       "         )\n",
       "         (26): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.274)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.283)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.291)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm_pre): Identity()\n",
       "   (head): NormMlpClassifierHead(\n",
       "     (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "     (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "     (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "     (pre_logits): Identity()\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (fc): Linear(in_features=1536, out_features=17, bias=True)\n",
       "   )\n",
       " ),\n",
       " ConvNeXt(\n",
       "   (stem): Sequential(\n",
       "     (0): Conv2d(3, 192, kernel_size=(4, 4), stride=(4, 4))\n",
       "     (1): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "   )\n",
       "   (stages): Sequential(\n",
       "     (0): ConvNeXtStage(\n",
       "       (downsample): Identity()\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): Identity()\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.009)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(192, 192, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=192)\n",
       "           (norm): LayerNorm((192,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.017)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (1): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((192,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(192, 384, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.026)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.034)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(384, 384, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=384)\n",
       "           (norm): LayerNorm((384,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.043)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (2): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((384,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(384, 768, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.051)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.060)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.069)\n",
       "         )\n",
       "         (3): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.077)\n",
       "         )\n",
       "         (4): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.086)\n",
       "         )\n",
       "         (5): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.094)\n",
       "         )\n",
       "         (6): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.103)\n",
       "         )\n",
       "         (7): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.111)\n",
       "         )\n",
       "         (8): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.120)\n",
       "         )\n",
       "         (9): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.129)\n",
       "         )\n",
       "         (10): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.137)\n",
       "         )\n",
       "         (11): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.146)\n",
       "         )\n",
       "         (12): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.154)\n",
       "         )\n",
       "         (13): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.163)\n",
       "         )\n",
       "         (14): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.171)\n",
       "         )\n",
       "         (15): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.180)\n",
       "         )\n",
       "         (16): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.189)\n",
       "         )\n",
       "         (17): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.197)\n",
       "         )\n",
       "         (18): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.206)\n",
       "         )\n",
       "         (19): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.214)\n",
       "         )\n",
       "         (20): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.223)\n",
       "         )\n",
       "         (21): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.231)\n",
       "         )\n",
       "         (22): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.240)\n",
       "         )\n",
       "         (23): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.249)\n",
       "         )\n",
       "         (24): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.257)\n",
       "         )\n",
       "         (25): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.266)\n",
       "         )\n",
       "         (26): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(768, 768, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=768)\n",
       "           (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.274)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "     (3): ConvNeXtStage(\n",
       "       (downsample): Sequential(\n",
       "         (0): LayerNorm2d((768,), eps=1e-06, elementwise_affine=True)\n",
       "         (1): Conv2d(768, 1536, kernel_size=(2, 2), stride=(2, 2))\n",
       "       )\n",
       "       (blocks): Sequential(\n",
       "         (0): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.283)\n",
       "         )\n",
       "         (1): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.291)\n",
       "         )\n",
       "         (2): ConvNeXtBlock(\n",
       "           (conv_dw): Conv2d(1536, 1536, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), groups=1536)\n",
       "           (norm): LayerNorm((1536,), eps=1e-06, elementwise_affine=True)\n",
       "           (mlp): GlobalResponseNormMlp(\n",
       "             (fc1): Linear(in_features=1536, out_features=6144, bias=True)\n",
       "             (act): GELU()\n",
       "             (drop1): Dropout(p=0.0, inplace=False)\n",
       "             (grn): GlobalResponseNorm()\n",
       "             (fc2): Linear(in_features=6144, out_features=1536, bias=True)\n",
       "             (drop2): Dropout(p=0.0, inplace=False)\n",
       "           )\n",
       "           (shortcut): Identity()\n",
       "           (drop_path): DropPath(drop_prob=0.300)\n",
       "         )\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (norm_pre): Identity()\n",
       "   (head): NormMlpClassifierHead(\n",
       "     (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
       "     (norm): LayerNorm2d((1536,), eps=1e-06, elementwise_affine=True)\n",
       "     (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "     (pre_logits): Identity()\n",
       "     (drop): Dropout(p=0.0, inplace=False)\n",
       "     (fc): Linear(in_features=1536, out_features=17, bias=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c352e007",
   "metadata": {},
   "outputs": [
    {
     "ename": "BrokenPipeError",
     "evalue": "[Errno 32] Broken pipe",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBrokenPipeError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m wandb\u001b[38;5;241m.\u001b[39mrun \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m      3\u001b[0m     wandb\u001b[38;5;241m.\u001b[39mfinish()\n\u001b[0;32m----> 5\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mproject\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDocument Classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mentity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmoonstalker9010-none\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mensemble_evaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimg_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbatch_size\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mBATCH_SIZE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlearning_rate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mLR\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mensemble_models\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m oof_targets \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     20\u001b[0m oof_preds \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1620\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1616\u001b[0m     wl\u001b[38;5;241m.\u001b[39m_get_logger()\u001b[38;5;241m.\u001b[39mexception(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror in wandb.init()\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39me)\n\u001b[1;32m   1618\u001b[0m \u001b[38;5;66;03m# Need to build delay into this sentry capture because our exit hooks\u001b[39;00m\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;66;03m# mess with sentry's ability to send out errors before the program ends.\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[43mwandb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sentry\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/analytics/sentry.py:157\u001b[0m, in \u001b[0;36mSentry.reraise\u001b[0;34m(self, exc)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexception(exc)\n\u001b[1;32m    155\u001b[0m \u001b[38;5;66;03m# this will messily add this \"reraise\" function to the stack trace,\u001b[39;00m\n\u001b[1;32m    156\u001b[0m \u001b[38;5;66;03m# but hopefully it's not too bad\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exc\u001b[38;5;241m.\u001b[39mwith_traceback(sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m])\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:1606\u001b[0m, in \u001b[0;36minit\u001b[0;34m(entity, project, dir, id, name, notes, tags, config, config_exclude_keys, config_include_keys, allow_val_change, group, job_type, mode, force, anonymous, reinit, resume, resume_from, fork_from, save_code, tensorboard, sync_tensorboard, monitor_gym, settings)\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_settings\u001b[38;5;241m.\u001b[39mx_server_side_derived_summary:\n\u001b[1;32m   1604\u001b[0m             init_telemetry\u001b[38;5;241m.\u001b[39mfeature\u001b[38;5;241m.\u001b[39mserver_side_derived_summary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m-> 1606\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_settings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_printer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1609\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m wl:\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/wandb_init.py:875\u001b[0m, in \u001b[0;36m_WandbInit.init\u001b[0;34m(self, settings, config, run_printer)\u001b[0m\n\u001b[1;32m    873\u001b[0m service \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_wl\u001b[38;5;241m.\u001b[39mensure_service()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msending inform_init request\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 875\u001b[0m \u001b[43mservice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minform_init\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m    \u001b[49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_proto\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msettings\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore\u001b[39;49;00m\n\u001b[1;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m backend \u001b[38;5;241m=\u001b[39m Backend(settings\u001b[38;5;241m=\u001b[39msettings, service\u001b[38;5;241m=\u001b[39mservice)\n\u001b[1;32m    881\u001b[0m backend\u001b[38;5;241m.\u001b[39mensure_launched()\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/lib/service/service_connection.py:111\u001b[0m, in \u001b[0;36mServiceConnection.inform_init\u001b[0;34m(self, settings, run_id)\u001b[0m\n\u001b[1;32m    109\u001b[0m request\u001b[38;5;241m.\u001b[39msettings\u001b[38;5;241m.\u001b[39mCopyFrom(settings)\n\u001b[1;32m    110\u001b[0m request\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mstream_id \u001b[38;5;241m=\u001b[39m run_id\n\u001b[0;32m--> 111\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_server_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mspb\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mServerRequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43minform_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py:150\u001b[0m, in \u001b[0;36mSockClient.send_server_request\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21msend_server_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, msg: spb\u001b[38;5;241m.\u001b[39mServerRequest) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmsg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py:147\u001b[0m, in \u001b[0;36mSockClient._send_message\u001b[0;34m(self, msg)\u001b[0m\n\u001b[1;32m    145\u001b[0m header \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39mpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BI\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mord\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW\u001b[39m\u001b[38;5;124m\"\u001b[39m), raw_size)\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m--> 147\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sendall_with_error_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43mheader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/CV_Project/lib/python3.9/site-packages/wandb/sdk/lib/sock_client.py:126\u001b[0m, in \u001b[0;36mSockClient._sendall_with_error_handle\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    124\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mmonotonic()\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 126\u001b[0m     sent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;66;03m# sent equal to 0 indicates a closed socket\u001b[39;00m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m sent \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mBrokenPipeError\u001b[0m: [Errno 32] Broken pipe"
     ]
    }
   ],
   "source": [
    "# 앙상블 WandB run\n",
    "if wandb.run is not None:\n",
    "    wandb.finish()\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Document Classification\",\n",
    "    entity=\"moonstalker9010-none\",\n",
    "    name=\"ensemble_evaluation\",\n",
    "    config={\n",
    "        \"epochs\": EPOCHS,\n",
    "        \"img_size\": img_size,\n",
    "        \"batch_size\": BATCH_SIZE,\n",
    "        \"learning_rate\": LR,\n",
    "        \"model_name\": model_name,\n",
    "        \"ensemble_models\": len(models),\n",
    "    }\n",
    ")\n",
    "\n",
    "oof_targets = []\n",
    "oof_preds = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(train_dfs, train_dfs['target'])):\n",
    "    print(f\"\\n=== Fold {fold+1} Validation Inference ===\")\n",
    "    val_fold_df = train_dfs.iloc[val_idx].reset_index(drop=True)\n",
    "    val_dataset = ImageDataset(val_fold_df, transform=test_transform)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "    fold_preds = []\n",
    "\n",
    "    # 각 fold 검증셋을 앙상블 모델로 추론\n",
    "    for model in models:\n",
    "        model.eval()\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for images, targets in val_loader:\n",
    "                images = images.to(device)\n",
    "                outputs = model(images)\n",
    "                probs = outputs.softmax(1).cpu().numpy()\n",
    "                preds.append(probs)\n",
    "        preds = np.concatenate(preds, axis=0)\n",
    "        fold_preds.append(preds)\n",
    "\n",
    "    # 앙상블 평균\n",
    "    ensemble_probs = np.mean(fold_preds, axis=0)\n",
    "    ensemble_preds = np.argmax(ensemble_probs, axis=1)\n",
    "\n",
    "    # fold별 성능 기록\n",
    "    fold_targets = val_fold_df[\"target\"].values\n",
    "    fold_f1 = f1_score(fold_targets, ensemble_preds, average=\"macro\")\n",
    "    fold_acc = accuracy_score(fold_targets, ensemble_preds)\n",
    "    print(f\"[Fold {fold+1}], F1: {fold_f1:.4f}, Acc: {fold_acc:.4f}\")\n",
    "\n",
    "    wandb.log({\n",
    "        f\"fold{fold+1}_f1\": fold_f1,\n",
    "        f\"fold{fold+1}_acc\": fold_acc,\n",
    "    })\n",
    "\n",
    "    oof_targets.extend(fold_targets)\n",
    "    oof_preds.extend(ensemble_preds)\n",
    "\n",
    "# 전체 OOF 성능 계산\n",
    "oof_f1 = f1_score(oof_targets, oof_preds, average=\"macro\")\n",
    "oof_acc = accuracy_score(oof_targets, oof_preds)\n",
    "print(f\"\\n=== OOF 앙상블 전체 성능: F1={oof_f1:.4f}, Acc={oof_acc:.4f} ===\")\n",
    "\n",
    "wandb.log({\n",
    "    \"ensemble_OOF_f1\": oof_f1,\n",
    "    \"ensemble_OOF_acc\": oof_acc,\n",
    "})\n",
    "\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2eab9f",
   "metadata": {},
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f2d4f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Inference: 100%|██████████| 785/785 [00:27<00:00, 28.61it/s]\n",
      "Inference: 100%|██████████| 785/785 [00:27<00:00, 28.81it/s]\n",
      "Inference: 100%|██████████| 785/785 [00:27<00:00, 28.74it/s]\n",
      "Inference: 100%|██████████| 785/785 [00:27<00:00, 28.58it/s]\n",
      "Inference: 100%|██████████| 785/785 [00:27<00:00, 28.40it/s]\n"
     ]
    }
   ],
   "source": [
    "all_preds = []\n",
    "\n",
    "# 추론 시작\n",
    "for model in models:\n",
    "    model_preds = []\n",
    "    with torch.no_grad(): \n",
    "        for images, _ in tqdm(test_loader, desc=\"Inference\"):\n",
    "            images = images.to(device)\n",
    "            outputs = model(images)                # 로짓\n",
    "            probs = torch.softmax(outputs, dim=1)  # 확률\n",
    "            model_preds.append(probs.cpu().numpy())\n",
    "    # 모델별 예측 shape: (num_samples, num_classes)\n",
    "    all_preds.append(np.concatenate(model_preds, axis=0))\n",
    "\n",
    "# 앙상블: 모델별 예측 평균\n",
    "ensemble_preds = np.mean(all_preds, axis=0)   # shape: (num_samples, num_classes)\n",
    "final_preds = np.argmax(ensemble_preds, axis=1)\n",
    "\n",
    "# 저장\n",
    "submission = pd.read_csv(\"../../data/sample_submission.csv\")\n",
    "submission[\"target\"] = final_preds\n",
    "submission.to_csv(\"../../data/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bad2429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CV_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
