# -*- coding: utf-8 -*-
"""baseline_code_advanced_tta2.py

Advanced version with proper TTA implementation.

## Improvements Applied:
- Better model architecture (EfficientNet)
- Larger image size (224x224)
- Enhanced data augmentation
- Learning rate scheduler
- Validation data split
- Label smoothing loss
- Mixed precision training
- Proper Test time augmentation (TTA)
- More training epochs
- Aspect ratio preserving resize (SmallestMaxSize + CenterCrop)

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- Load Data
- Train Model
- Inference & Save File
"""

import os
import time
import random

import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torch.optim.lr_scheduler import CosineAnnealingLR
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from torch.cuda.amp.autocast_mode import autocast
from torch.cuda.amp.grad_scaler import GradScaler
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score
from sklearn.model_selection import train_test_split

# ë¡œê·¸ ìœ í‹¸ë¦¬í‹° import
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))  # í˜„ì¬ íŒŒì¼ì˜ ìƒìœ„ ë””ë ‰í† ë¦¬ë¥¼ Python pathì— ì¶”ê°€
import utils.log_util as log

# ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
SEED = 42
os.environ['PYTHONHASHSEED'] = str(SEED)

# CUDA 10.2+ í™˜ê²½ì—ì„œ ê²°ì •ì  ì—°ì‚°ì„ ìœ„í•œ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'

random.seed(SEED)
np.random.seed(SEED)
torch.manual_seed(SEED)
torch.cuda.manual_seed(SEED)
torch.cuda.manual_seed_all(SEED)

# ì™„ì „í•œ ì¬í˜„ì„±ì„ ìœ„í•œ ì„¤ì •
torch.backends.cudnn.deterministic = True
torch.backends.cudnn.benchmark = False

# CUDA í™˜ê²½ì—ì„œ ê²°ì •ì  ì—°ì‚° ì„¤ì • (ì„ íƒì )
try:
    torch.use_deterministic_algorithms(True)
    log.info("ì™„ì „í•œ ì¬í˜„ì„± ì„¤ì •ì´ í™œì„±í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")
except Exception as e:
    log.info(f"torch.use_deterministic_algorithms(True) ì„¤ì • ì‹¤íŒ¨: {e}")
    log.info("ê¸°ë³¸ ì¬í˜„ì„± ì„¤ì •ë§Œ ì‚¬ìš©ë©ë‹ˆë‹¤.")

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# Label Smoothing Loss í´ë˜ìŠ¤ ì •ì˜
class LabelSmoothingLoss(nn.Module):
    def __init__(self, classes, smoothing=0.1):
        super(LabelSmoothingLoss, self).__init__()
        self.smoothing = smoothing
        self.classes = classes
        
    def forward(self, pred, target):
        pred = pred.log_softmax(dim=-1)
        with torch.no_grad():
            true_dist = torch.zeros_like(pred)
            true_dist.fill_(self.smoothing / (self.classes - 1))
            true_dist.scatter_(1, target.data.unsqueeze(1), 1.0 - self.smoothing)
        return torch.mean(torch.sum(-true_dist * pred, dim=-1))

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, csv_data, path, transform=None):
        if isinstance(csv_data, str):
            self.df = pd.read_csv(csv_data).values
        else:
            self.df = csv_data.values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device, scaler):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader, desc="Training")
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)

        optimizer.zero_grad()

        with autocast():
            preds = model(image)
            loss = loss_fn(preds, targets)

        scaler.scale(loss).backward()
        scaler.step(optimizer)
        scaler.update()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Training - Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret

# ê²€ì¦ì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤. (TTA ì ìš©)
def validate_one_epoch(loader, model, loss_fn, device, use_tta=True, tta_count=3):
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader, desc="Validation")
    with torch.no_grad():
        for image, targets in pbar:
            image = image.to(device)
            targets = targets.to(device)

            if use_tta:
                # TTAë¥¼ ìœ„í•œ ì—¬ëŸ¬ ë²ˆ ì˜ˆì¸¡
                batch_preds = []
                for _ in range(tta_count):
                    with autocast():
                        preds = model(image)
                        batch_preds.append(preds.softmax(dim=1))
                
                # í‰ê· ë‚´ê¸°
                final_preds = torch.stack(batch_preds).mean(0)
                loss = loss_fn(final_preds.log(), targets)  # log_softmaxë¡œ ë³€í™˜
            else:
                with autocast():
                    preds = model(image)
                    loss = loss_fn(preds, targets)
                    final_preds = preds.softmax(dim=1)

            val_loss += loss.item()
            preds_list.extend(final_preds.argmax(dim=1).detach().cpu().numpy())
            targets_list.extend(targets.detach().cpu().numpy())

            pbar.set_description(f"Validation - Loss: {loss.item():.4f}")

    val_loss /= len(loader)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
    }

    return ret

# Validation TTAë¥¼ ìœ„í•œ ê³ ì •ëœ transform ì„¸íŠ¸ (ì´ë¯¸ì§€ë³„ ë™ì  í¬ê¸° ê²°ì •)
def get_val_tta_transforms_dynamic(img_height, img_width):
    """TTAë¥¼ ìœ„í•œ ê³ ì •ëœ transformë“¤ (ê°„ë‹¨í•˜ê³  ì•ˆì •ì ì¸ ë³€í˜•ë“¤)
    - ì›ë³¸ ì´ë¯¸ì§€ì˜ ê°€ë¡œ, ì„¸ë¡œ í­ ì¤‘ ì‘ì€ í­ì„ ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• ë¦¬ì‚¬ì´ì¦ˆ (ë°ì´í„° ì†ì‹¤ ìµœì†Œí™”)
    """
    # ì›ë³¸ ì´ë¯¸ì§€ì˜ ê°€ë¡œ, ì„¸ë¡œ ì¤‘ ì‘ì€ í­ì„ êµ¬í•¨
    min_size = min(img_height, img_width)
    
    return [
        # ì›ë³¸
        A.Compose([
            A.Resize(height=min_size, width=min_size),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ì¢Œìš° ë°˜ì „
        A.Compose([
            A.Resize(height=min_size, width=min_size),
            A.HorizontalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ìƒí•˜ ë°˜ì „ (ë¬¸ì„œ ì´ë¯¸ì§€ì— ìœ ìš©í•  ìˆ˜ ìˆìŒ)
        A.Compose([
            A.Resize(height=min_size, width=min_size),
            A.VerticalFlip(p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # íšŒì „ (ì•½ê°„ì˜ íšŒì „)
        A.Compose([
            A.Resize(height=min_size, width=min_size),
            A.ShiftScaleRotate(shift_limit=0, scale_limit=0, rotate_limit=15, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
        # ë°ê¸° ì¡°ì •
        A.Compose([
            A.Resize(height=min_size, width=min_size),
            A.RandomBrightnessContrast(brightness_limit=0.1, contrast_limit=0, p=1.0),
            A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ToTensorV2(),
        ]),
    ]

# ê³ ì •ëœ TTAë¥¼ ì‚¬ìš©í•˜ëŠ” ê²€ì¦ í•¨ìˆ˜
def validate_one_epoch_tta(val_data, model, loss_fn, device, img_size, data_path):
    """ê³ ì •ëœ TTAë¥¼ ì‚¬ìš©í•œ validation"""
    model.eval()
    val_loss = 0
    preds_list = []
    targets_list = []
    
    with torch.no_grad():
        for idx, (img_name, target) in enumerate(tqdm(val_data.values, desc="Validation TTA")):
            # ì´ë¯¸ì§€ ë¡œë“œ
            img_path = os.path.join(data_path, "train", img_name)  
            img = np.array(Image.open(img_path))
            
            # ì´ë¯¸ì§€ í¬ê¸° êµ¬í•˜ê¸°
            img_height, img_width = img.shape[:2]
            
            # ê° ì´ë¯¸ì§€ë³„ë¡œ ë™ì ìœ¼ë¡œ TTA transform ìƒì„±
            val_tta_transforms = get_val_tta_transforms_dynamic(img_height, img_width)
            
            # ê° TTA transform ì ìš©í•˜ì—¬ ì˜ˆì¸¡
            all_preds = []
            all_losses = []
            
            for transform in val_tta_transforms:
                transformed_img = transform(image=img)['image'].unsqueeze(0).to(device)
                target_tensor = torch.tensor([target]).to(device)
                
                with autocast():
                    preds = model(transformed_img)
                    loss = loss_fn(preds, target_tensor)
                
                all_preds.append(preds.softmax(dim=1))
                all_losses.append(loss.item())
            
            # ì˜ˆì¸¡ í‰ê· 
            final_pred = torch.stack(all_preds).mean(0)
            avg_loss = np.mean(all_losses)
            
            val_loss += avg_loss
            preds_list.extend(final_pred.argmax(dim=1).detach().cpu().numpy())
            targets_list.append(target)
    
    val_loss /= len(val_data)
    val_acc = accuracy_score(targets_list, preds_list)
    val_f1 = f1_score(targets_list, preds_list, average='macro')
    
    ret = {
        "val_loss": val_loss,
        "val_acc": val_acc,
        "val_f1": val_f1,
    }
    
    return ret

# Test Time Augmentationì„ ìœ„í•œ ì˜ˆì¸¡ í•¨ìˆ˜ (tst_dataset ì‚¬ìš©)
def predict_with_tta(model, dataset, device, img_size):
    """ì§„ì§œ TTAë¥¼ ì ìš©í•œ ì˜ˆì¸¡ í•¨ìˆ˜ - datasetì„ ì‚¬ìš©"""
    model.eval()
    predictions = []
    
    with torch.no_grad():
        for idx in tqdm(range(len(dataset)), desc="Real TTA Prediction"):
            # ì›ë³¸ ì´ë¯¸ì§€ë¥¼ íŒŒì¼ì—ì„œ ì§ì ‘ ë¡œë“œ (transform ì—†ì´)
            img_name, _ = dataset.df[idx]
            img_path = os.path.join(dataset.path, img_name)
            original_img = np.array(Image.open(img_path))
            
            # ì´ë¯¸ì§€ í¬ê¸° êµ¬í•˜ê¸°
            img_height, img_width = original_img.shape[:2]
            
            # ê° ì´ë¯¸ì§€ë³„ë¡œ ë™ì ìœ¼ë¡œ TTA transform ìƒì„±
            tta_transforms = get_val_tta_transforms_dynamic(img_height, img_width)
            
            # ê° TTA transform ì ìš©í•˜ì—¬ ì˜ˆì¸¡
            all_preds = []
            
            for transform in tta_transforms:
                # ë§¤ë²ˆ ì›ë³¸ ì´ë¯¸ì§€ì—ì„œ ë‹¤ë¥¸ ë³€í˜• ì ìš©
                transformed_img = transform(image=original_img)['image'].unsqueeze(0).to(device)
                
                with autocast():
                    preds = model(transformed_img)
                
                all_preds.append(preds.softmax(dim=1))
            
            # ì˜ˆì¸¡ í‰ê· 
            final_pred = torch.stack(all_preds).mean(0)
            predictions.extend(final_pred.argmax(dim=1).detach().cpu().numpy())
    
    return predictions

"""## Hyper-parameters
* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
"""

# device
device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
log.info(f"Using device: {device}")

# data config
data_path = '../../input/data'

# model config
# model_name = 'tf_efficientnetv2_l'  # EfficientNet v2 Large ëª¨ë¸ ì‚¬ìš©
model_name = 'tf_efficientnetv2_xl'  # EfficientNet v2 Large ëª¨ë¸ ì‚¬ìš©
# training config
train_img_size = 384  # í›ˆë ¨ìš© ì´ë¯¸ì§€ í¬ê¸°
test_img_size = 480   # í…ŒìŠ¤íŠ¸ìš© ì´ë¯¸ì§€ í¬ê¸°
LR = 1e-4  # ë” í° ëª¨ë¸ì— ë§ì¶° í•™ìŠµë¥  ì¡°ì •
EPOCHS = 20  # ì¶©ë¶„í•œ epoch
BATCH_SIZE = 10  # ì´ë¯¸ì§€ í¬ê¸°ì— ë§ì¶° ë°°ì¹˜ í¬ê¸° ì¡°ì •
num_workers = 0
weight_decay = 1e-4
label_smoothing = 0.1

"""## Load Data
* í•™ìŠµ, ê²€ì¦, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
"""

# ê°•í™”ëœ augmentationì„ ìœ„í•œ transform ì½”ë“œ
trn_transform = A.Compose([
    # ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ë¦¬ì‚¬ì´ì¦ˆ (ì‘ì€ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ) + ì¤‘ì•™ í¬ë¡­
    A.SmallestMaxSize(max_size=train_img_size),  # ì´ë¯¸ì§€ ë¹„ìœ¨ ìœ ì§€í•˜ë©´ì„œ ì‘ì€ ë³€ì„ ê¸°ì¤€ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆ
    A.CenterCrop(height=train_img_size, width=train_img_size),  # ì¤‘ì•™ ê¸°ì¤€ìœ¼ë¡œ ì •ì‚¬ê°í˜• í¬ë¡­
    # ë‹¤ì–‘í•œ ë°ì´í„° ì¦ê°• ê¸°ë²•ë“¤
    A.HorizontalFlip(p=0.5),
    A.VerticalFlip(p=0.2),
    A.RandomRotate90(p=0.5),
    A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, p=0.5),
    A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.3),
    A.GaussNoise(var_limit=(10.0, 50.0), p=0.2),
    A.Blur(blur_limit=3, p=0.1),
    A.CLAHE(clip_limit=2.0, p=0.2),
    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ToTensorV2(),
])

# validation/test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ
# tst_transform_tta = val_transform_tta = trn_transform


# ê²€ì¦ ë°ì´í„° ë¶„í• 
train_df = pd.read_csv(f"{data_path}/train.csv")
train_data, val_data = train_test_split(
    train_df, 
    test_size=0.2, 
    stratify=train_df['target'], 
    random_state=SEED
)

log.info(f"Train samples: {len(train_data)}")
log.info(f"Validation samples: {len(val_data)}")

# Dataset ì •ì˜
trn_dataset = ImageDataset(
    train_data,
    f"{data_path}/train/",
    transform=trn_transform
)
val_dataset = ImageDataset(
    val_data,
    f"{data_path}/train/",
    transform=None  # TTAì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë³€í˜•í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” None
)
tst_dataset = ImageDataset(
    f"{data_path}/sample_submission.csv",
    f"{data_path}/test/",
    transform=None  # TTAì—ì„œ ì›ë³¸ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë³€í˜•í•˜ë¯€ë¡œ ì—¬ê¸°ì„œëŠ” None
)

log.info(f"Train dataset: {len(trn_dataset)}")
log.info(f"Validation dataset: {len(val_dataset)}")
log.info(f"Test dataset: {len(tst_dataset)}")

# DataLoader ì •ì˜
trn_loader = DataLoader(
    trn_dataset,
    batch_size=BATCH_SIZE,
    shuffle=True,
    num_workers=num_workers,
    pin_memory=True,
    drop_last=False
)
val_loader = DataLoader(
    val_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=num_workers,
    pin_memory=True
)
# test loader (TTAì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
tst_loader = DataLoader(
    tst_dataset,
    batch_size=BATCH_SIZE,
    shuffle=False,
    num_workers=0,
    pin_memory=True
)

"""## Train Model
* ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.
"""

# load model
model = timm.create_model(
    model_name,
    pretrained=True,
    num_classes=17
).to(device)

log.info(f"Model: {model_name}")
log.info(f"Number of parameters: {sum(p.numel() for p in model.parameters()):,}")

# Loss function, optimizer, scheduler ì •ì˜
loss_fn = LabelSmoothingLoss(classes=17, smoothing=label_smoothing)
optimizer = Adam(model.parameters(), lr=LR, weight_decay=weight_decay)
scheduler = CosineAnnealingLR(optimizer, T_max=EPOCHS, eta_min=1e-6)
scaler = GradScaler()

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥ì„ ìœ„í•œ ë³€ìˆ˜
best_val_f1 = 0.0
best_model_path = "best_model.pth"

log.info("Starting training...")
for epoch in range(EPOCHS):
    log.info(f"\n=== Epoch {epoch+1}/{EPOCHS} ===")
    
    # Training
    train_ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device, scaler)
    
    # Validation (ì§„ì§œ TTA ì ìš©ìœ¼ë¡œ test ë°ì´í„°ì™€ ë” ìœ ì‚¬í•œ ì¡°ê±´ì—ì„œ í‰ê°€)
    val_ret = validate_one_epoch_tta(val_data, model, loss_fn, device, test_img_size, data_path)
    
    # Learning rate scheduler step
    scheduler.step()
    
    # ê²°ê³¼ ì¶œë ¥
    current_lr = optimizer.param_groups[0]['lr']
    
    train_ret['epoch'] = epoch
    val_ret['epoch'] = epoch
    val_ret['lr'] = current_lr
    
    # ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ì €ì¥
    if val_ret['val_f1'] > best_val_f1:
        best_val_f1 = val_ret['val_f1']
        torch.save(model.state_dict(), best_model_path)
        log.info(f"ğŸ’¾ Best model saved! F1: {best_val_f1:.4f}")
    
    log_message = ""
    for k, v in train_ret.items():
        log_message += f"train_{k}: {v:.4f} | "
    for k, v in val_ret.items():
        log_message += f"{k}: {v:.4f} | "
    
    log.info(log_message.rstrip(" | "))

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
log.info(f"\nğŸ† Loading best model (F1: {best_val_f1:.4f})")
model.load_state_dict(torch.load(best_model_path))

"""## Inference & Save File
* í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
"""

log.info("\nStarting inference with Test Time Augmentation...")

# TTAë¡œ ì˜ˆì¸¡ (tst_dataset ì‚¬ìš©)
preds_list = predict_with_tta(model, tst_dataset, device, test_img_size)

# ê²°ê³¼ ì €ì¥
sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
pred_df = sample_submission_df.copy()
pred_df['target'] = preds_list

# ID ìˆœì„œ í™•ì¸ (ì´ë¯¸ ê°™ì€ ìˆœì„œë¡œ ì²˜ë¦¬í–ˆìœ¼ë¯€ë¡œ ë¬¸ì œì—†ìŒ)
assert len(pred_df) == len(sample_submission_df)

output_path = "./output"
os.makedirs(output_path, exist_ok=True)
pred_df.to_csv(f"{output_path}/pred_advanced_tta2_efnv2xl_resize3.csv", index=False)

log.info(f"\nâœ… Prediction completed and saved to {output_path}/pred_advanced_tta2_efnv2xl_resize3.csv")
log.info(f"Best validation F1 score: {best_val_f1:.4f}")

# ë©”ëª¨ë¦¬ ì •ë¦¬
if os.path.exists(best_model_path):
    os.remove(best_model_path)

pred_df.head()