# -*- coding: utf-8 -*-
"""baseline_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjsn3XqvQPx3tqy-ZNsGwYhI0MVkVH7b

# **📄 Document type classification baseline code**
> 문서 타입 분류 대회에 오신 여러분 환영합니다! 🎉     
> 아래 baseline에서는 ResNet 모델을 로드하여, 모델을 학습 및 예측 파일 생성하는 프로세스에 대해 알아보겠습니다.

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- Load Data
- Train Model
- Inference & Save File

## 1. Prepare Environments

* 데이터 로드를 위한 구글 드라이브를 마운트합니다.
* 필요한 라이브러리를 설치합니다.
"""

# 구글 드라이브 마운트, Colab을 이용하지 않는다면 패스해도 됩니다.
# from google.colab import drive
# drive.mount('/gdrive', force_remount=True)
# drive.mount('/content/drive')

# 구글 드라이브에 업로드된 대회 데이터를 압축 해제하고 로컬에 저장합니다.
# !tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null

# 필요한 라이브러리를 설치합니다.
# !pip install timm

"""## 2. Import Library & Define Functions
* 학습 및 추론에 필요한 라이브러리를 로드합니다.
* 학습 및 추론에 필요한 함수와 클래스를 정의합니다.
"""

import os
import time
import random

import hydra
from omegaconf import DictConfig, OmegaConf
import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score

# 로그 유틸리티 import
import log_util as log

# 현재 스크립트 위치를 작업 디렉토리로 설정
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# 데이터셋 클래스를 정의합니다.
class ImageDataset(Dataset):
    def __init__(self, csv, path, transform=None):
        self.df = pd.read_csv(csv).values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target

# one epoch 학습을 위한 함수입니다.
def train_one_epoch(loader, model, optimizer, loss_fn, device):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader)
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)

        model.zero_grad(set_to_none=True)

        preds = model(image)
        loss = loss_fn(preds, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret

@hydra.main(version_base=None, config_path="config", config_name="config")
def main(cfg: DictConfig) -> None:
    """## 3. Hyper-parameters
    * 학습 및 추론에 필요한 하이퍼파라미터들을 정의합니다.
    """
    
    # 설정 출력
    log.info(f"설정 로드 완료:")
    log.info(f"\n{OmegaConf.to_yaml(cfg)}")
    
    # 시드를 고정합니다.
    SEED = cfg.training.seed
    os.environ['PYTHONHASHSEED'] = str(SEED)
    random.seed(SEED)
    np.random.seed(SEED)
    torch.manual_seed(SEED)
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.benchmark = True

    log.info("환경 설정 완료")

    # device
    device = torch.device('cuda' if torch.cuda.is_available() and cfg.device == 'cuda' else 'cpu')
    log.info(f"사용 장치: {device}")

    # data config
    data_path = cfg.data.data_path

    # model config
    model_name = cfg.model.name

    # training config
    img_size = cfg.data.img_size
    LR = cfg.training.lr
    EPOCHS = cfg.training.epochs
    BATCH_SIZE = cfg.training.batch_size
    num_workers = cfg.data.num_workers

    log.info(f"하이퍼파라미터 설정 - 모델: {model_name}, 이미지 크기: {img_size}, 학습률: {LR}, 에포크: {EPOCHS}, 배치 크기: {BATCH_SIZE}")

    """## 4. Load Data
    * 학습, 테스트 데이터셋과 로더를 정의합니다.
    """

    # augmentation을 위한 transform 코드
    trn_transform = A.Compose([
        # 이미지 크기 조정
        A.Resize(height=img_size, width=img_size),
        # images normalization
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        # numpy 이미지나 PIL 이미지를 PyTorch 텐서로 변환
        ToTensorV2(),
    ])

    # test image 변환을 위한 transform 코드
    tst_transform = A.Compose([
        A.Resize(height=img_size, width=img_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

    # Dataset 정의
    trn_dataset = ImageDataset(
        f"{data_path}/train.csv",
        f"{data_path}/train/",
        transform=trn_transform
    )
    tst_dataset = ImageDataset(
        f"{data_path}/sample_submission.csv",
        f"{data_path}/test/",
        transform=tst_transform
    )
    log.info(f"데이터셋 로드 완료 - 훈련 데이터: {len(trn_dataset)}개, 테스트 데이터: {len(tst_dataset)}개")

    # DataLoader 정의
    trn_loader = DataLoader(
        trn_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False
    )
    tst_loader = DataLoader(
        tst_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    """## 5. Train Model
    * 모델을 로드하고, 학습을 진행합니다.
    """

    # load model
    model = timm.create_model(
        model_name,
        pretrained=cfg.model.pretrained,
        num_classes=cfg.model.num_classes
    ).to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = Adam(model.parameters(), lr=LR)

    log.info(f"모델 로드 완료 - {model_name}, 클래스 수: {cfg.model.num_classes}개")
    log.info("학습 시작")

    for epoch in range(EPOCHS):
        ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)
        ret['epoch'] = epoch

        log_message = f"Epoch {epoch+1}/{EPOCHS} 완료 - "
        log_message += f"train_loss: {ret['train_loss']:.4f}, "
        log_message += f"train_acc: {ret['train_acc']:.4f}, "
        log_message += f"train_f1: {ret['train_f1']:.4f}"
        log.info(log_message)

    """# 6. Inference & Save File
    * 테스트 이미지에 대한 추론을 진행하고, 결과 파일을 저장합니다.
    """

    log.info("추론 시작")

    preds_list = []

    model.eval()
    for image, _ in tqdm(tst_loader):
        image = image.to(device)

        with torch.no_grad():
            preds = model(image)
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())

    pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])
    pred_df['target'] = preds_list

    sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
    assert (sample_submission_df['ID'] == pred_df['ID']).all()

    output_path = cfg.output.dir
    os.makedirs(output_path, exist_ok=True)
    pred_df.to_csv(f"{output_path}/{cfg.output.filename}", index=False)

    log.info(f"추론 완료 - 결과 파일 저장: {output_path}/{cfg.output.filename}")
    log.info("전체 프로세스 완료")

    print(pred_df.head())

if __name__ == "__main__":
    main()
