# -*- coding: utf-8 -*-
"""baseline_code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pjsn3XqvQPx3tqy-ZNsGwYhI0MVkVH7b

# **ğŸ“„ Document type classification baseline code**
> ë¬¸ì„œ íƒ€ì… ë¶„ë¥˜ ëŒ€íšŒì— ì˜¤ì‹  ì—¬ëŸ¬ë¶„ í™˜ì˜í•©ë‹ˆë‹¤! ğŸ‰     
> ì•„ë˜ baselineì—ì„œëŠ” ResNet ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬, ëª¨ë¸ì„ í•™ìŠµ ë° ì˜ˆì¸¡ íŒŒì¼ ìƒì„±í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤.

## Contents
- Prepare Environments
- Import Library & Define Functions
- Hyper-parameters
- Load Data
- Train Model
- Inference & Save File

## 1. Prepare Environments

* ë°ì´í„° ë¡œë“œë¥¼ ìœ„í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œë¥¼ ë§ˆìš´íŠ¸í•©ë‹ˆë‹¤.
* í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
"""

# êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸, Colabì„ ì´ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤ë©´ íŒ¨ìŠ¤í•´ë„ ë©ë‹ˆë‹¤.
# from google.colab import drive
# drive.mount('/gdrive', force_remount=True)
# drive.mount('/content/drive')

# êµ¬ê¸€ ë“œë¼ì´ë¸Œì— ì—…ë¡œë“œëœ ëŒ€íšŒ ë°ì´í„°ë¥¼ ì••ì¶• í•´ì œí•˜ê³  ë¡œì»¬ì— ì €ì¥í•©ë‹ˆë‹¤.
# !tar -xvf drive/MyDrive/datasets_fin.tar > /dev/null

# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.
# !pip install timm

"""## 2. Import Library & Define Functions
* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
* í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•¨ìˆ˜ì™€ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
"""

import os
import time
import random

import hydra
from omegaconf import DictConfig, OmegaConf
import timm
import torch
import albumentations as A
import pandas as pd
import numpy as np
import torch.nn as nn
from albumentations.pytorch import ToTensorV2
from torch.optim import Adam
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from PIL import Image
from tqdm import tqdm
from sklearn.metrics import accuracy_score, f1_score

# ë¡œê·¸ ìœ í‹¸ë¦¬í‹° import
import log_util as log

# í˜„ì¬ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ë¥¼ ì‘ì—… ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •
os.chdir(os.path.dirname(os.path.abspath(__file__)))

# ë°ì´í„°ì…‹ í´ë˜ìŠ¤ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
class ImageDataset(Dataset):
    def __init__(self, csv, path, transform=None):
        self.df = pd.read_csv(csv).values
        self.path = path
        self.transform = transform

    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):
        name, target = self.df[idx]
        img = np.array(Image.open(os.path.join(self.path, name)))
        if self.transform:
            img = self.transform(image=img)['image']
        return img, target

# one epoch í•™ìŠµì„ ìœ„í•œ í•¨ìˆ˜ì…ë‹ˆë‹¤.
def train_one_epoch(loader, model, optimizer, loss_fn, device):
    model.train()
    train_loss = 0
    preds_list = []
    targets_list = []

    pbar = tqdm(loader)
    for image, targets in pbar:
        image = image.to(device)
        targets = targets.to(device)

        model.zero_grad(set_to_none=True)

        preds = model(image)
        loss = loss_fn(preds, targets)
        loss.backward()
        optimizer.step()

        train_loss += loss.item()
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())
        targets_list.extend(targets.detach().cpu().numpy())

        pbar.set_description(f"Loss: {loss.item():.4f}")

    train_loss /= len(loader)
    train_acc = accuracy_score(targets_list, preds_list)
    train_f1 = f1_score(targets_list, preds_list, average='macro')

    ret = {
        "train_loss": train_loss,
        "train_acc": train_acc,
        "train_f1": train_f1,
    }

    return ret

@hydra.main(version_base=None, config_path="config", config_name="config")
def main(cfg: DictConfig) -> None:
    """## 3. Hyper-parameters
    * í•™ìŠµ ë° ì¶”ë¡ ì— í•„ìš”í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„°ë“¤ì„ ì •ì˜í•©ë‹ˆë‹¤.
    """
    
    # ì„¤ì • ì¶œë ¥
    log.info(f"ì„¤ì • ë¡œë“œ ì™„ë£Œ:")
    log.info(f"\n{OmegaConf.to_yaml(cfg)}")
    
    # ì‹œë“œë¥¼ ê³ ì •í•©ë‹ˆë‹¤.
    SEED = cfg.training.seed
    os.environ['PYTHONHASHSEED'] = str(SEED)
    random.seed(SEED)
    np.random.seed(SEED)
    torch.manual_seed(SEED)
    torch.cuda.manual_seed(SEED)
    torch.cuda.manual_seed_all(SEED)
    torch.backends.cudnn.benchmark = True

    log.info("í™˜ê²½ ì„¤ì • ì™„ë£Œ")

    # device
    device = torch.device('cuda' if torch.cuda.is_available() and cfg.device == 'cuda' else 'cpu')
    log.info(f"ì‚¬ìš© ì¥ì¹˜: {device}")

    # data config
    data_path = cfg.data.data_path

    # model config
    model_name = cfg.model.name

    # training config
    img_size = cfg.data.img_size
    LR = cfg.training.lr
    EPOCHS = cfg.training.epochs
    BATCH_SIZE = cfg.training.batch_size
    num_workers = cfg.data.num_workers

    log.info(f"í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì • - ëª¨ë¸: {model_name}, ì´ë¯¸ì§€ í¬ê¸°: {img_size}, í•™ìŠµë¥ : {LR}, ì—í¬í¬: {EPOCHS}, ë°°ì¹˜ í¬ê¸°: {BATCH_SIZE}")

    """## 4. Load Data
    * í•™ìŠµ, í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ê³¼ ë¡œë”ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
    """

    # augmentationì„ ìœ„í•œ transform ì½”ë“œ
    trn_transform = A.Compose([
        # ì´ë¯¸ì§€ í¬ê¸° ì¡°ì •
        A.Resize(height=img_size, width=img_size),
        # images normalization
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        # numpy ì´ë¯¸ì§€ë‚˜ PIL ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜
        ToTensorV2(),
    ])

    # test image ë³€í™˜ì„ ìœ„í•œ transform ì½”ë“œ
    tst_transform = A.Compose([
        A.Resize(height=img_size, width=img_size),
        A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
        ToTensorV2(),
    ])

    # Dataset ì •ì˜
    trn_dataset = ImageDataset(
        f"{data_path}/train.csv",
        f"{data_path}/train/",
        transform=trn_transform
    )
    tst_dataset = ImageDataset(
        f"{data_path}/sample_submission.csv",
        f"{data_path}/test/",
        transform=tst_transform
    )
    log.info(f"ë°ì´í„°ì…‹ ë¡œë“œ ì™„ë£Œ - í›ˆë ¨ ë°ì´í„°: {len(trn_dataset)}ê°œ, í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(tst_dataset)}ê°œ")

    # DataLoader ì •ì˜
    trn_loader = DataLoader(
        trn_dataset,
        batch_size=BATCH_SIZE,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=False
    )
    tst_loader = DataLoader(
        tst_dataset,
        batch_size=BATCH_SIZE,
        shuffle=False,
        num_workers=0,
        pin_memory=True
    )

    """## 5. Train Model
    * ëª¨ë¸ì„ ë¡œë“œí•˜ê³ , í•™ìŠµì„ ì§„í–‰í•©ë‹ˆë‹¤.
    """

    # load model
    model = timm.create_model(
        model_name,
        pretrained=cfg.model.pretrained,
        num_classes=cfg.model.num_classes
    ).to(device)
    loss_fn = nn.CrossEntropyLoss()
    optimizer = Adam(model.parameters(), lr=LR)

    log.info(f"ëª¨ë¸ ë¡œë“œ ì™„ë£Œ - {model_name}, í´ë˜ìŠ¤ ìˆ˜: {cfg.model.num_classes}ê°œ")
    log.info("í•™ìŠµ ì‹œì‘")

    for epoch in range(EPOCHS):
        ret = train_one_epoch(trn_loader, model, optimizer, loss_fn, device=device)
        ret['epoch'] = epoch

        log_message = f"Epoch {epoch+1}/{EPOCHS} ì™„ë£Œ - "
        log_message += f"train_loss: {ret['train_loss']:.4f}, "
        log_message += f"train_acc: {ret['train_acc']:.4f}, "
        log_message += f"train_f1: {ret['train_f1']:.4f}"
        log.info(log_message)

    """# 6. Inference & Save File
    * í…ŒìŠ¤íŠ¸ ì´ë¯¸ì§€ì— ëŒ€í•œ ì¶”ë¡ ì„ ì§„í–‰í•˜ê³ , ê²°ê³¼ íŒŒì¼ì„ ì €ì¥í•©ë‹ˆë‹¤.
    """

    log.info("ì¶”ë¡  ì‹œì‘")

    preds_list = []

    model.eval()
    for image, _ in tqdm(tst_loader):
        image = image.to(device)

        with torch.no_grad():
            preds = model(image)
        preds_list.extend(preds.argmax(dim=1).detach().cpu().numpy())

    pred_df = pd.DataFrame(tst_dataset.df, columns=['ID', 'target'])
    pred_df['target'] = preds_list

    sample_submission_df = pd.read_csv(f"{data_path}/sample_submission.csv")
    assert (sample_submission_df['ID'] == pred_df['ID']).all()

    output_path = cfg.output.dir
    os.makedirs(output_path, exist_ok=True)
    pred_df.to_csv(f"{output_path}/{cfg.output.filename}", index=False)

    log.info(f"ì¶”ë¡  ì™„ë£Œ - ê²°ê³¼ íŒŒì¼ ì €ì¥: {output_path}/{cfg.output.filename}")
    log.info("ì „ì²´ í”„ë¡œì„¸ìŠ¤ ì™„ë£Œ")

    print(pred_df.head())

if __name__ == "__main__":
    main()
